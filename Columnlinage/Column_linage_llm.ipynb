{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyN0NDxJfefb3UmDyj1SAdwv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3bdc539b20f44af4a24da2fcc2ccc185": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e1ddb276f95948f49b9d5d0139cae186",
              "IPY_MODEL_6b670c08f1e448ccb61458241695de19",
              "IPY_MODEL_751fb5ba4d9c488cb18646ea30f3995c"
            ],
            "layout": "IPY_MODEL_f3649e8661b842a882cd2bde3fbcefdb"
          }
        },
        "e1ddb276f95948f49b9d5d0139cae186": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d10957f7c6504bc8b5f3e213ecc29046",
            "placeholder": "​",
            "style": "IPY_MODEL_44d6e57752074d8896b4cc305872dbe5",
            "value": "Downloading shards: 100%"
          }
        },
        "6b670c08f1e448ccb61458241695de19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f6473f97ca94deba47e36c6f02c6b96",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1bb9707f848f44ea985eabd7c9ef7dad",
            "value": 2
          }
        },
        "751fb5ba4d9c488cb18646ea30f3995c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_558b9c3e4264467cbde59a42b46018e6",
            "placeholder": "​",
            "style": "IPY_MODEL_cfd75aa34d9e4495be158f2ab3e35d37",
            "value": " 2/2 [01:10&lt;00:00, 32.49s/it]"
          }
        },
        "f3649e8661b842a882cd2bde3fbcefdb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d10957f7c6504bc8b5f3e213ecc29046": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44d6e57752074d8896b4cc305872dbe5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3f6473f97ca94deba47e36c6f02c6b96": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1bb9707f848f44ea985eabd7c9ef7dad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "558b9c3e4264467cbde59a42b46018e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfd75aa34d9e4495be158f2ab3e35d37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2b8d50eb0cae48429c194ce073d9b813": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e662de39b84f4533ba93f628de8e20c6",
              "IPY_MODEL_401235cb9fb2455f8542ce21b7c04d91",
              "IPY_MODEL_c66a3ae3384a4d21872deb76884ba63c"
            ],
            "layout": "IPY_MODEL_d943ab5028024f20b319c20ae45c37fc"
          }
        },
        "e662de39b84f4533ba93f628de8e20c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f73be49ffcd64246af756efa7cf3f53b",
            "placeholder": "​",
            "style": "IPY_MODEL_36449dc2e9cd4059818be6ab8be5660a",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "401235cb9fb2455f8542ce21b7c04d91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_389bc5eaa8e54a458013101f2e0ee6ff",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1b090acd5191486a9348040795f5c50b",
            "value": 2
          }
        },
        "c66a3ae3384a4d21872deb76884ba63c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d89fb4b35c8447f8bcc915ac24099a23",
            "placeholder": "​",
            "style": "IPY_MODEL_48ad18498d294971a81f1eea80a0a282",
            "value": " 2/2 [00:07&lt;00:00,  3.36s/it]"
          }
        },
        "d943ab5028024f20b319c20ae45c37fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f73be49ffcd64246af756efa7cf3f53b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36449dc2e9cd4059818be6ab8be5660a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "389bc5eaa8e54a458013101f2e0ee6ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b090acd5191486a9348040795f5c50b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d89fb4b35c8447f8bcc915ac24099a23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48ad18498d294971a81f1eea80a0a282": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/indrajeetapache/Innovation-Hub/blob/main/Columnlinage/Column_linage_llm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***\n",
        "1. We will try to mimic the column lineage with LLM.\n",
        "2. Spark will be used in this session and to provide the lineage etween source and target we will LLM\n",
        "***\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DkbbuRvpFJQP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, concat, lit, sum as spark_sum, avg, count\n",
        "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType\n",
        "from pyspark.sql import functions as F\n",
        "from io import StringIO\n",
        "from pyspark.sql import DataFrame\n",
        "import sys\n",
        "import os\n",
        "os.environ['HF_HUB_DISABLE_PROGRESS_BARS'] = '1'"
      ],
      "metadata": {
        "id": "_3ScXVa5FcK7"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Spark\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"DAG_Lineage_Extraction\") \\\n",
        "    .config(\"spark.sql.adaptive.enabled\", \"false\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Create sample data\n",
        "sample_data = [\n",
        "    (\"John\", \"Doe\", 25, 50000.0, \"Engineering\"),\n",
        "    (\"Jane\", \"Smith\", 30, 75000.0, \"Marketing\"),\n",
        "    (\"Bob\", \"Johnson\", 35, 60000.0, \"Engineering\"),\n",
        "    (\"Alice\", \"Brown\", 28, 80000.0, \"Sales\"),\n",
        "    (\"Charlie\", \"Wilson\", 32, 70000.0, \"Marketing\")\n",
        "]\n",
        "\n",
        "schema = StructType([\n",
        "    StructField(\"first_name\", StringType(), True),\n",
        "    StructField(\"last_name\", StringType(), True),\n",
        "    StructField(\"age\", IntegerType(), True),\n",
        "    StructField(\"salary\", DoubleType(), True),\n",
        "    StructField(\"department\", StringType(), True)\n",
        "])\n",
        "\n",
        "# Create initial DataFrame\n",
        "df_original = spark.createDataFrame(sample_data, schema)"
      ],
      "metadata": {
        "id": "dZUKwiQLHe84"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_original.show(10,0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OOFFVaGpHi9P",
        "outputId": "d1a6c19d-43e6-454a-fdf3-98755ccf6823"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+---------+---+-------+-----------+\n",
            "|first_name|last_name|age|salary |department |\n",
            "+----------+---------+---+-------+-----------+\n",
            "|John      |Doe      |25 |50000.0|Engineering|\n",
            "|Jane      |Smith    |30 |75000.0|Marketing  |\n",
            "|Bob       |Johnson  |35 |60000.0|Engineering|\n",
            "|Alice     |Brown    |28 |80000.0|Sales      |\n",
            "|Charlie   |Wilson   |32 |70000.0|Marketing  |\n",
            "+----------+---------+---+-------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Original DataFrame:\")\n",
        "df_original.show()\n",
        "\n",
        "# Transformation 1: Create derived columns\n",
        "df_transformed = df_original \\\n",
        "    .withColumn(\"full_name\", concat(col(\"first_name\"), lit(\" \"), col(\"last_name\"))) \\\n",
        "    .withColumn(\"salary_category\",\n",
        "                F.when(col(\"salary\") > 70000, \"High\")\n",
        "                .when(col(\"salary\") > 50000, \"Medium\")\n",
        "                .otherwise(\"Low\")) \\\n",
        "    .withColumn(\"age_group\",\n",
        "                F.when(col(\"age\") < 30, \"Young\")\n",
        "                .otherwise(\"Senior\"))\n",
        "print(\"\\nTransformed DataFrame:\")\n",
        "df_transformed.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3O_YZS3HqNc",
        "outputId": "84bdadb7-6a9f-44ea-e4c4-5c7dc966199f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original DataFrame:\n",
            "+----------+---------+---+-------+-----------+\n",
            "|first_name|last_name|age| salary| department|\n",
            "+----------+---------+---+-------+-----------+\n",
            "|      John|      Doe| 25|50000.0|Engineering|\n",
            "|      Jane|    Smith| 30|75000.0|  Marketing|\n",
            "|       Bob|  Johnson| 35|60000.0|Engineering|\n",
            "|     Alice|    Brown| 28|80000.0|      Sales|\n",
            "|   Charlie|   Wilson| 32|70000.0|  Marketing|\n",
            "+----------+---------+---+-------+-----------+\n",
            "\n",
            "\n",
            "Transformed DataFrame:\n",
            "+----------+---------+---+-------+-----------+--------------+---------------+---------+\n",
            "|first_name|last_name|age| salary| department|     full_name|salary_category|age_group|\n",
            "+----------+---------+---+-------+-----------+--------------+---------------+---------+\n",
            "|      John|      Doe| 25|50000.0|Engineering|      John Doe|            Low|    Young|\n",
            "|      Jane|    Smith| 30|75000.0|  Marketing|    Jane Smith|           High|   Senior|\n",
            "|       Bob|  Johnson| 35|60000.0|Engineering|   Bob Johnson|         Medium|   Senior|\n",
            "|     Alice|    Brown| 28|80000.0|      Sales|   Alice Brown|           High|    Young|\n",
            "|   Charlie|   Wilson| 32|70000.0|  Marketing|Charlie Wilson|         Medium|   Senior|\n",
            "+----------+---------+---+-------+-----------+--------------+---------------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_aggregated = df_transformed \\\n",
        "    .groupBy(\"department\", \"salary_category\") \\\n",
        "    .agg(\n",
        "        spark_sum(\"salary\").alias(\"total_salary\"),\n",
        "        avg(\"age\").alias(\"avg_age\"),\n",
        "        count(\"*\").alias(\"employee_count\")\n",
        "    )\n",
        "\n",
        "print(\"\\nAggregated DataFrame:\")\n",
        "df_aggregated.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dg3GQl0WHvD3",
        "outputId": "da71bde6-3d6a-4fa1-aa15-4ff2742eefc2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Aggregated DataFrame:\n",
            "+-----------+---------------+------------+-------+--------------+\n",
            "| department|salary_category|total_salary|avg_age|employee_count|\n",
            "+-----------+---------------+------------+-------+--------------+\n",
            "|Engineering|            Low|     50000.0|   25.0|             1|\n",
            "|      Sales|           High|     80000.0|   28.0|             1|\n",
            "|  Marketing|         Medium|     70000.0|   32.0|             1|\n",
            "|Engineering|         Medium|     60000.0|   35.0|             1|\n",
            "|  Marketing|           High|     75000.0|   30.0|             1|\n",
            "+-----------+---------------+------------+-------+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Function to extract dag information**"
      ],
      "metadata": {
        "id": "ArKgvV0uIYh4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to extract DAG information\n",
        "def extract_dag_info(dataframe, stage_name):\n",
        "    \"\"\"Extract both logical and physical plan information\"\"\"\n",
        "\n",
        "    # Method 1: Using explain() to capture plans\n",
        "    from io import StringIO\n",
        "    import sys\n",
        "\n",
        "    # Capture explain output\n",
        "    old_stdout = sys.stdout\n",
        "    sys.stdout = buffer = StringIO()\n",
        "\n",
        "    # Get extended plan information\n",
        "    dataframe.explain(extended=True)\n",
        "    plan_output = buffer.getvalue()\n",
        "\n",
        "    sys.stdout = old_stdout\n",
        "\n",
        "    # Split the explain output into logical and physical parts\n",
        "    lines = plan_output.split('\\n')\n",
        "    logical_start = -1\n",
        "    physical_start = -1\n",
        "\n",
        "    for i, line in enumerate(lines):\n",
        "        if \"Parsed Logical Plan\" in line or \"Analyzed Logical Plan\" in line:\n",
        "            logical_start = i\n",
        "        elif \"Physical Plan\" in line:\n",
        "            physical_start = i\n",
        "            break\n",
        "\n",
        "    logical_plan_str = '\\n'.join(lines[logical_start:physical_start]) if logical_start != -1 else \"Not found\"\n",
        "    physical_plan_str = '\\n'.join(lines[physical_start:]) if physical_start != -1 else \"Not found\"\n",
        "\n",
        "    dag_info = {\n",
        "        \"stage_name\": stage_name,\n",
        "        \"logical_plan\": logical_plan_str,\n",
        "        \"physical_plan\": physical_plan_str,\n",
        "        \"full_explain\": plan_output,\n",
        "        \"schema\": [{\"name\": field.name, \"type\": str(field.dataType)} for field in dataframe.schema.fields]\n",
        "    }\n",
        "\n",
        "    return dag_info\n"
      ],
      "metadata": {
        "id": "4sSeH6jBIQ_y"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TEXT for LLM**"
      ],
      "metadata": {
        "id": "nFwCVqoTItnp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to extract transformation details for LLM\n",
        "def extract_transformation_context(df_before, df_after, transformation_type):\n",
        "    \"\"\"Extract context that LLM can use for lineage analysis\"\"\"\n",
        "\n",
        "    before_columns = [field.name for field in df_before.schema.fields]\n",
        "    after_columns = [field.name for field in df_after.schema.fields]\n",
        "\n",
        "    transformation_context = {\n",
        "        \"transformation_type\": transformation_type,\n",
        "        \"input_columns\": before_columns,\n",
        "        \"output_columns\": after_columns,\n",
        "        \"new_columns\": list(set(after_columns) - set(before_columns)),\n",
        "        \"dropped_columns\": list(set(before_columns) - set(after_columns))\n",
        "    }\n",
        "\n",
        "    return transformation_context"
      ],
      "metadata": {
        "id": "saSB-mznInnq"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Extracted DAG information**"
      ],
      "metadata": {
        "id": "4eEK-vILI3q0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"EXTRACTING DAG INFORMATION\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "original_dag = extract_dag_info(df_original, \"original\")\n",
        "transformed_dag = extract_dag_info(df_transformed, \"transformed\")\n",
        "aggregated_dag = extract_dag_info(df_aggregated, \"aggregated\")\n"
      ],
      "metadata": {
        "id": "Lu2YZ4tgIxkC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9da7249b-89a2-489d-a6ab-8f0b11c103e5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "EXTRACTING DAG INFORMATION\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "original_dag\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRFGpGezI_tz",
        "outputId": "23bc56f5-f540-48bf-cb7d-96934c17b4dc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'stage_name': 'original',\n",
              " 'logical_plan': '== Analyzed Logical Plan ==\\nfirst_name: string, last_name: string, age: int, salary: double, department: string\\nLogicalRDD [first_name#0, last_name#1, age#2, salary#3, department#4], false\\n\\n== Optimized Logical Plan ==\\nLogicalRDD [first_name#0, last_name#1, age#2, salary#3, department#4], false\\n',\n",
              " 'physical_plan': '== Physical Plan ==\\n*(1) Scan ExistingRDD[first_name#0,last_name#1,age#2,salary#3,department#4]\\n\\n',\n",
              " 'full_explain': '== Parsed Logical Plan ==\\nLogicalRDD [first_name#0, last_name#1, age#2, salary#3, department#4], false\\n\\n== Analyzed Logical Plan ==\\nfirst_name: string, last_name: string, age: int, salary: double, department: string\\nLogicalRDD [first_name#0, last_name#1, age#2, salary#3, department#4], false\\n\\n== Optimized Logical Plan ==\\nLogicalRDD [first_name#0, last_name#1, age#2, salary#3, department#4], false\\n\\n== Physical Plan ==\\n*(1) Scan ExistingRDD[first_name#0,last_name#1,age#2,salary#3,department#4]\\n\\n',\n",
              " 'schema': [{'name': 'first_name', 'type': 'StringType()'},\n",
              "  {'name': 'last_name', 'type': 'StringType()'},\n",
              "  {'name': 'age', 'type': 'IntegerType()'},\n",
              "  {'name': 'salary', 'type': 'DoubleType()'},\n",
              "  {'name': 'department', 'type': 'StringType()'}]}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transformed_dag"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_vucbI0J8p5",
        "outputId": "75b08e9c-b0e9-406e-ebbc-4bb6859e81f1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'stage_name': 'transformed',\n",
              " 'logical_plan': '== Analyzed Logical Plan ==\\nfirst_name: string, last_name: string, age: int, salary: double, department: string, full_name: string, salary_category: string, age_group: string\\nProject [first_name#0, last_name#1, age#2, salary#3, department#4, full_name#52, salary_category#59, CASE WHEN (age#2 < 30) THEN Young ELSE Senior END AS age_group#67]\\n+- Project [first_name#0, last_name#1, age#2, salary#3, department#4, full_name#52, CASE WHEN (salary#3 > cast(70000 as double)) THEN High WHEN (salary#3 > cast(50000 as double)) THEN Medium ELSE Low END AS salary_category#59]\\n   +- Project [first_name#0, last_name#1, age#2, salary#3, department#4, concat(first_name#0,  , last_name#1) AS full_name#52]\\n      +- LogicalRDD [first_name#0, last_name#1, age#2, salary#3, department#4], false\\n\\n== Optimized Logical Plan ==\\nProject [first_name#0, last_name#1, age#2, salary#3, department#4, concat(first_name#0,  , last_name#1) AS full_name#52, CASE WHEN (salary#3 > 70000.0) THEN High WHEN (salary#3 > 50000.0) THEN Medium ELSE Low END AS salary_category#59, CASE WHEN (age#2 < 30) THEN Young ELSE Senior END AS age_group#67]\\n+- LogicalRDD [first_name#0, last_name#1, age#2, salary#3, department#4], false\\n',\n",
              " 'physical_plan': '== Physical Plan ==\\n*(1) Project [first_name#0, last_name#1, age#2, salary#3, department#4, concat(first_name#0,  , last_name#1) AS full_name#52, CASE WHEN (salary#3 > 70000.0) THEN High WHEN (salary#3 > 50000.0) THEN Medium ELSE Low END AS salary_category#59, CASE WHEN (age#2 < 30) THEN Young ELSE Senior END AS age_group#67]\\n+- *(1) Scan ExistingRDD[first_name#0,last_name#1,age#2,salary#3,department#4]\\n\\n',\n",
              " 'full_explain': \"== Parsed Logical Plan ==\\n'Project [first_name#0, last_name#1, age#2, salary#3, department#4, full_name#52, salary_category#59, CASE WHEN ('age < 30) THEN Young ELSE Senior END AS age_group#67]\\n+- Project [first_name#0, last_name#1, age#2, salary#3, department#4, full_name#52, CASE WHEN (salary#3 > cast(70000 as double)) THEN High WHEN (salary#3 > cast(50000 as double)) THEN Medium ELSE Low END AS salary_category#59]\\n   +- Project [first_name#0, last_name#1, age#2, salary#3, department#4, concat(first_name#0,  , last_name#1) AS full_name#52]\\n      +- LogicalRDD [first_name#0, last_name#1, age#2, salary#3, department#4], false\\n\\n== Analyzed Logical Plan ==\\nfirst_name: string, last_name: string, age: int, salary: double, department: string, full_name: string, salary_category: string, age_group: string\\nProject [first_name#0, last_name#1, age#2, salary#3, department#4, full_name#52, salary_category#59, CASE WHEN (age#2 < 30) THEN Young ELSE Senior END AS age_group#67]\\n+- Project [first_name#0, last_name#1, age#2, salary#3, department#4, full_name#52, CASE WHEN (salary#3 > cast(70000 as double)) THEN High WHEN (salary#3 > cast(50000 as double)) THEN Medium ELSE Low END AS salary_category#59]\\n   +- Project [first_name#0, last_name#1, age#2, salary#3, department#4, concat(first_name#0,  , last_name#1) AS full_name#52]\\n      +- LogicalRDD [first_name#0, last_name#1, age#2, salary#3, department#4], false\\n\\n== Optimized Logical Plan ==\\nProject [first_name#0, last_name#1, age#2, salary#3, department#4, concat(first_name#0,  , last_name#1) AS full_name#52, CASE WHEN (salary#3 > 70000.0) THEN High WHEN (salary#3 > 50000.0) THEN Medium ELSE Low END AS salary_category#59, CASE WHEN (age#2 < 30) THEN Young ELSE Senior END AS age_group#67]\\n+- LogicalRDD [first_name#0, last_name#1, age#2, salary#3, department#4], false\\n\\n== Physical Plan ==\\n*(1) Project [first_name#0, last_name#1, age#2, salary#3, department#4, concat(first_name#0,  , last_name#1) AS full_name#52, CASE WHEN (salary#3 > 70000.0) THEN High WHEN (salary#3 > 50000.0) THEN Medium ELSE Low END AS salary_category#59, CASE WHEN (age#2 < 30) THEN Young ELSE Senior END AS age_group#67]\\n+- *(1) Scan ExistingRDD[first_name#0,last_name#1,age#2,salary#3,department#4]\\n\\n\",\n",
              " 'schema': [{'name': 'first_name', 'type': 'StringType()'},\n",
              "  {'name': 'last_name', 'type': 'StringType()'},\n",
              "  {'name': 'age', 'type': 'IntegerType()'},\n",
              "  {'name': 'salary', 'type': 'DoubleType()'},\n",
              "  {'name': 'department', 'type': 'StringType()'},\n",
              "  {'name': 'full_name', 'type': 'StringType()'},\n",
              "  {'name': 'salary_category', 'type': 'StringType()'},\n",
              "  {'name': 'age_group', 'type': 'StringType()'}]}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "aggregated_dag"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_FRxPX1aKAPI",
        "outputId": "d5f25915-1a4c-4289-e0c5-bbf655a7cb44"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'stage_name': 'aggregated',\n",
              " 'logical_plan': '== Analyzed Logical Plan ==\\ndepartment: string, salary_category: string, total_salary: double, avg_age: double, employee_count: bigint\\nAggregate [department#4, salary_category#59], [department#4, salary_category#59, sum(salary#3) AS total_salary#118, avg(age#2) AS avg_age#120, count(1) AS employee_count#122L]\\n+- Project [first_name#0, last_name#1, age#2, salary#3, department#4, full_name#52, salary_category#59, CASE WHEN (age#2 < 30) THEN Young ELSE Senior END AS age_group#67]\\n   +- Project [first_name#0, last_name#1, age#2, salary#3, department#4, full_name#52, CASE WHEN (salary#3 > cast(70000 as double)) THEN High WHEN (salary#3 > cast(50000 as double)) THEN Medium ELSE Low END AS salary_category#59]\\n      +- Project [first_name#0, last_name#1, age#2, salary#3, department#4, concat(first_name#0,  , last_name#1) AS full_name#52]\\n         +- LogicalRDD [first_name#0, last_name#1, age#2, salary#3, department#4], false\\n\\n== Optimized Logical Plan ==\\nAggregate [department#4, salary_category#59], [department#4, salary_category#59, sum(salary#3) AS total_salary#118, avg(age#2) AS avg_age#120, count(1) AS employee_count#122L]\\n+- Project [age#2, salary#3, department#4, CASE WHEN (salary#3 > 70000.0) THEN High WHEN (salary#3 > 50000.0) THEN Medium ELSE Low END AS salary_category#59]\\n   +- LogicalRDD [first_name#0, last_name#1, age#2, salary#3, department#4], false\\n',\n",
              " 'physical_plan': '== Physical Plan ==\\n*(2) HashAggregate(keys=[department#4, salary_category#59], functions=[sum(salary#3), avg(age#2), count(1)], output=[department#4, salary_category#59, total_salary#118, avg_age#120, employee_count#122L])\\n+- Exchange hashpartitioning(department#4, salary_category#59, 200), ENSURE_REQUIREMENTS, [plan_id=99]\\n   +- *(1) HashAggregate(keys=[department#4, salary_category#59], functions=[partial_sum(salary#3), partial_avg(age#2), partial_count(1)], output=[department#4, salary_category#59, sum#147, sum#148, count#149L, count#150L])\\n      +- *(1) Project [age#2, salary#3, department#4, CASE WHEN (salary#3 > 70000.0) THEN High WHEN (salary#3 > 50000.0) THEN Medium ELSE Low END AS salary_category#59]\\n         +- *(1) Scan ExistingRDD[first_name#0,last_name#1,age#2,salary#3,department#4]\\n\\n',\n",
              " 'full_explain': \"== Parsed Logical Plan ==\\n'Aggregate ['department, 'salary_category], ['department, 'salary_category, sum('salary) AS total_salary#118, avg('age) AS avg_age#120, count(1) AS employee_count#122L]\\n+- Project [first_name#0, last_name#1, age#2, salary#3, department#4, full_name#52, salary_category#59, CASE WHEN (age#2 < 30) THEN Young ELSE Senior END AS age_group#67]\\n   +- Project [first_name#0, last_name#1, age#2, salary#3, department#4, full_name#52, CASE WHEN (salary#3 > cast(70000 as double)) THEN High WHEN (salary#3 > cast(50000 as double)) THEN Medium ELSE Low END AS salary_category#59]\\n      +- Project [first_name#0, last_name#1, age#2, salary#3, department#4, concat(first_name#0,  , last_name#1) AS full_name#52]\\n         +- LogicalRDD [first_name#0, last_name#1, age#2, salary#3, department#4], false\\n\\n== Analyzed Logical Plan ==\\ndepartment: string, salary_category: string, total_salary: double, avg_age: double, employee_count: bigint\\nAggregate [department#4, salary_category#59], [department#4, salary_category#59, sum(salary#3) AS total_salary#118, avg(age#2) AS avg_age#120, count(1) AS employee_count#122L]\\n+- Project [first_name#0, last_name#1, age#2, salary#3, department#4, full_name#52, salary_category#59, CASE WHEN (age#2 < 30) THEN Young ELSE Senior END AS age_group#67]\\n   +- Project [first_name#0, last_name#1, age#2, salary#3, department#4, full_name#52, CASE WHEN (salary#3 > cast(70000 as double)) THEN High WHEN (salary#3 > cast(50000 as double)) THEN Medium ELSE Low END AS salary_category#59]\\n      +- Project [first_name#0, last_name#1, age#2, salary#3, department#4, concat(first_name#0,  , last_name#1) AS full_name#52]\\n         +- LogicalRDD [first_name#0, last_name#1, age#2, salary#3, department#4], false\\n\\n== Optimized Logical Plan ==\\nAggregate [department#4, salary_category#59], [department#4, salary_category#59, sum(salary#3) AS total_salary#118, avg(age#2) AS avg_age#120, count(1) AS employee_count#122L]\\n+- Project [age#2, salary#3, department#4, CASE WHEN (salary#3 > 70000.0) THEN High WHEN (salary#3 > 50000.0) THEN Medium ELSE Low END AS salary_category#59]\\n   +- LogicalRDD [first_name#0, last_name#1, age#2, salary#3, department#4], false\\n\\n== Physical Plan ==\\n*(2) HashAggregate(keys=[department#4, salary_category#59], functions=[sum(salary#3), avg(age#2), count(1)], output=[department#4, salary_category#59, total_salary#118, avg_age#120, employee_count#122L])\\n+- Exchange hashpartitioning(department#4, salary_category#59, 200), ENSURE_REQUIREMENTS, [plan_id=99]\\n   +- *(1) HashAggregate(keys=[department#4, salary_category#59], functions=[partial_sum(salary#3), partial_avg(age#2), partial_count(1)], output=[department#4, salary_category#59, sum#147, sum#148, count#149L, count#150L])\\n      +- *(1) Project [age#2, salary#3, department#4, CASE WHEN (salary#3 > 70000.0) THEN High WHEN (salary#3 > 50000.0) THEN Medium ELSE Low END AS salary_category#59]\\n         +- *(1) Scan ExistingRDD[first_name#0,last_name#1,age#2,salary#3,department#4]\\n\\n\",\n",
              " 'schema': [{'name': 'department', 'type': 'StringType()'},\n",
              "  {'name': 'salary_category', 'type': 'StringType()'},\n",
              "  {'name': 'total_salary', 'type': 'DoubleType()'},\n",
              "  {'name': 'avg_age', 'type': 'DoubleType()'},\n",
              "  {'name': 'employee_count', 'type': 'LongType()'}]}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Extract transformation contexts**"
      ],
      "metadata": {
        "id": "_yp0EPkGKYb0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform_context_1 = extract_transformation_context(df_original, df_transformed, \"column_derivation\")\n",
        "transform_context_2 = extract_transformation_context(df_transformed, df_aggregated, \"aggregation\")"
      ],
      "metadata": {
        "id": "6oMpidebKTHS"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform_context_1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4O9np3UlKbu7",
        "outputId": "8b2e96aa-1046-4b49-b251-faebb062583a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'transformation_type': 'column_derivation',\n",
              " 'input_columns': ['first_name', 'last_name', 'age', 'salary', 'department'],\n",
              " 'output_columns': ['first_name',\n",
              "  'last_name',\n",
              "  'age',\n",
              "  'salary',\n",
              "  'department',\n",
              "  'full_name',\n",
              "  'salary_category',\n",
              "  'age_group'],\n",
              " 'new_columns': ['full_name', 'salary_category', 'age_group'],\n",
              " 'dropped_columns': []}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform_context_2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24O4iyZxKc1i",
        "outputId": "e5b31f26-2b23-48f6-a0e8-bee3a94f8ab0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'transformation_type': 'aggregation',\n",
              " 'input_columns': ['first_name',\n",
              "  'last_name',\n",
              "  'age',\n",
              "  'salary',\n",
              "  'department',\n",
              "  'full_name',\n",
              "  'salary_category',\n",
              "  'age_group'],\n",
              " 'output_columns': ['department',\n",
              "  'salary_category',\n",
              "  'total_salary',\n",
              "  'avg_age',\n",
              "  'employee_count'],\n",
              " 'new_columns': ['avg_age', 'employee_count', 'total_salary'],\n",
              " 'dropped_columns': ['full_name',\n",
              "  'salary',\n",
              "  'last_name',\n",
              "  'age',\n",
              "  'age_group',\n",
              "  'first_name']}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prepare data for LLM processing**"
      ],
      "metadata": {
        "id": "oB9foppsNhiq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "llm_input_data = {\n",
        "    \"job_id\": \"sample_lineage_job\",\n",
        "    \"transformations\": [\n",
        "        {\n",
        "            \"stage\": \"original_to_transformed\",\n",
        "            \"context\": transform_context_1,\n",
        "            \"dag_info\": transformed_dag\n",
        "        },\n",
        "        {\n",
        "            \"stage\": \"transformed_to_aggregated\",\n",
        "            \"context\": transform_context_2,\n",
        "            \"dag_info\": aggregated_dag\n",
        "        }\n",
        "    ]\n",
        "}"
      ],
      "metadata": {
        "id": "8n1ebZabKeUG"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DAG information for LLM**"
      ],
      "metadata": {
        "id": "y7Ae-cdgNvjS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"\\nSample DAG Information for LLM:\")\n",
        "print(json.dumps(llm_input_data, indent=2)[:1000] + \"...\")\n",
        "\n",
        "\n",
        "print(\"\\nLogical Plan for 'transformed' stage:\")\n",
        "print(transformed_dag[\"logical_plan\"][:500] + \"...\")\n",
        "\n",
        "print(\"\\nPhysical Plan for 'aggregated' stage:\")\n",
        "print(aggregated_dag[\"physical_plan\"][:500] + \"...\")\n",
        "\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"DAG EXTRACTION COMPLETE\")\n",
        "print(\"=\"*50)"
      ],
      "metadata": {
        "id": "t2b91NW8Knu8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffcf7d72-277f-4610-c8a0-9417dc837f41"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sample DAG Information for LLM:\n",
            "{\n",
            "  \"job_id\": \"sample_lineage_job\",\n",
            "  \"transformations\": [\n",
            "    {\n",
            "      \"stage\": \"original_to_transformed\",\n",
            "      \"context\": {\n",
            "        \"transformation_type\": \"column_derivation\",\n",
            "        \"input_columns\": [\n",
            "          \"first_name\",\n",
            "          \"last_name\",\n",
            "          \"age\",\n",
            "          \"salary\",\n",
            "          \"department\"\n",
            "        ],\n",
            "        \"output_columns\": [\n",
            "          \"first_name\",\n",
            "          \"last_name\",\n",
            "          \"age\",\n",
            "          \"salary\",\n",
            "          \"department\",\n",
            "          \"full_name\",\n",
            "          \"salary_category\",\n",
            "          \"age_group\"\n",
            "        ],\n",
            "        \"new_columns\": [\n",
            "          \"full_name\",\n",
            "          \"salary_category\",\n",
            "          \"age_group\"\n",
            "        ],\n",
            "        \"dropped_columns\": []\n",
            "      },\n",
            "      \"dag_info\": {\n",
            "        \"stage_name\": \"transformed\",\n",
            "        \"logical_plan\": \"== Analyzed Logical Plan ==\\nfirst_name: string, last_name: string, age: int, salary: double, department: string, full_name: string, salary_category: string, age_group: string\\nProject [first_name#0, last_name#1, age#2, salar...\n",
            "\n",
            "Logical Plan for 'transformed' stage:\n",
            "== Analyzed Logical Plan ==\n",
            "first_name: string, last_name: string, age: int, salary: double, department: string, full_name: string, salary_category: string, age_group: string\n",
            "Project [first_name#0, last_name#1, age#2, salary#3, department#4, full_name#52, salary_category#59, CASE WHEN (age#2 < 30) THEN Young ELSE Senior END AS age_group#67]\n",
            "+- Project [first_name#0, last_name#1, age#2, salary#3, department#4, full_name#52, CASE WHEN (salary#3 > cast(70000 as double)) THEN High WHEN (salary#3 > c...\n",
            "\n",
            "Physical Plan for 'aggregated' stage:\n",
            "== Physical Plan ==\n",
            "*(2) HashAggregate(keys=[department#4, salary_category#59], functions=[sum(salary#3), avg(age#2), count(1)], output=[department#4, salary_category#59, total_salary#118, avg_age#120, employee_count#122L])\n",
            "+- Exchange hashpartitioning(department#4, salary_category#59, 200), ENSURE_REQUIREMENTS, [plan_id=99]\n",
            "   +- *(1) HashAggregate(keys=[department#4, salary_category#59], functions=[partial_sum(salary#3), partial_avg(age#2), partial_count(1)], output=[department#4, salary_categ...\n",
            "\n",
            "==================================================\n",
            "DAG EXTRACTION COMPLETE\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Function to prepare LLM prompt**"
      ],
      "metadata": {
        "id": "zRpufa4dOxih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_llm_prompt(transformation_data):\n",
        "    \"\"\"Prepare structured prompt for LLM to extract column lineage\"\"\"\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    Analyze this Spark transformation and extract column lineage:\n",
        "\n",
        "    Transformation Type: {transformation_data['context']['transformation_type']}\n",
        "    Input Columns: {transformation_data['context']['input_columns']}\n",
        "    Output Columns: {transformation_data['context']['output_columns']}\n",
        "    New Columns: {transformation_data['context']['new_columns']}\n",
        "\n",
        "    Logical Plan:\n",
        "    {transformation_data['dag_info']['logical_plan'][:800]}\n",
        "\n",
        "    Extract column lineage in this format:\n",
        "    {{\n",
        "        \"lineage\": [\n",
        "            {{\"source_columns\": [\"col1\", \"col2\"], \"target_column\": \"derived_col\", \"operation\": \"concat\"}},\n",
        "            {{\"source_columns\": [\"col3\"], \"target_column\": \"derived_col2\", \"operation\": \"case_when\"}}\n",
        "        ]\n",
        "    }}\n",
        "    \"\"\"\n",
        "\n",
        "    return prompt"
      ],
      "metadata": {
        "id": "6NbQuamUODXc"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_prompt = prepare_llm_prompt(llm_input_data[\"transformations\"][0])"
      ],
      "metadata": {
        "id": "L4dfMY-EO2pR"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "H3I-zIBLO8gj",
        "outputId": "26aa8280-f090-48d2-989a-0dca4c76d1f8"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n    Analyze this Spark transformation and extract column lineage:\\n\\n    Transformation Type: column_derivation\\n    Input Columns: [\\'first_name\\', \\'last_name\\', \\'age\\', \\'salary\\', \\'department\\']\\n    Output Columns: [\\'first_name\\', \\'last_name\\', \\'age\\', \\'salary\\', \\'department\\', \\'full_name\\', \\'salary_category\\', \\'age_group\\']\\n    New Columns: [\\'full_name\\', \\'salary_category\\', \\'age_group\\']\\n\\n    Logical Plan:\\n    == Analyzed Logical Plan ==\\nfirst_name: string, last_name: string, age: int, salary: double, department: string, full_name: string, salary_category: string, age_group: string\\nProject [first_name#0, last_name#1, age#2, salary#3, department#4, full_name#52, salary_category#59, CASE WHEN (age#2 < 30) THEN Young ELSE Senior END AS age_group#67]\\n+- Project [first_name#0, last_name#1, age#2, salary#3, department#4, full_name#52, CASE WHEN (salary#3 > cast(70000 as double)) THEN High WHEN (salary#3 > cast(50000 as double)) THEN Medium ELSE Low END AS salary_category#59]\\n   +- Project [first_name#0, last_name#1, age#2, salary#3, department#4, concat(first_name#0,  , last_name#1) AS full_name#52]\\n      +- LogicalRDD [first_name#0, last_name#1, age#2, salary#3, department#4], false\\n\\n== Optimized Log\\n\\n    Extract column lineage in this format:\\n    {\\n        \"lineage\": [\\n            {\"source_columns\": [\"col1\", \"col2\"], \"target_column\": \"derived_col\", \"operation\": \"concat\"},\\n            {\"source_columns\": [\"col3\"], \"target_column\": \"derived_col2\", \"operation\": \"case_when\"}\\n        ]\\n    }\\n    '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LLMA model**"
      ],
      "metadata": {
        "id": "7C9tqXi3qFZ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers==4.36.0 torch accelerate bitsandbytes"
      ],
      "metadata": {
        "id": "nSKY69DGqHFX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c280341-93df-4ff5-ed28-d42b1c670470"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers==4.36.0\n",
            "  Downloading transformers-4.36.0-py3-none-any.whl.metadata (126 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/126.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.8/126.8 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.8.1)\n",
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.46.1-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.36.0) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.11/dist-packages (from transformers==4.36.0) (0.33.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.36.0) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.36.0) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.36.0) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.36.0) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.36.0) (2.32.3)\n",
            "Collecting tokenizers<0.19,>=0.14 (from transformers==4.36.0)\n",
            "  Downloading tokenizers-0.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.36.0) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.36.0) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.36.0) (1.1.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.36.0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.36.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.36.0) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.36.0) (2025.6.15)\n",
            "Downloading transformers-4.36.0-py3-none-any.whl (8.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m126.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m108.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m94.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m56.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m110.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bitsandbytes-0.46.1-py3-none-manylinux_2_24_x86_64.whl (72.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.9/72.9 MB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m110.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, tokenizers, nvidia-cusolver-cu12, transformers, bitsandbytes\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.21.2\n",
            "    Uninstalling tokenizers-0.21.2:\n",
            "      Successfully uninstalled tokenizers-0.21.2\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.53.0\n",
            "    Uninstalling transformers-4.53.0:\n",
            "      Successfully uninstalled transformers-4.53.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "sentence-transformers 4.1.0 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.36.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed bitsandbytes-0.46.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 tokenizers-0.15.2 transformers-4.36.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "import re\n",
        "\n"
      ],
      "metadata": {
        "id": "1yCQln12qHYw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d9aa40f-d85a-4fa4-df89-3dcd8c79f75f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  _torch_pytree._register_pytree_node(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "from huggingface_hub import login\n",
        "\n",
        "token = userdata.get('HF_TOKEN')\n",
        "login(token=token, add_to_git_credential=False)"
      ],
      "metadata": {
        "id": "l21xXyDrFe0Q"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model loading**"
      ],
      "metadata": {
        "id": "__A-MtqsyNCa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Loading CodeLlama model...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/CodeLlama-7b-Instruct-hf\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"meta-llama/CodeLlama-7b-Instruct-hf\",\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\",\n",
        "    load_in_8bit=True  # For Colab memory optimization\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262,
          "referenced_widgets": [
            "3bdc539b20f44af4a24da2fcc2ccc185",
            "e1ddb276f95948f49b9d5d0139cae186",
            "6b670c08f1e448ccb61458241695de19",
            "751fb5ba4d9c488cb18646ea30f3995c",
            "f3649e8661b842a882cd2bde3fbcefdb",
            "d10957f7c6504bc8b5f3e213ecc29046",
            "44d6e57752074d8896b4cc305872dbe5",
            "3f6473f97ca94deba47e36c6f02c6b96",
            "1bb9707f848f44ea985eabd7c9ef7dad",
            "558b9c3e4264467cbde59a42b46018e6",
            "cfd75aa34d9e4495be158f2ab3e35d37",
            "2b8d50eb0cae48429c194ce073d9b813",
            "e662de39b84f4533ba93f628de8e20c6",
            "401235cb9fb2455f8542ce21b7c04d91",
            "c66a3ae3384a4d21872deb76884ba63c",
            "d943ab5028024f20b319c20ae45c37fc",
            "f73be49ffcd64246af756efa7cf3f53b",
            "36449dc2e9cd4059818be6ab8be5660a",
            "389bc5eaa8e54a458013101f2e0ee6ff",
            "1b090acd5191486a9348040795f5c50b",
            "d89fb4b35c8447f8bcc915ac24099a23",
            "48ad18498d294971a81f1eea80a0a282"
          ]
        },
        "id": "lbkKHWJ4x9W9",
        "outputId": "d66ccdab-c28b-4321-f3c7-adf6a21a1980"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading CodeLlama model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3bdc539b20f44af4a24da2fcc2ccc185"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2b8d50eb0cae48429c194ce073d9b813"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def process_prompt_with_codellama(prompt):\n",
        "    \"\"\"Process prompt through CodeLlama\"\"\"\n",
        "    formatted_prompt = f\"<s>[INST] {prompt.strip()} [/INST]\"\n",
        "\n",
        "    inputs = tokenizer(formatted_prompt, return_tensors=\"pt\", truncation=True, max_length=2048)\n",
        "\n",
        "    # Move inputs to GPU\n",
        "    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            inputs['input_ids'],\n",
        "            max_new_tokens=512,\n",
        "            temperature=0.1,\n",
        "            do_sample=True,\n",
        "            pad_token_id=tokenizer.eos_token_id\n",
        "        )\n",
        "\n",
        "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    response_start = response.find(\"[/INST]\") + 7\n",
        "    return response[response_start:].strip()"
      ],
      "metadata": {
        "id": "wjrC_RnDyPyz"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_response = process_prompt_with_codellama(sample_prompt)\n",
        "print(\"LLM Response:\", test_response[:200])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvwjvUap5ETz",
        "outputId": "277ddb3b-f981-4798-c803-822e7b1d1674"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LLM Response: The column lineage for this Spark transformation can be extracted as follows:\n",
            "\n",
            "{\n",
            "    \"lineage\": [\n",
            "        {\"source_columns\": [\"first_name\", \"last_name\"], \"target_column\": \"full_name\", \"operation\": \"co\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "RjGYAgk-5Foe",
        "outputId": "68ebf93c-22cb-4841-c551-f1ba609d0192"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n    Analyze this Spark transformation and extract column lineage:\\n\\n    Transformation Type: column_derivation\\n    Input Columns: [\\'first_name\\', \\'last_name\\', \\'age\\', \\'salary\\', \\'department\\']\\n    Output Columns: [\\'first_name\\', \\'last_name\\', \\'age\\', \\'salary\\', \\'department\\', \\'full_name\\', \\'salary_category\\', \\'age_group\\']\\n    New Columns: [\\'age_group\\', \\'full_name\\', \\'salary_category\\']\\n\\n    Logical Plan:\\n    == Analyzed Logical Plan ==\\nfirst_name: string, last_name: string, age: int, salary: double, department: string, full_name: string, salary_category: string, age_group: string\\nProject [first_name#0, last_name#1, age#2, salary#3, department#4, full_name#52, salary_category#59, CASE WHEN (age#2 < 30) THEN Young ELSE Senior END AS age_group#67]\\n+- Project [first_name#0, last_name#1, age#2, salary#3, department#4, full_name#52, CASE WHEN (salary#3 > cast(70000 as double)) THEN High WHEN (salary#3 > cast(50000 as double)) THEN Medium ELSE Low END AS salary_category#59]\\n   +- Project [first_name#0, last_name#1, age#2, salary#3, department#4, concat(first_name#0,  , last_name#1) AS full_name#52]\\n      +- LogicalRDD [first_name#0, last_name#1, age#2, salary#3, department#4], false\\n\\n== Optimized Log\\n\\n    Extract column lineage in this format:\\n    {\\n        \"lineage\": [\\n            {\"source_columns\": [\"col1\", \"col2\"], \"target_column\": \"derived_col\", \"operation\": \"concat\"},\\n            {\"source_columns\": [\"col3\"], \"target_column\": \"derived_col2\", \"operation\": \"case_when\"}\\n        ]\\n    }\\n    '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "TLBNIsTS5hgA",
        "outputId": "2b6fdb96-bffc-4c6b-8577-37ce01fc2840"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The column lineage for this Spark transformation can be extracted as follows:\\n\\n{\\n    \"lineage\": [\\n        {\"source_columns\": [\"first_name\", \"last_name\"], \"target_column\": \"full_name\", \"operation\": \"concat\"},\\n        {\"source_columns\": [\"salary\"], \"target_column\": \"salary_category\", \"operation\": \"case_when\"},\\n        {\"source_columns\": [\"age\"], \"target_column\": \"age_group\", \"operation\": \"case_when\"}\\n    ]\\n}\\n\\nHere, we have three column derivations:\\n\\n1. The \"full_name\" column is derived from the \"first_name\" and \"last_name\" columns using the \"concat\" operation.\\n2. The \"salary_category\" column is derived from the \"salary\" column using the \"case_when\" operation.\\n3. The \"age_group\" column is derived from the \"age\" column using the \"case_when\" operation.\\n\\nNote that the \"case_when\" operation is used for both the \"salary_category\" and \"age_group\" columns, but the source columns and the target column names are different for each operation.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    }
  ]
}