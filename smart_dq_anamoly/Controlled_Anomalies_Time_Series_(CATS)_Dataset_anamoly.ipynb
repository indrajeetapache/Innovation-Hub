{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**sample data set downloaded from this **\n",
        "[link text](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud/data)"
      ],
      "metadata": {
        "id": "jqCkBgFp6-_6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**install required lib**"
      ],
      "metadata": {
        "id": "kE0Q_JnLjXHY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q kaggle\n",
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "os.environ[\"KAGGLE_USERNAME\"] = userdata.get('KAGGLE_USERNAME')\n",
        "os.environ[\"KAGGLE_KEY\"] = userdata.get('KAGGLE_KEY')"
      ],
      "metadata": {
        "id": "oez9vn37_5gy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gdrive_path=\"/content/drive/MyDrive/Anamolies/CATS_dataset\""
      ],
      "metadata": {
        "id": "fHobKzP37MWB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from datetime import datetime\n",
        "from typing import Dict, List, Optional, Any, Union\n",
        "import os\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "uwSaz-fNeW3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Read the sample data**"
      ],
      "metadata": {
        "id": "okeLS4XpeZcq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(gdrive_path+\"/data.csv\")"
      ],
      "metadata": {
        "id": "AeG9GfdCeYld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFs6EPgWfLr9",
        "outputId": "44dfabcc-8d70-4b5b-b0c2-0801c56f6f4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['timestamp', 'aimp', 'amud', 'arnd', 'asin1', 'asin2', 'adbr', 'adfl',\n",
              "       'bed1', 'bed2', 'bfo1', 'bfo2', 'bso1', 'bso2', 'bso3', 'ced1', 'cfo1',\n",
              "       'cso1', 'y', 'category'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Profiling**"
      ],
      "metadata": {
        "id": "mpduURs5jGyb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DataQualityProfiler:\n",
        "    \"\"\"\n",
        "    Dataset-level DQ metrics for anomaly detection\n",
        "    Approach: Column-wise metrics per day → detect corrupt datasets (not individual accounts)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, df):\n",
        "        print(\"Initializing DataQualityProfiler...\")\n",
        "        self.df = df.copy()\n",
        "        self.numeric_cols = ['aimp', 'amud', 'arnd', 'asin1', 'asin2', 'adbr', 'adfl',\n",
        "                            'bed1', 'bed2', 'bfo1', 'bfo2', 'bso1', 'bso2', 'bso3',\n",
        "                            'ced1', 'cfo1', 'cso1', 'y', 'category']\n",
        "        print(f\"Initialized with {len(self.df)} records, {len(self.numeric_cols)} numeric columns\")\n",
        "\n",
        "    def prepare_timestamp(self, timestamp_col='timestamp'):\n",
        "        \"\"\"Convert timestamp to yyyy-mm-dd format\"\"\"\n",
        "        print(f\"Converting {timestamp_col} to yyyy-mm-dd format...\")\n",
        "\n",
        "        if timestamp_col in self.df.columns:\n",
        "            self.df[timestamp_col] = pd.to_datetime(self.df[timestamp_col]).dt.date\n",
        "            unique_dates = self.df[timestamp_col].nunique()\n",
        "            print(f\"Converted timestamps - Found {unique_dates} unique dates\")\n",
        "        else:\n",
        "            print(\"No timestamp column found, creating synthetic dates\")\n",
        "\n",
        "        return self.df[timestamp_col].unique() if timestamp_col in self.df.columns else None\n",
        "\n",
        "    def calculate_basic_metrics(self, series, col_name, date):\n",
        "        \"\"\"Calculate basic statistical metrics with logging\"\"\"\n",
        "        print(f\"Basic metrics for {col_name} on {date}\")\n",
        "\n",
        "        return {\n",
        "            'Mean': series.mean(),\n",
        "            'Minimum': series.min(),\n",
        "            'Maximum': series.max(),\n",
        "            'StandardDeviation': series.std(),\n",
        "            'Sum': series.sum(),\n",
        "            'count': len(series),\n",
        "            'Completeness': series.notna().sum() / len(series),\n",
        "            'missingCount': series.isna().sum(),\n",
        "        }\n",
        "\n",
        "    def calculate_distribution_metrics(self, series, col_name, date):\n",
        "        \"\"\"Calculate distribution-based metrics with logging\"\"\"\n",
        "        print(f\"Distribution metrics for {col_name} on {date}\")\n",
        "\n",
        "        clean_series = series.dropna()\n",
        "\n",
        "        # Histogram calculation\n",
        "        try:\n",
        "            hist_counts, _ = np.histogram(clean_series, bins=10)\n",
        "            histogram_str = ','.join(map(str, hist_counts))\n",
        "        except:\n",
        "            histogram_str = \"0,0,0,0,0,0,0,0,0,0\"\n",
        "\n",
        "        # Data type inference\n",
        "        if pd.api.types.is_numeric_dtype(series):\n",
        "            data_type = \"INTEGER\" if pd.api.types.is_integer_dtype(series) else \"DECIMAL\"\n",
        "        elif pd.api.types.is_datetime64_any_dtype(series):\n",
        "            data_type = \"TIMESTAMP\"\n",
        "        elif pd.api.types.is_bool_dtype(series):\n",
        "            data_type = \"BOOLEAN\"\n",
        "        else:\n",
        "            data_type = \"STRING\"\n",
        "\n",
        "        return {\n",
        "            'zerocount': (clean_series == 0).sum(),\n",
        "            'zeroCount': (clean_series == 0).sum(),\n",
        "            'zerocountpercentage': ((clean_series == 0).sum() / len(clean_series)) * 100 if len(clean_series) > 0 else 0,\n",
        "            'negativecount': (clean_series < 0).sum(),\n",
        "            'negativeCount': (clean_series < 0).sum(),\n",
        "            'negativecountpercentage': ((clean_series < 0).sum() / len(clean_series)) * 100 if len(clean_series) > 0 else 0,\n",
        "            'CountDistinct': clean_series.nunique(),\n",
        "            'Uniqueness': clean_series.nunique() / len(clean_series) if len(clean_series) > 0 else 0,\n",
        "            'UniqueValueRatio': clean_series.nunique() / len(clean_series) if len(clean_series) > 0 else 0,\n",
        "            'Distinctness': clean_series.nunique() / len(clean_series) if len(clean_series) > 0 else 0,\n",
        "            'Histogram': histogram_str,\n",
        "            'DataType': data_type,\n",
        "        }\n",
        "\n",
        "    def calculate_quantiles(self, series, col_name, date):\n",
        "        \"\"\"Calculate approximate quantiles with logging\"\"\"\n",
        "        print(f\"Quantile metrics for {col_name} on {date}\")\n",
        "\n",
        "        clean_series = series.dropna()\n",
        "        if len(clean_series) == 0:\n",
        "            return {\n",
        "                'ApproxQuantiles_0.1': 0, 'ApproxQuantiles_0.25': 0, 'ApproxQuantiles_0.5': 0,\n",
        "                'ApproxQuantiles_0.75': 0, 'ApproxQuantiles_0.9': 0\n",
        "            }\n",
        "\n",
        "        return {\n",
        "            'ApproxQuantiles_0.1': clean_series.quantile(0.1),\n",
        "            'ApproxQuantiles_0.25': clean_series.quantile(0.25),\n",
        "            'ApproxQuantiles_0.5': clean_series.quantile(0.5),\n",
        "            'ApproxQuantiles_0.75': clean_series.quantile(0.75),\n",
        "            'ApproxQuantiles_0.9': clean_series.quantile(0.9),\n",
        "        }\n",
        "\n",
        "    def calculate_entropy(self, series, col_name, date):\n",
        "        \"\"\"Calculate Shannon entropy with logging\"\"\"\n",
        "        print(f\"Entropy calculation for {col_name} on {date}\")\n",
        "\n",
        "        clean_series = series.dropna()\n",
        "        if len(clean_series) == 0:\n",
        "            return 0\n",
        "\n",
        "        try:\n",
        "            bins = min(50, len(clean_series.unique()))\n",
        "            hist, _ = np.histogram(clean_series, bins=bins)\n",
        "            hist = hist[hist > 0]\n",
        "            probs = hist / hist.sum()\n",
        "            entropy = -np.sum(probs * np.log2(probs))\n",
        "            print(f\"Entropy calculated: {entropy:.3f}\")\n",
        "            return entropy\n",
        "        except:\n",
        "            print(f\"Entropy calculation failed for {col_name}\")\n",
        "            return 0\n",
        "\n",
        "    def calculate_correlation_matrix(self, day_data, date):\n",
        "        \"\"\"Calculate correlation matrix for the day with logging\"\"\"\n",
        "        print(f\"Correlation matrix for {date}\")\n",
        "\n",
        "        available_cols = [col for col in self.numeric_cols if col in day_data.columns]\n",
        "        if len(available_cols) < 2:\n",
        "            return pd.DataFrame()\n",
        "\n",
        "        corr_matrix = day_data[available_cols].corr()\n",
        "        print(f\"Correlation matrix calculated for {len(available_cols)} columns\")\n",
        "        return corr_matrix\n",
        "\n",
        "    def calculate_mutual_information(self, col1_data, col2_data, col1, col2, date):\n",
        "        \"\"\"Calculate mutual information with logging\"\"\"\n",
        "        print(f\"Mutual information: {col1} vs {col2} on {date}\")\n",
        "\n",
        "        try:\n",
        "            x_binned = pd.cut(col1_data.dropna(), bins=10, labels=False)\n",
        "            y_binned = pd.cut(col2_data.dropna(), bins=10, labels=False)\n",
        "\n",
        "            # Align the series\n",
        "            min_len = min(len(x_binned), len(y_binned))\n",
        "            x_binned = x_binned[:min_len]\n",
        "            y_binned = y_binned[:min_len]\n",
        "\n",
        "            contingency = pd.crosstab(x_binned, y_binned)\n",
        "\n",
        "            mi = 0\n",
        "            total = contingency.sum().sum()\n",
        "\n",
        "            for i in range(contingency.shape[0]):\n",
        "                for j in range(contingency.shape[1]):\n",
        "                    if contingency.iloc[i, j] > 0:\n",
        "                        pxy = contingency.iloc[i, j] / total\n",
        "                        px = contingency.iloc[i, :].sum() / total\n",
        "                        py = contingency.iloc[:, j].sum() / total\n",
        "                        mi += pxy * np.log2(pxy / (px * py))\n",
        "\n",
        "            print(f\"MI calculated: {mi:.3f}\")\n",
        "            return mi\n",
        "        except Exception as e:\n",
        "            print(f\"MI calculation failed: {str(e)}\")\n",
        "            return 0\n",
        "\n",
        "    def profile_dataset_daily(self, timestamp_col='timestamp'):\n",
        "        \"\"\"\n",
        "        Profile dataset column-wise per day for dataset-level anomaly detection\n",
        "        Returns: One row per date with aggregated column metrics\n",
        "        \"\"\"\n",
        "        print(\"Starting dataset-level daily profiling...\")\n",
        "\n",
        "        # Prepare timestamps\n",
        "        dates = self.prepare_timestamp(timestamp_col)\n",
        "\n",
        "        if dates is None:\n",
        "            print(\"No valid dates found\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "        features_list = []\n",
        "\n",
        "        for date_idx, date in enumerate(sorted(dates)):\n",
        "            print(f\"Processing date {date_idx + 1}/{len(dates)}: {date}\")\n",
        "\n",
        "            # Get all data for this date\n",
        "            if timestamp_col in self.df.columns:\n",
        "                day_data = self.df[self.df[timestamp_col] == date]\n",
        "            else:\n",
        "                # Fallback to chunking\n",
        "                start_idx = date_idx * 1000\n",
        "                end_idx = min(start_idx + 1000, len(self.df))\n",
        "                day_data = self.df.iloc[start_idx:end_idx]\n",
        "\n",
        "            if len(day_data) == 0:\n",
        "                print(f\"No data for {date}\")\n",
        "                continue\n",
        "\n",
        "            print(f\"Processing {len(day_data)} records\")\n",
        "\n",
        "            # Initialize daily features\n",
        "            daily_features = {\n",
        "                'date': str(date),\n",
        "                'total_records': len(day_data),\n",
        "                'dataset_completeness': day_data.notna().sum().sum() / (len(day_data) * len(self.numeric_cols))\n",
        "            }\n",
        "\n",
        "            # Calculate correlation matrix for the day\n",
        "            corr_matrix = self.calculate_correlation_matrix(day_data, date)\n",
        "\n",
        "            # Process each column\n",
        "            for col in self.numeric_cols:\n",
        "                if col not in day_data.columns:\n",
        "                    print(f\"Column {col} not found\")\n",
        "                    continue\n",
        "\n",
        "                print(f\"Processing column: {col}\")\n",
        "                series = day_data[col]\n",
        "\n",
        "                # Basic metrics\n",
        "                basic_metrics = self.calculate_basic_metrics(series, col, date)\n",
        "                for metric, value in basic_metrics.items():\n",
        "                    daily_features[f\"{col}_{metric}\"] = value\n",
        "\n",
        "                # Distribution metrics\n",
        "                dist_metrics = self.calculate_distribution_metrics(series, col, date)\n",
        "                for metric, value in dist_metrics.items():\n",
        "                    daily_features[f\"{col}_{metric}\"] = value\n",
        "\n",
        "                # Quantiles\n",
        "                quantile_metrics = self.calculate_quantiles(series, col, date)\n",
        "                for metric, value in quantile_metrics.items():\n",
        "                    daily_features[f\"{col}_{metric}\"] = value\n",
        "\n",
        "                # Entropy\n",
        "                daily_features[f\"{col}_Entropy\"] = self.calculate_entropy(series, col, date)\n",
        "\n",
        "                # Size metrics\n",
        "                daily_features[f\"{col}_Size\"] = len(series)\n",
        "                if series.dtype == 'object':\n",
        "                    daily_features[f\"{col}_MaxLength\"] = series.astype(str).str.len().max()\n",
        "                    daily_features[f\"{col}_MinLength\"] = series.astype(str).str.len().min()\n",
        "                else:\n",
        "                    daily_features[f\"{col}_MaxLength\"] = 0\n",
        "                    daily_features[f\"{col}_MinLength\"] = 0\n",
        "\n",
        "                # Correlation with other columns\n",
        "                if not corr_matrix.empty and col in corr_matrix.columns:\n",
        "                    for other_col in self.numeric_cols[:5]:  # Limit correlations\n",
        "                        if other_col != col and other_col in corr_matrix.columns:\n",
        "                            daily_features[f\"{col}_Correlation_{other_col}\"] = corr_matrix.loc[col, other_col]\n",
        "\n",
        "                # Mutual information with first column\n",
        "                if col != self.numeric_cols[0] and self.numeric_cols[0] in day_data.columns:\n",
        "                    mi_value = self.calculate_mutual_information(\n",
        "                        day_data[col], day_data[self.numeric_cols[0]], col, self.numeric_cols[0], date\n",
        "                    )\n",
        "                    daily_features[f\"{col}_MutualInformation\"] = mi_value\n",
        "\n",
        "            features_list.append(daily_features)\n",
        "            print(f\"Completed {date} - Generated {len(daily_features)} features\")\n",
        "\n",
        "            # Limit for demo\n",
        "            if len(features_list) >= 180:\n",
        "                break\n",
        "\n",
        "        result_df = pd.DataFrame(features_list)\n",
        "        print(f\"Profiling complete! Generated {result_df.shape[0]} days × {result_df.shape[1]} features\")\n",
        "        return result_df"
      ],
      "metadata": {
        "id": "CulorO9xJyJx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Z score calculation**"
      ],
      "metadata": {
        "id": "c_7VhzP_J5eL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_features_for_model(df, zscore_threshold=3.0, target_cols=None, enhanced=False):\n",
        "    \"\"\"Main function to prepare dataset-level features for anomaly detection\"\"\"\n",
        "    print(\"DATASET-LEVEL ANOMALY DETECTION FEATURE PREPARATION\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Initialize profiler\n",
        "    profiler = DataQualityProfiler(df)\n",
        "\n",
        "    # Generate base features (daily dataset profiles)\n",
        "    print(\"\\n STEP 1: Calculating daily DQ metrics...\")\n",
        "    feature_df = profiler.profile_dataset_daily()\n",
        "\n",
        "    if feature_df.empty:\n",
        "        print(\"No features generated\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    # Add rolling window features with z-scores\n",
        "    print(\"\\n  STEP 2: Creating rolling features...\")\n",
        "    final_features = create_rolling_features(feature_df)\n",
        "\n",
        "    # Handle null values for ML models\n",
        "    print(\"\\n STEP 3: Handling null values...\")\n",
        "    final_features = handle_nulls_for_ml(final_features)\n",
        "\n",
        "    if enhanced:\n",
        "        # Enhanced feature engineering for LSTM\n",
        "        print(f\"\\n STEP 4: Enhanced feature engineering (threshold={zscore_threshold})...\")\n",
        "        feature_engineer = FeatureEngineer(zscore_threshold=zscore_threshold)\n",
        "        final_features = feature_engineer.create_features(\n",
        "            final_features,\n",
        "            process_date_col='date',\n",
        "            target_cols=target_cols\n",
        "        )\n",
        "\n",
        "    print(f\"\\nFEATURE PREPARATION COMPLETE!\")\n",
        "    print(f\" Final shape: {final_features.shape[0]} days × {final_features.shape[1]} features\")\n",
        "    print(f\" Ready for dataset-level anomaly detection\")\n",
        "\n",
        "    return final_features"
      ],
      "metadata": {
        "id": "FOFPHahlAglB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create Lag features**"
      ],
      "metadata": {
        "id": "DPodHHqpSP0L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_lag_features(feature_df, lag_features=[1, 2, 3], base_columns_only=True):\n",
        "    \"\"\"Create lag features on base columns only (not derived features)\"\"\"\n",
        "    print(f\" Creating lag features: {lag_features}\")\n",
        "\n",
        "    feature_df = feature_df.sort_values('date').reset_index(drop=True)\n",
        "\n",
        "    if base_columns_only:\n",
        "        # Exclude derived features - only base columns\n",
        "        derived_suffixes = ['_rolling_', '_zscore_', '_anomaly_', '_diff_', '_ratio_', '_trend_', '_mean', '_std', '_min', '_max']\n",
        "        base_columns = [col for col in feature_df.columns\n",
        "                       if col != 'date' and not any(suffix in col for suffix in derived_suffixes)]\n",
        "    else:\n",
        "        base_columns = [col for col in feature_df.columns if col != 'date']\n",
        "\n",
        "    result_df = feature_df.copy()\n",
        "\n",
        "    for lag in lag_features:\n",
        "        for col in base_columns:\n",
        "            if pd.api.types.is_numeric_dtype(feature_df[col]):\n",
        "                # Create lag feature\n",
        "                result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
        "                # Create difference from lag\n",
        "                result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
        "\n",
        "    # Fill NaN values from shifting\n",
        "    lag_cols = [col for col in result_df.columns if '_lag_' in col]\n",
        "    result_df[lag_cols] = result_df[lag_cols].fillna(0)\n",
        "\n",
        "    new_features = len(result_df.columns) - len(feature_df.columns)\n",
        "    print(f\" Added {new_features} lag features\")\n",
        "\n",
        "    return result_df"
      ],
      "metadata": {
        "id": "7hyyeoX7SUU_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Rolling feature**"
      ],
      "metadata": {
        "id": "xXx72vHYIP4c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_rolling_features(feature_df, windows=[7, 14, 30, 90]):\n",
        "    \"\"\"Create rolling window features for temporal analysis\"\"\"\n",
        "    print(f\"\\n Creating rolling features with windows: {windows}\")\n",
        "\n",
        "    feature_df = feature_df.sort_values('date').reset_index(drop=True)\n",
        "    numeric_features = [col for col in feature_df.columns if col not in ['date']]\n",
        "\n",
        "    # Use list to collect DataFrames, then concat once\n",
        "    rolling_dfs = [feature_df]\n",
        "\n",
        "    for window in windows:\n",
        "        print(f\"   Processing {window}-day rolling window...\")\n",
        "        window_features = {}\n",
        "\n",
        "        for feature in numeric_features:\n",
        "            if feature_df[feature].dtype in ['float64', 'int64']:\n",
        "                # Calculate all rolling stats at once\n",
        "                rolling_data = feature_df[feature].rolling(window)\n",
        "                rolling_mean = rolling_data.mean()\n",
        "                rolling_std = rolling_data.std()\n",
        "\n",
        "                window_features[f\"{feature}_rolling_{window}d_mean\"] = rolling_mean\n",
        "                window_features[f\"{feature}_rolling_{window}d_std\"] = rolling_std\n",
        "                window_features[f\"{feature}_rolling_{window}d_min\"] = rolling_data.min()\n",
        "                window_features[f\"{feature}_rolling_{window}d_max\"] = rolling_data.max()\n",
        "\n",
        "                # Z-score features (current vs rolling window)\n",
        "                current_value = feature_df[feature]\n",
        "                window_features[f\"{feature}_zscore_{window}d\"] = (\n",
        "                    (current_value - rolling_mean) / (rolling_std + 1e-8)\n",
        "                )\n",
        "\n",
        "                # Anomaly flags based on z-score threshold\n",
        "                zscore_col = f\"{feature}_zscore_{window}d\"\n",
        "                window_features[f\"{feature}_anomaly_{window}d\"] = (\n",
        "                    window_features[zscore_col].abs() > 3.0\n",
        "                ).astype(int)\n",
        "\n",
        "                # Trend features\n",
        "                window_features[f\"{feature}_trend_{window}d\"] = rolling_data.apply(\n",
        "                    lambda x: np.polyfit(range(len(x)), x, 1)[0] if len(x) == window else 0\n",
        "                )\n",
        "\n",
        "                # Difference from rolling mean\n",
        "                window_features[f\"{feature}_diff_{window}d\"] = current_value - rolling_mean\n",
        "\n",
        "                # Ratio to rolling mean\n",
        "                window_features[f\"{feature}_ratio_{window}d\"] = (\n",
        "                    current_value / (rolling_mean + 1e-8)\n",
        "                )\n",
        "\n",
        "        # Add window features as DataFrame\n",
        "        rolling_dfs.append(pd.DataFrame(window_features))\n",
        "\n",
        "    # Concatenate all at once\n",
        "    rolling_features = pd.concat(rolling_dfs, axis=1)\n",
        "    print(f\" Rolling features created: {rolling_features.shape[1]} total features\")\n",
        "    return rolling_features\n"
      ],
      "metadata": {
        "id": "Wa43eDyVIVEq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Enhanced feature engineering**"
      ],
      "metadata": {
        "id": "gwGTGu38H_m8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FeatureEngineer:\n",
        "    \"\"\"Enhanced feature engineering for LSTM anomaly detection\"\"\"\n",
        "\n",
        "    def __init__(self, zscore_threshold=3.0):\n",
        "        self.zscore_threshold = zscore_threshold\n",
        "        print(f\"[INIT] FeatureEngineer with threshold={zscore_threshold}\")\n",
        "\n",
        "    def create_features(self, profile_df, process_date_col='date', target_cols=None):\n",
        "        \"\"\"Create LSTM-optimized features\"\"\"\n",
        "        print(f\"[FEATURES] Enhancing {profile_df.shape[1]} features for LSTM\")\n",
        "\n",
        "        result_df = profile_df.copy()\n",
        "\n",
        "        # Find profile columns\n",
        "        profile_cols = [col for col in profile_df.columns if any(\n",
        "            suffix in col for suffix in ['_zscore_', '_anomaly_', '_diff_', '_ratio_']\n",
        "        )]\n",
        "\n",
        "        # Create combined anomaly scores\n",
        "        result_df = self._create_combined_scores(result_df, profile_cols)\n",
        "\n",
        "        # Add time features\n",
        "        result_df = self._add_time_features(result_df, process_date_col)\n",
        "\n",
        "        # Target-specific features\n",
        "        if target_cols:\n",
        "            result_df = self._create_target_features(result_df, target_cols)\n",
        "\n",
        "        print(f\"[COMPLETE] Added {result_df.shape[1] - profile_df.shape[1]} enhanced features\")\n",
        "        return result_df\n",
        "\n",
        "    def _create_combined_scores(self, df, profile_cols):\n",
        "        \"\"\"Combined anomaly scores across windows\"\"\"\n",
        "        result_df = df.copy()\n",
        "\n",
        "        # Get base feature names\n",
        "        base_features = set()\n",
        "        for col in profile_cols:\n",
        "            if '_zscore_' in col:\n",
        "                base_name = col.split('_zscore_')[0]\n",
        "                base_features.add(base_name)\n",
        "\n",
        "        print(f\"[COMBINED] Creating scores for {len(base_features)} features\")\n",
        "\n",
        "        for base in list(base_features)[:10]:  # Limit for performance\n",
        "            zscore_cols = [col for col in profile_cols if col.startswith(f\"{base}_zscore_\")]\n",
        "\n",
        "            if len(zscore_cols) > 1:\n",
        "                # Combined anomaly score (max absolute z-score across windows)\n",
        "                result_df[f\"{base}_max_zscore\"] = df[zscore_cols].abs().max(axis=1)\n",
        "\n",
        "                # Combined flag\n",
        "                result_df[f\"{base}_any_anomaly\"] = (\n",
        "                    result_df[f\"{base}_max_zscore\"] > self.zscore_threshold\n",
        "                ).astype(int)\n",
        "\n",
        "        return result_df\n",
        "\n",
        "    def _add_time_features(self, df, date_col):\n",
        "        \"\"\"Calendar features for LSTM temporal patterns\"\"\"\n",
        "        result_df = df.copy()\n",
        "\n",
        "        if date_col in df.columns:\n",
        "            result_df[date_col] = pd.to_datetime(result_df[date_col])\n",
        "            result_df['day_of_week'] = result_df[date_col].dt.dayofweek\n",
        "            result_df['is_month_end'] = result_df[date_col].dt.is_month_end.astype(int)\n",
        "            result_df['is_quarter_end'] = result_df[date_col].dt.is_quarter_end.astype(int)\n",
        "\n",
        "        return result_df\n",
        "\n",
        "    def _create_target_features(self, df, target_cols):\n",
        "        \"\"\"Target-specific aggregated features\"\"\"\n",
        "        result_df = df.copy()\n",
        "\n",
        "        for target in target_cols:\n",
        "            anomaly_flags = [col for col in df.columns if f\"{target}_anomaly_\" in col]\n",
        "\n",
        "            if anomaly_flags:\n",
        "                result_df[f\"{target}_total_anomalies\"] = result_df[anomaly_flags].sum(axis=1)\n",
        "                result_df[f\"{target}_any_anomaly\"] = result_df[anomaly_flags].max(axis=1)\n",
        "\n",
        "        return result_df\n",
        "\n",
        "def handle_nulls_for_ml(df):\n",
        "    \"\"\"Handle null values for LSTM/PyOD models\"\"\"\n",
        "    print(f\"   Input shape: {df.shape}\")\n",
        "\n",
        "    # 1. Drop columns where ALL values are null\n",
        "    all_null_cols = df.columns[df.isnull().all()].tolist()\n",
        "    if all_null_cols:\n",
        "        print(f\"    Dropping {len(all_null_cols)} all-null columns: {all_null_cols[:5]}...\")\n",
        "        df = df.drop(columns=all_null_cols)\n",
        "\n",
        "    # 2. Drop columns with >95% nulls as most of the population is null\n",
        "    high_null_cols = df.columns[df.isnull().mean() > 0.95].tolist()\n",
        "    if high_null_cols:\n",
        "        print(f\"    Dropping {len(high_null_cols)} high-null columns (>95%): {high_null_cols[:5]}...\")\n",
        "        df = df.drop(columns=high_null_cols)\n",
        "\n",
        "    # 3. Fill remaining nulls\n",
        "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
        "    non_numeric_cols = [col for col in df.columns if col not in numeric_cols and col != 'date']\n",
        "\n",
        "    print(f\"   Filling nulls in {len(numeric_cols)} numeric columns...\")\n",
        "    df[numeric_cols] = df[numeric_cols].fillna(0)  # Fill with 0 for metrics\n",
        "\n",
        "    if non_numeric_cols:\n",
        "        print(f\"   Filling nulls in {len(non_numeric_cols)} non-numeric columns...\")\n",
        "        df[non_numeric_cols] = df[non_numeric_cols].fillna('unknown')\n",
        "\n",
        "    print(f\"   Final shape: {df.shape}\")\n",
        "    print(f\"   Remaining nulls: {df.isnull().sum().sum()}\")\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "A7rIczD5H_GV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Feature engineering main function**"
      ],
      "metadata": {
        "id": "MyBjTo35Ifpz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_features_for_model(df, zscore_threshold=3.0, target_cols=None, enhanced=False):\n",
        "    \"\"\"Main function to prepare dataset-level features for anomaly detection\"\"\"\n",
        "    print(\" DATASET-LEVEL ANOMALY DETECTION FEATURE PREPARATION\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Initialize profiler\n",
        "    profiler = DataQualityProfiler(df)\n",
        "\n",
        "    # Generate base features (daily dataset profiles)\n",
        "    print(\"\\n STEP 1: Calculating daily DQ metrics...\")\n",
        "    feature_df = profiler.profile_dataset_daily()\n",
        "\n",
        "    if feature_df.empty:\n",
        "        print(\" No features generated\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    # Add rolling window features with z-scores\n",
        "    print(\"\\n STEP 2: Creating rolling features...\")\n",
        "    final_features = create_rolling_features(feature_df)\n",
        "\n",
        "    print(\"\\n STEP 2.5: Creating lag features...\")\n",
        "    final_features = create_lag_features(\n",
        "        final_features,\n",
        "        lag_features=[1, 2, 3],\n",
        "        base_columns_only=True  # Only on base columns, not rolling features\n",
        "    )\n",
        "\n",
        "    # Handle null values for ML models\n",
        "    print(\"\\n STEP 3: Handling null values...\")\n",
        "    final_features = handle_nulls_for_ml(final_features)\n",
        "\n",
        "    if enhanced:\n",
        "        # Enhanced feature engineering for LSTM\n",
        "        print(f\"\\n STEP 4: Enhanced feature engineering (threshold={zscore_threshold})...\")\n",
        "        feature_engineer = FeatureEngineer(zscore_threshold=zscore_threshold)\n",
        "        final_features = feature_engineer.create_features(\n",
        "            final_features,\n",
        "            process_date_col='date',\n",
        "            target_cols=target_cols\n",
        "        )\n",
        "\n",
        "    print(f\"\\n FEATURE PREPARATION COMPLETE!\")\n",
        "    print(f\" Final shape: {final_features.shape[0]} days × {final_features.shape[1]} features\")\n",
        "    print(f\" Ready for dataset-level anomaly detection\")\n",
        "\n",
        "    return final_features"
      ],
      "metadata": {
        "id": "RYRp0O05IkWG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# USAGE:\n",
        "# df = pd.read_csv('cats_data.csv')\n",
        "# features = prepare_features_for_model(df)\n",
        "#\n",
        "# # For dataset-level anomaly detection\n",
        "# X = features.drop(['date'], axis=1).values\n",
        "# scaler = StandardScaler()\n",
        "# X_scaled = scaler.fit_transform(X)\n",
        "#\n",
        "# # Feed to your existing models\n",
        "# anomalous_dates = your_model.predict(X_scaled)"
      ],
      "metadata": {
        "id": "6RvC73mKKVsG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = prepare_features_for_model(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GkcxsJZauN5y",
        "outputId": "0e7398f8-1981-4fde-c2b3-6e221de708e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Mutual information: cfo1 vs aimp on 2023-01-26\n",
            "MI calculated: 0.000\n",
            "Processing column: cso1\n",
            "Basic metrics for cso1 on 2023-01-26\n",
            "Distribution metrics for cso1 on 2023-01-26\n",
            "Quantile metrics for cso1 on 2023-01-26\n",
            "Entropy calculation for cso1 on 2023-01-26\n",
            "Entropy calculated: 5.388\n",
            "Mutual information: cso1 vs aimp on 2023-01-26\n",
            "MI calculated: 0.000\n",
            "Processing column: y\n",
            "Basic metrics for y on 2023-01-26\n",
            "Distribution metrics for y on 2023-01-26\n",
            "Quantile metrics for y on 2023-01-26\n",
            "Entropy calculation for y on 2023-01-26\n",
            "Entropy calculated: 0.229\n",
            "Mutual information: y vs aimp on 2023-01-26\n",
            "MI calculated: 0.000\n",
            "Processing column: category\n",
            "Basic metrics for category on 2023-01-26\n",
            "Distribution metrics for category on 2023-01-26\n",
            "Quantile metrics for category on 2023-01-26\n",
            "Entropy calculation for category on 2023-01-26\n",
            "Entropy calculated: 0.250\n",
            "Mutual information: category vs aimp on 2023-01-26\n",
            "MI calculated: 0.000\n",
            "Completed 2023-01-26 - Generated 662 features\n",
            "Processing date 27/58: 2023-01-27\n",
            "Processing 86400 records\n",
            "Correlation matrix for 2023-01-27\n",
            "Correlation matrix calculated for 19 columns\n",
            "Processing column: aimp\n",
            "Basic metrics for aimp on 2023-01-27\n",
            "Distribution metrics for aimp on 2023-01-27\n",
            "Quantile metrics for aimp on 2023-01-27\n",
            "Entropy calculation for aimp on 2023-01-27\n",
            "Entropy calculated: 0.081\n",
            "Processing column: amud\n",
            "Basic metrics for amud on 2023-01-27\n",
            "Distribution metrics for amud on 2023-01-27\n",
            "Quantile metrics for amud on 2023-01-27\n",
            "Entropy calculation for amud on 2023-01-27\n",
            "Entropy calculated: 3.539\n",
            "Mutual information: amud vs aimp on 2023-01-27\n",
            "MI calculated: 0.000\n",
            "Processing column: arnd\n",
            "Basic metrics for arnd on 2023-01-27\n",
            "Distribution metrics for arnd on 2023-01-27\n",
            "Quantile metrics for arnd on 2023-01-27\n",
            "Entropy calculation for arnd on 2023-01-27\n",
            "Entropy calculated: 5.264\n",
            "Mutual information: arnd vs aimp on 2023-01-27\n",
            "MI calculated: 0.000\n",
            "Processing column: asin1\n",
            "Basic metrics for asin1 on 2023-01-27\n",
            "Distribution metrics for asin1 on 2023-01-27\n",
            "Quantile metrics for asin1 on 2023-01-27\n",
            "Entropy calculation for asin1 on 2023-01-27\n",
            "Entropy calculated: 4.979\n",
            "Mutual information: asin1 vs aimp on 2023-01-27\n",
            "MI calculated: 0.000\n",
            "Processing column: asin2\n",
            "Basic metrics for asin2 on 2023-01-27\n",
            "Distribution metrics for asin2 on 2023-01-27\n",
            "Quantile metrics for asin2 on 2023-01-27\n",
            "Entropy calculation for asin2 on 2023-01-27\n",
            "Entropy calculated: 5.364\n",
            "Mutual information: asin2 vs aimp on 2023-01-27\n",
            "MI calculated: 0.000\n",
            "Processing column: adbr\n",
            "Basic metrics for adbr on 2023-01-27\n",
            "Distribution metrics for adbr on 2023-01-27\n",
            "Quantile metrics for adbr on 2023-01-27\n",
            "Entropy calculation for adbr on 2023-01-27\n",
            "Entropy calculated: 0.999\n",
            "Mutual information: adbr vs aimp on 2023-01-27\n",
            "MI calculated: 0.000\n",
            "Processing column: adfl\n",
            "Basic metrics for adfl on 2023-01-27\n",
            "Distribution metrics for adfl on 2023-01-27\n",
            "Quantile metrics for adfl on 2023-01-27\n",
            "Entropy calculation for adfl on 2023-01-27\n",
            "Entropy calculated: 0.964\n",
            "Mutual information: adfl vs aimp on 2023-01-27\n",
            "MI calculated: 0.000\n",
            "Processing column: bed1\n",
            "Basic metrics for bed1 on 2023-01-27\n",
            "Distribution metrics for bed1 on 2023-01-27\n",
            "Quantile metrics for bed1 on 2023-01-27\n",
            "Entropy calculation for bed1 on 2023-01-27\n",
            "Entropy calculated: 4.689\n",
            "Mutual information: bed1 vs aimp on 2023-01-27\n",
            "MI calculated: 0.014\n",
            "Processing column: bed2\n",
            "Basic metrics for bed2 on 2023-01-27\n",
            "Distribution metrics for bed2 on 2023-01-27\n",
            "Quantile metrics for bed2 on 2023-01-27\n",
            "Entropy calculation for bed2 on 2023-01-27\n",
            "Entropy calculated: 2.755\n",
            "Mutual information: bed2 vs aimp on 2023-01-27\n",
            "MI calculated: 0.046\n",
            "Processing column: bfo1\n",
            "Basic metrics for bfo1 on 2023-01-27\n",
            "Distribution metrics for bfo1 on 2023-01-27\n",
            "Quantile metrics for bfo1 on 2023-01-27\n",
            "Entropy calculation for bfo1 on 2023-01-27\n",
            "Entropy calculated: 4.686\n",
            "Mutual information: bfo1 vs aimp on 2023-01-27\n",
            "MI calculated: 0.000\n",
            "Processing column: bfo2\n",
            "Basic metrics for bfo2 on 2023-01-27\n",
            "Distribution metrics for bfo2 on 2023-01-27\n",
            "Quantile metrics for bfo2 on 2023-01-27\n",
            "Entropy calculation for bfo2 on 2023-01-27\n",
            "Entropy calculated: 5.256\n",
            "Mutual information: bfo2 vs aimp on 2023-01-27\n",
            "MI calculated: 0.000\n",
            "Processing column: bso1\n",
            "Basic metrics for bso1 on 2023-01-27\n",
            "Distribution metrics for bso1 on 2023-01-27\n",
            "Quantile metrics for bso1 on 2023-01-27\n",
            "Entropy calculation for bso1 on 2023-01-27\n",
            "Entropy calculated: 4.496\n",
            "Mutual information: bso1 vs aimp on 2023-01-27\n",
            "MI calculated: 0.000\n",
            "Processing column: bso2\n",
            "Basic metrics for bso2 on 2023-01-27\n",
            "Distribution metrics for bso2 on 2023-01-27\n",
            "Quantile metrics for bso2 on 2023-01-27\n",
            "Entropy calculation for bso2 on 2023-01-27\n",
            "Entropy calculated: 3.799\n",
            "Mutual information: bso2 vs aimp on 2023-01-27\n",
            "MI calculated: 0.000\n",
            "Processing column: bso3\n",
            "Basic metrics for bso3 on 2023-01-27\n",
            "Distribution metrics for bso3 on 2023-01-27\n",
            "Quantile metrics for bso3 on 2023-01-27\n",
            "Entropy calculation for bso3 on 2023-01-27\n",
            "Entropy calculated: 5.168\n",
            "Mutual information: bso3 vs aimp on 2023-01-27\n",
            "MI calculated: 0.000\n",
            "Processing column: ced1\n",
            "Basic metrics for ced1 on 2023-01-27\n",
            "Distribution metrics for ced1 on 2023-01-27\n",
            "Quantile metrics for ced1 on 2023-01-27\n",
            "Entropy calculation for ced1 on 2023-01-27\n",
            "Entropy calculated: 5.211\n",
            "Mutual information: ced1 vs aimp on 2023-01-27\n",
            "MI calculated: 0.000\n",
            "Processing column: cfo1\n",
            "Basic metrics for cfo1 on 2023-01-27\n",
            "Distribution metrics for cfo1 on 2023-01-27\n",
            "Quantile metrics for cfo1 on 2023-01-27\n",
            "Entropy calculation for cfo1 on 2023-01-27\n",
            "Entropy calculated: 4.781\n",
            "Mutual information: cfo1 vs aimp on 2023-01-27\n",
            "MI calculated: 0.000\n",
            "Processing column: cso1\n",
            "Basic metrics for cso1 on 2023-01-27\n",
            "Distribution metrics for cso1 on 2023-01-27\n",
            "Quantile metrics for cso1 on 2023-01-27\n",
            "Entropy calculation for cso1 on 2023-01-27\n",
            "Entropy calculated: 5.158\n",
            "Mutual information: cso1 vs aimp on 2023-01-27\n",
            "MI calculated: 0.000\n",
            "Processing column: y\n",
            "Basic metrics for y on 2023-01-27\n",
            "Distribution metrics for y on 2023-01-27\n",
            "Quantile metrics for y on 2023-01-27\n",
            "Entropy calculation for y on 2023-01-27\n",
            "Entropy calculated: 0.245\n",
            "Mutual information: y vs aimp on 2023-01-27\n",
            "MI calculated: 0.000\n",
            "Processing column: category\n",
            "Basic metrics for category on 2023-01-27\n",
            "Distribution metrics for category on 2023-01-27\n",
            "Quantile metrics for category on 2023-01-27\n",
            "Entropy calculation for category on 2023-01-27\n",
            "Entropy calculated: 0.290\n",
            "Mutual information: category vs aimp on 2023-01-27\n",
            "MI calculated: 0.000\n",
            "Completed 2023-01-27 - Generated 662 features\n",
            "Processing date 28/58: 2023-01-28\n",
            "Processing 86400 records\n",
            "Correlation matrix for 2023-01-28\n",
            "Correlation matrix calculated for 19 columns\n",
            "Processing column: aimp\n",
            "Basic metrics for aimp on 2023-01-28\n",
            "Distribution metrics for aimp on 2023-01-28\n",
            "Quantile metrics for aimp on 2023-01-28\n",
            "Entropy calculation for aimp on 2023-01-28\n",
            "Entropy calculated: 0.086\n",
            "Processing column: amud\n",
            "Basic metrics for amud on 2023-01-28\n",
            "Distribution metrics for amud on 2023-01-28\n",
            "Quantile metrics for amud on 2023-01-28\n",
            "Entropy calculation for amud on 2023-01-28\n",
            "Entropy calculated: 4.096\n",
            "Mutual information: amud vs aimp on 2023-01-28\n",
            "MI calculated: 0.000\n",
            "Processing column: arnd\n",
            "Basic metrics for arnd on 2023-01-28\n",
            "Distribution metrics for arnd on 2023-01-28\n",
            "Quantile metrics for arnd on 2023-01-28\n",
            "Entropy calculation for arnd on 2023-01-28\n",
            "Entropy calculated: 4.425\n",
            "Mutual information: arnd vs aimp on 2023-01-28\n",
            "MI calculated: 0.000\n",
            "Processing column: asin1\n",
            "Basic metrics for asin1 on 2023-01-28\n",
            "Distribution metrics for asin1 on 2023-01-28\n",
            "Quantile metrics for asin1 on 2023-01-28\n",
            "Entropy calculation for asin1 on 2023-01-28\n",
            "Entropy calculated: 5.585\n",
            "Mutual information: asin1 vs aimp on 2023-01-28\n",
            "MI calculated: 0.000\n",
            "Processing column: asin2\n",
            "Basic metrics for asin2 on 2023-01-28\n",
            "Distribution metrics for asin2 on 2023-01-28\n",
            "Quantile metrics for asin2 on 2023-01-28\n",
            "Entropy calculation for asin2 on 2023-01-28\n",
            "Entropy calculated: 5.375\n",
            "Mutual information: asin2 vs aimp on 2023-01-28\n",
            "MI calculated: 0.000\n",
            "Processing column: adbr\n",
            "Basic metrics for adbr on 2023-01-28\n",
            "Distribution metrics for adbr on 2023-01-28\n",
            "Quantile metrics for adbr on 2023-01-28\n",
            "Entropy calculation for adbr on 2023-01-28\n",
            "Entropy calculated: 0.999\n",
            "Mutual information: adbr vs aimp on 2023-01-28\n",
            "MI calculated: 0.000\n",
            "Processing column: adfl\n",
            "Basic metrics for adfl on 2023-01-28\n",
            "Distribution metrics for adfl on 2023-01-28\n",
            "Quantile metrics for adfl on 2023-01-28\n",
            "Entropy calculation for adfl on 2023-01-28\n",
            "Entropy calculated: 0.966\n",
            "Mutual information: adfl vs aimp on 2023-01-28\n",
            "MI calculated: 0.000\n",
            "Processing column: bed1\n",
            "Basic metrics for bed1 on 2023-01-28\n",
            "Distribution metrics for bed1 on 2023-01-28\n",
            "Quantile metrics for bed1 on 2023-01-28\n",
            "Entropy calculation for bed1 on 2023-01-28\n",
            "Entropy calculated: 4.825\n",
            "Mutual information: bed1 vs aimp on 2023-01-28\n",
            "MI calculated: 0.014\n",
            "Processing column: bed2\n",
            "Basic metrics for bed2 on 2023-01-28\n",
            "Distribution metrics for bed2 on 2023-01-28\n",
            "Quantile metrics for bed2 on 2023-01-28\n",
            "Entropy calculation for bed2 on 2023-01-28\n",
            "Entropy calculated: 2.996\n",
            "Mutual information: bed2 vs aimp on 2023-01-28\n",
            "MI calculated: 0.043\n",
            "Processing column: bfo1\n",
            "Basic metrics for bfo1 on 2023-01-28\n",
            "Distribution metrics for bfo1 on 2023-01-28\n",
            "Quantile metrics for bfo1 on 2023-01-28\n",
            "Entropy calculation for bfo1 on 2023-01-28\n",
            "Entropy calculated: 3.782\n",
            "Mutual information: bfo1 vs aimp on 2023-01-28\n",
            "MI calculated: 0.000\n",
            "Processing column: bfo2\n",
            "Basic metrics for bfo2 on 2023-01-28\n",
            "Distribution metrics for bfo2 on 2023-01-28\n",
            "Quantile metrics for bfo2 on 2023-01-28\n",
            "Entropy calculation for bfo2 on 2023-01-28\n",
            "Entropy calculated: 5.272\n",
            "Mutual information: bfo2 vs aimp on 2023-01-28\n",
            "MI calculated: 0.000\n",
            "Processing column: bso1\n",
            "Basic metrics for bso1 on 2023-01-28\n",
            "Distribution metrics for bso1 on 2023-01-28\n",
            "Quantile metrics for bso1 on 2023-01-28\n",
            "Entropy calculation for bso1 on 2023-01-28\n",
            "Entropy calculated: 4.922\n",
            "Mutual information: bso1 vs aimp on 2023-01-28\n",
            "MI calculated: 0.000\n",
            "Processing column: bso2\n",
            "Basic metrics for bso2 on 2023-01-28\n",
            "Distribution metrics for bso2 on 2023-01-28\n",
            "Quantile metrics for bso2 on 2023-01-28\n",
            "Entropy calculation for bso2 on 2023-01-28\n",
            "Entropy calculated: 3.610\n",
            "Mutual information: bso2 vs aimp on 2023-01-28\n",
            "MI calculated: 0.000\n",
            "Processing column: bso3\n",
            "Basic metrics for bso3 on 2023-01-28\n",
            "Distribution metrics for bso3 on 2023-01-28\n",
            "Quantile metrics for bso3 on 2023-01-28\n",
            "Entropy calculation for bso3 on 2023-01-28\n",
            "Entropy calculated: 5.008\n",
            "Mutual information: bso3 vs aimp on 2023-01-28\n",
            "MI calculated: 0.000\n",
            "Processing column: ced1\n",
            "Basic metrics for ced1 on 2023-01-28\n",
            "Distribution metrics for ced1 on 2023-01-28\n",
            "Quantile metrics for ced1 on 2023-01-28\n",
            "Entropy calculation for ced1 on 2023-01-28\n",
            "Entropy calculated: 4.990\n",
            "Mutual information: ced1 vs aimp on 2023-01-28\n",
            "MI calculated: 0.000\n",
            "Processing column: cfo1\n",
            "Basic metrics for cfo1 on 2023-01-28\n",
            "Distribution metrics for cfo1 on 2023-01-28\n",
            "Quantile metrics for cfo1 on 2023-01-28\n",
            "Entropy calculation for cfo1 on 2023-01-28\n",
            "Entropy calculated: 5.035\n",
            "Mutual information: cfo1 vs aimp on 2023-01-28\n",
            "MI calculated: 0.000\n",
            "Processing column: cso1\n",
            "Basic metrics for cso1 on 2023-01-28\n",
            "Distribution metrics for cso1 on 2023-01-28\n",
            "Quantile metrics for cso1 on 2023-01-28\n",
            "Entropy calculation for cso1 on 2023-01-28\n",
            "Entropy calculated: 5.154\n",
            "Mutual information: cso1 vs aimp on 2023-01-28\n",
            "MI calculated: 0.000\n",
            "Processing column: y\n",
            "Basic metrics for y on 2023-01-28\n",
            "Distribution metrics for y on 2023-01-28\n",
            "Quantile metrics for y on 2023-01-28\n",
            "Entropy calculation for y on 2023-01-28\n",
            "Entropy calculated: 0.422\n",
            "Mutual information: y vs aimp on 2023-01-28\n",
            "MI calculated: 0.000\n",
            "Processing column: category\n",
            "Basic metrics for category on 2023-01-28\n",
            "Distribution metrics for category on 2023-01-28\n",
            "Quantile metrics for category on 2023-01-28\n",
            "Entropy calculation for category on 2023-01-28\n",
            "Entropy calculated: 0.448\n",
            "Mutual information: category vs aimp on 2023-01-28\n",
            "MI calculated: 0.000\n",
            "Completed 2023-01-28 - Generated 662 features\n",
            "Processing date 29/58: 2023-01-29\n",
            "Processing 86400 records\n",
            "Correlation matrix for 2023-01-29\n",
            "Correlation matrix calculated for 19 columns\n",
            "Processing column: aimp\n",
            "Basic metrics for aimp on 2023-01-29\n",
            "Distribution metrics for aimp on 2023-01-29\n",
            "Quantile metrics for aimp on 2023-01-29\n",
            "Entropy calculation for aimp on 2023-01-29\n",
            "Entropy calculated: 0.080\n",
            "Processing column: amud\n",
            "Basic metrics for amud on 2023-01-29\n",
            "Distribution metrics for amud on 2023-01-29\n",
            "Quantile metrics for amud on 2023-01-29\n",
            "Entropy calculation for amud on 2023-01-29\n",
            "Entropy calculated: 3.961\n",
            "Mutual information: amud vs aimp on 2023-01-29\n",
            "MI calculated: 0.000\n",
            "Processing column: arnd\n",
            "Basic metrics for arnd on 2023-01-29\n",
            "Distribution metrics for arnd on 2023-01-29\n",
            "Quantile metrics for arnd on 2023-01-29\n",
            "Entropy calculation for arnd on 2023-01-29\n",
            "Entropy calculated: 4.122\n",
            "Mutual information: arnd vs aimp on 2023-01-29\n",
            "MI calculated: 0.000\n",
            "Processing column: asin1\n",
            "Basic metrics for asin1 on 2023-01-29\n",
            "Distribution metrics for asin1 on 2023-01-29\n",
            "Quantile metrics for asin1 on 2023-01-29\n",
            "Entropy calculation for asin1 on 2023-01-29\n",
            "Entropy calculated: 4.938\n",
            "Mutual information: asin1 vs aimp on 2023-01-29\n",
            "MI calculated: 0.000\n",
            "Processing column: asin2\n",
            "Basic metrics for asin2 on 2023-01-29\n",
            "Distribution metrics for asin2 on 2023-01-29\n",
            "Quantile metrics for asin2 on 2023-01-29\n",
            "Entropy calculation for asin2 on 2023-01-29\n",
            "Entropy calculated: 5.364\n",
            "Mutual information: asin2 vs aimp on 2023-01-29\n",
            "MI calculated: 0.000\n",
            "Processing column: adbr\n",
            "Basic metrics for adbr on 2023-01-29\n",
            "Distribution metrics for adbr on 2023-01-29\n",
            "Quantile metrics for adbr on 2023-01-29\n",
            "Entropy calculation for adbr on 2023-01-29\n",
            "Entropy calculated: 0.998\n",
            "Mutual information: adbr vs aimp on 2023-01-29\n",
            "MI calculated: 0.000\n",
            "Processing column: adfl\n",
            "Basic metrics for adfl on 2023-01-29\n",
            "Distribution metrics for adfl on 2023-01-29\n",
            "Quantile metrics for adfl on 2023-01-29\n",
            "Entropy calculation for adfl on 2023-01-29\n",
            "Entropy calculated: 0.967\n",
            "Mutual information: adfl vs aimp on 2023-01-29\n",
            "MI calculated: 0.000\n",
            "Processing column: bed1\n",
            "Basic metrics for bed1 on 2023-01-29\n",
            "Distribution metrics for bed1 on 2023-01-29\n",
            "Quantile metrics for bed1 on 2023-01-29\n",
            "Entropy calculation for bed1 on 2023-01-29\n",
            "Entropy calculated: 4.621\n",
            "Mutual information: bed1 vs aimp on 2023-01-29\n",
            "MI calculated: 0.014\n",
            "Processing column: bed2\n",
            "Basic metrics for bed2 on 2023-01-29\n",
            "Distribution metrics for bed2 on 2023-01-29\n",
            "Quantile metrics for bed2 on 2023-01-29\n",
            "Entropy calculation for bed2 on 2023-01-29\n",
            "Entropy calculated: 2.550\n",
            "Mutual information: bed2 vs aimp on 2023-01-29\n",
            "MI calculated: 0.031\n",
            "Processing column: bfo1\n",
            "Basic metrics for bfo1 on 2023-01-29\n",
            "Distribution metrics for bfo1 on 2023-01-29\n",
            "Quantile metrics for bfo1 on 2023-01-29\n",
            "Entropy calculation for bfo1 on 2023-01-29\n",
            "Entropy calculated: 4.411\n",
            "Mutual information: bfo1 vs aimp on 2023-01-29\n",
            "MI calculated: 0.000\n",
            "Processing column: bfo2\n",
            "Basic metrics for bfo2 on 2023-01-29\n",
            "Distribution metrics for bfo2 on 2023-01-29\n",
            "Quantile metrics for bfo2 on 2023-01-29\n",
            "Entropy calculation for bfo2 on 2023-01-29\n",
            "Entropy calculated: 4.446\n",
            "Mutual information: bfo2 vs aimp on 2023-01-29\n",
            "MI calculated: 0.000\n",
            "Processing column: bso1\n",
            "Basic metrics for bso1 on 2023-01-29\n",
            "Distribution metrics for bso1 on 2023-01-29\n",
            "Quantile metrics for bso1 on 2023-01-29\n",
            "Entropy calculation for bso1 on 2023-01-29\n",
            "Entropy calculated: 4.874\n",
            "Mutual information: bso1 vs aimp on 2023-01-29\n",
            "MI calculated: 0.000\n",
            "Processing column: bso2\n",
            "Basic metrics for bso2 on 2023-01-29\n",
            "Distribution metrics for bso2 on 2023-01-29\n",
            "Quantile metrics for bso2 on 2023-01-29\n",
            "Entropy calculation for bso2 on 2023-01-29\n",
            "Entropy calculated: 3.617\n",
            "Mutual information: bso2 vs aimp on 2023-01-29\n",
            "MI calculated: 0.000\n",
            "Processing column: bso3\n",
            "Basic metrics for bso3 on 2023-01-29\n",
            "Distribution metrics for bso3 on 2023-01-29\n",
            "Quantile metrics for bso3 on 2023-01-29\n",
            "Entropy calculation for bso3 on 2023-01-29\n",
            "Entropy calculated: 5.158\n",
            "Mutual information: bso3 vs aimp on 2023-01-29\n",
            "MI calculated: 0.000\n",
            "Processing column: ced1\n",
            "Basic metrics for ced1 on 2023-01-29\n",
            "Distribution metrics for ced1 on 2023-01-29\n",
            "Quantile metrics for ced1 on 2023-01-29\n",
            "Entropy calculation for ced1 on 2023-01-29\n",
            "Entropy calculated: 4.131\n",
            "Mutual information: ced1 vs aimp on 2023-01-29\n",
            "MI calculated: 0.000\n",
            "Processing column: cfo1\n",
            "Basic metrics for cfo1 on 2023-01-29\n",
            "Distribution metrics for cfo1 on 2023-01-29\n",
            "Quantile metrics for cfo1 on 2023-01-29\n",
            "Entropy calculation for cfo1 on 2023-01-29\n",
            "Entropy calculated: 4.747\n",
            "Mutual information: cfo1 vs aimp on 2023-01-29\n",
            "MI calculated: 0.000\n",
            "Processing column: cso1\n",
            "Basic metrics for cso1 on 2023-01-29\n",
            "Distribution metrics for cso1 on 2023-01-29\n",
            "Quantile metrics for cso1 on 2023-01-29\n",
            "Entropy calculation for cso1 on 2023-01-29\n",
            "Entropy calculated: 4.442\n",
            "Mutual information: cso1 vs aimp on 2023-01-29\n",
            "MI calculated: 0.000\n",
            "Processing column: y\n",
            "Basic metrics for y on 2023-01-29\n",
            "Distribution metrics for y on 2023-01-29\n",
            "Quantile metrics for y on 2023-01-29\n",
            "Entropy calculation for y on 2023-01-29\n",
            "Entropy calculated: 0.260\n",
            "Mutual information: y vs aimp on 2023-01-29\n",
            "MI calculated: 0.000\n",
            "Processing column: category\n",
            "Basic metrics for category on 2023-01-29\n",
            "Distribution metrics for category on 2023-01-29\n",
            "Quantile metrics for category on 2023-01-29\n",
            "Entropy calculation for category on 2023-01-29\n",
            "Entropy calculated: 0.333\n",
            "Mutual information: category vs aimp on 2023-01-29\n",
            "MI calculated: 0.000\n",
            "Completed 2023-01-29 - Generated 662 features\n",
            "Processing date 30/58: 2023-01-30\n",
            "Processing 86400 records\n",
            "Correlation matrix for 2023-01-30\n",
            "Correlation matrix calculated for 19 columns\n",
            "Processing column: aimp\n",
            "Basic metrics for aimp on 2023-01-30\n",
            "Distribution metrics for aimp on 2023-01-30\n",
            "Quantile metrics for aimp on 2023-01-30\n",
            "Entropy calculation for aimp on 2023-01-30\n",
            "Entropy calculated: 0.082\n",
            "Processing column: amud\n",
            "Basic metrics for amud on 2023-01-30\n",
            "Distribution metrics for amud on 2023-01-30\n",
            "Quantile metrics for amud on 2023-01-30\n",
            "Entropy calculation for amud on 2023-01-30\n",
            "Entropy calculated: 4.729\n",
            "Mutual information: amud vs aimp on 2023-01-30\n",
            "MI calculated: 0.000\n",
            "Processing column: arnd\n",
            "Basic metrics for arnd on 2023-01-30\n",
            "Distribution metrics for arnd on 2023-01-30\n",
            "Quantile metrics for arnd on 2023-01-30\n",
            "Entropy calculation for arnd on 2023-01-30\n",
            "Entropy calculated: 4.591\n",
            "Mutual information: arnd vs aimp on 2023-01-30\n",
            "MI calculated: 0.000\n",
            "Processing column: asin1\n",
            "Basic metrics for asin1 on 2023-01-30\n",
            "Distribution metrics for asin1 on 2023-01-30\n",
            "Quantile metrics for asin1 on 2023-01-30\n",
            "Entropy calculation for asin1 on 2023-01-30\n",
            "Entropy calculated: 5.364\n",
            "Mutual information: asin1 vs aimp on 2023-01-30\n",
            "MI calculated: 0.000\n",
            "Processing column: asin2\n",
            "Basic metrics for asin2 on 2023-01-30\n",
            "Distribution metrics for asin2 on 2023-01-30\n",
            "Quantile metrics for asin2 on 2023-01-30\n",
            "Entropy calculation for asin2 on 2023-01-30\n",
            "Entropy calculated: 5.375\n",
            "Mutual information: asin2 vs aimp on 2023-01-30\n",
            "MI calculated: 0.000\n",
            "Processing column: adbr\n",
            "Basic metrics for adbr on 2023-01-30\n",
            "Distribution metrics for adbr on 2023-01-30\n",
            "Quantile metrics for adbr on 2023-01-30\n",
            "Entropy calculation for adbr on 2023-01-30\n",
            "Entropy calculated: 1.000\n",
            "Mutual information: adbr vs aimp on 2023-01-30\n",
            "MI calculated: 0.000\n",
            "Processing column: adfl\n",
            "Basic metrics for adfl on 2023-01-30\n",
            "Distribution metrics for adfl on 2023-01-30\n",
            "Quantile metrics for adfl on 2023-01-30\n",
            "Entropy calculation for adfl on 2023-01-30\n",
            "Entropy calculated: 0.972\n",
            "Mutual information: adfl vs aimp on 2023-01-30\n",
            "MI calculated: 0.000\n",
            "Processing column: bed1\n",
            "Basic metrics for bed1 on 2023-01-30\n",
            "Distribution metrics for bed1 on 2023-01-30\n",
            "Quantile metrics for bed1 on 2023-01-30\n",
            "Entropy calculation for bed1 on 2023-01-30\n",
            "Entropy calculated: 4.601\n",
            "Mutual information: bed1 vs aimp on 2023-01-30\n",
            "MI calculated: 0.013\n",
            "Processing column: bed2\n",
            "Basic metrics for bed2 on 2023-01-30\n",
            "Distribution metrics for bed2 on 2023-01-30\n",
            "Quantile metrics for bed2 on 2023-01-30\n",
            "Entropy calculation for bed2 on 2023-01-30\n",
            "Entropy calculated: 2.311\n",
            "Mutual information: bed2 vs aimp on 2023-01-30\n",
            "MI calculated: 0.036\n",
            "Processing column: bfo1\n",
            "Basic metrics for bfo1 on 2023-01-30\n",
            "Distribution metrics for bfo1 on 2023-01-30\n",
            "Quantile metrics for bfo1 on 2023-01-30\n",
            "Entropy calculation for bfo1 on 2023-01-30\n",
            "Entropy calculated: 4.269\n",
            "Mutual information: bfo1 vs aimp on 2023-01-30\n",
            "MI calculated: 0.000\n",
            "Processing column: bfo2\n",
            "Basic metrics for bfo2 on 2023-01-30\n",
            "Distribution metrics for bfo2 on 2023-01-30\n",
            "Quantile metrics for bfo2 on 2023-01-30\n",
            "Entropy calculation for bfo2 on 2023-01-30\n",
            "Entropy calculated: 5.228\n",
            "Mutual information: bfo2 vs aimp on 2023-01-30\n",
            "MI calculated: 0.000\n",
            "Processing column: bso1\n",
            "Basic metrics for bso1 on 2023-01-30\n",
            "Distribution metrics for bso1 on 2023-01-30\n",
            "Quantile metrics for bso1 on 2023-01-30\n",
            "Entropy calculation for bso1 on 2023-01-30\n",
            "Entropy calculated: 5.117\n",
            "Mutual information: bso1 vs aimp on 2023-01-30\n",
            "MI calculated: 0.000\n",
            "Processing column: bso2\n",
            "Basic metrics for bso2 on 2023-01-30\n",
            "Distribution metrics for bso2 on 2023-01-30\n",
            "Quantile metrics for bso2 on 2023-01-30\n",
            "Entropy calculation for bso2 on 2023-01-30\n",
            "Entropy calculated: 5.522\n",
            "Mutual information: bso2 vs aimp on 2023-01-30\n",
            "MI calculated: 0.000\n",
            "Processing column: bso3\n",
            "Basic metrics for bso3 on 2023-01-30\n",
            "Distribution metrics for bso3 on 2023-01-30\n",
            "Quantile metrics for bso3 on 2023-01-30\n",
            "Entropy calculation for bso3 on 2023-01-30\n",
            "Entropy calculated: 5.269\n",
            "Mutual information: bso3 vs aimp on 2023-01-30\n",
            "MI calculated: 0.000\n",
            "Processing column: ced1\n",
            "Basic metrics for ced1 on 2023-01-30\n",
            "Distribution metrics for ced1 on 2023-01-30\n",
            "Quantile metrics for ced1 on 2023-01-30\n",
            "Entropy calculation for ced1 on 2023-01-30\n",
            "Entropy calculated: 4.921\n",
            "Mutual information: ced1 vs aimp on 2023-01-30\n",
            "MI calculated: 0.000\n",
            "Processing column: cfo1\n",
            "Basic metrics for cfo1 on 2023-01-30\n",
            "Distribution metrics for cfo1 on 2023-01-30\n",
            "Quantile metrics for cfo1 on 2023-01-30\n",
            "Entropy calculation for cfo1 on 2023-01-30\n",
            "Entropy calculated: 5.363\n",
            "Mutual information: cfo1 vs aimp on 2023-01-30\n",
            "MI calculated: 0.000\n",
            "Processing column: cso1\n",
            "Basic metrics for cso1 on 2023-01-30\n",
            "Distribution metrics for cso1 on 2023-01-30\n",
            "Quantile metrics for cso1 on 2023-01-30\n",
            "Entropy calculation for cso1 on 2023-01-30\n",
            "Entropy calculated: 5.243\n",
            "Mutual information: cso1 vs aimp on 2023-01-30\n",
            "MI calculated: 0.000\n",
            "Processing column: y\n",
            "Basic metrics for y on 2023-01-30\n",
            "Distribution metrics for y on 2023-01-30\n",
            "Quantile metrics for y on 2023-01-30\n",
            "Entropy calculation for y on 2023-01-30\n",
            "Entropy calculated: 0.106\n",
            "Mutual information: y vs aimp on 2023-01-30\n",
            "MI calculated: 0.000\n",
            "Processing column: category\n",
            "Basic metrics for category on 2023-01-30\n",
            "Distribution metrics for category on 2023-01-30\n",
            "Quantile metrics for category on 2023-01-30\n",
            "Entropy calculation for category on 2023-01-30\n",
            "Entropy calculated: 0.106\n",
            "Mutual information: category vs aimp on 2023-01-30\n",
            "MI calculated: 0.000\n",
            "Completed 2023-01-30 - Generated 662 features\n",
            "Processing date 31/58: 2023-01-31\n",
            "Processing 86400 records\n",
            "Correlation matrix for 2023-01-31\n",
            "Correlation matrix calculated for 19 columns\n",
            "Processing column: aimp\n",
            "Basic metrics for aimp on 2023-01-31\n",
            "Distribution metrics for aimp on 2023-01-31\n",
            "Quantile metrics for aimp on 2023-01-31\n",
            "Entropy calculation for aimp on 2023-01-31\n",
            "Entropy calculated: 0.082\n",
            "Processing column: amud\n",
            "Basic metrics for amud on 2023-01-31\n",
            "Distribution metrics for amud on 2023-01-31\n",
            "Quantile metrics for amud on 2023-01-31\n",
            "Entropy calculation for amud on 2023-01-31\n",
            "Entropy calculated: 3.644\n",
            "Mutual information: amud vs aimp on 2023-01-31\n",
            "MI calculated: 0.000\n",
            "Processing column: arnd\n",
            "Basic metrics for arnd on 2023-01-31\n",
            "Distribution metrics for arnd on 2023-01-31\n",
            "Quantile metrics for arnd on 2023-01-31\n",
            "Entropy calculation for arnd on 2023-01-31\n",
            "Entropy calculated: 5.254\n",
            "Mutual information: arnd vs aimp on 2023-01-31\n",
            "MI calculated: 0.000\n",
            "Processing column: asin1\n",
            "Basic metrics for asin1 on 2023-01-31\n",
            "Distribution metrics for asin1 on 2023-01-31\n",
            "Quantile metrics for asin1 on 2023-01-31\n",
            "Entropy calculation for asin1 on 2023-01-31\n",
            "Entropy calculated: 5.375\n",
            "Mutual information: asin1 vs aimp on 2023-01-31\n",
            "MI calculated: 0.000\n",
            "Processing column: asin2\n",
            "Basic metrics for asin2 on 2023-01-31\n",
            "Distribution metrics for asin2 on 2023-01-31\n",
            "Quantile metrics for asin2 on 2023-01-31\n",
            "Entropy calculation for asin2 on 2023-01-31\n",
            "Entropy calculated: 5.364\n",
            "Mutual information: asin2 vs aimp on 2023-01-31\n",
            "MI calculated: 0.000\n",
            "Processing column: adbr\n",
            "Basic metrics for adbr on 2023-01-31\n",
            "Distribution metrics for adbr on 2023-01-31\n",
            "Quantile metrics for adbr on 2023-01-31\n",
            "Entropy calculation for adbr on 2023-01-31\n",
            "Entropy calculated: 0.999\n",
            "Mutual information: adbr vs aimp on 2023-01-31\n",
            "MI calculated: 0.000\n",
            "Processing column: adfl\n",
            "Basic metrics for adfl on 2023-01-31\n",
            "Distribution metrics for adfl on 2023-01-31\n",
            "Quantile metrics for adfl on 2023-01-31\n",
            "Entropy calculation for adfl on 2023-01-31\n",
            "Entropy calculated: 0.963\n",
            "Mutual information: adfl vs aimp on 2023-01-31\n",
            "MI calculated: 0.000\n",
            "Processing column: bed1\n",
            "Basic metrics for bed1 on 2023-01-31\n",
            "Distribution metrics for bed1 on 2023-01-31\n",
            "Quantile metrics for bed1 on 2023-01-31\n",
            "Entropy calculation for bed1 on 2023-01-31\n",
            "Entropy calculated: 4.560\n",
            "Mutual information: bed1 vs aimp on 2023-01-31\n",
            "MI calculated: 0.013\n",
            "Processing column: bed2\n",
            "Basic metrics for bed2 on 2023-01-31\n",
            "Distribution metrics for bed2 on 2023-01-31\n",
            "Quantile metrics for bed2 on 2023-01-31\n",
            "Entropy calculation for bed2 on 2023-01-31\n",
            "Entropy calculated: 2.847\n",
            "Mutual information: bed2 vs aimp on 2023-01-31\n",
            "MI calculated: 0.043\n",
            "Processing column: bfo1\n",
            "Basic metrics for bfo1 on 2023-01-31\n",
            "Distribution metrics for bfo1 on 2023-01-31\n",
            "Quantile metrics for bfo1 on 2023-01-31\n",
            "Entropy calculation for bfo1 on 2023-01-31\n",
            "Entropy calculated: 4.674\n",
            "Mutual information: bfo1 vs aimp on 2023-01-31\n",
            "MI calculated: 0.000\n",
            "Processing column: bfo2\n",
            "Basic metrics for bfo2 on 2023-01-31\n",
            "Distribution metrics for bfo2 on 2023-01-31\n",
            "Quantile metrics for bfo2 on 2023-01-31\n",
            "Entropy calculation for bfo2 on 2023-01-31\n",
            "Entropy calculated: 5.276\n",
            "Mutual information: bfo2 vs aimp on 2023-01-31\n",
            "MI calculated: 0.000\n",
            "Processing column: bso1\n",
            "Basic metrics for bso1 on 2023-01-31\n",
            "Distribution metrics for bso1 on 2023-01-31\n",
            "Quantile metrics for bso1 on 2023-01-31\n",
            "Entropy calculation for bso1 on 2023-01-31\n",
            "Entropy calculated: 3.692\n",
            "Mutual information: bso1 vs aimp on 2023-01-31\n",
            "MI calculated: 0.000\n",
            "Processing column: bso2\n",
            "Basic metrics for bso2 on 2023-01-31\n",
            "Distribution metrics for bso2 on 2023-01-31\n",
            "Quantile metrics for bso2 on 2023-01-31\n",
            "Entropy calculation for bso2 on 2023-01-31\n",
            "Entropy calculated: 5.518\n",
            "Mutual information: bso2 vs aimp on 2023-01-31\n",
            "MI calculated: 0.000\n",
            "Processing column: bso3\n",
            "Basic metrics for bso3 on 2023-01-31\n",
            "Distribution metrics for bso3 on 2023-01-31\n",
            "Quantile metrics for bso3 on 2023-01-31\n",
            "Entropy calculation for bso3 on 2023-01-31\n",
            "Entropy calculated: 5.250\n",
            "Mutual information: bso3 vs aimp on 2023-01-31\n",
            "MI calculated: 0.000\n",
            "Processing column: ced1\n",
            "Basic metrics for ced1 on 2023-01-31\n",
            "Distribution metrics for ced1 on 2023-01-31\n",
            "Quantile metrics for ced1 on 2023-01-31\n",
            "Entropy calculation for ced1 on 2023-01-31\n",
            "Entropy calculated: 4.722\n",
            "Mutual information: ced1 vs aimp on 2023-01-31\n",
            "MI calculated: 0.000\n",
            "Processing column: cfo1\n",
            "Basic metrics for cfo1 on 2023-01-31\n",
            "Distribution metrics for cfo1 on 2023-01-31\n",
            "Quantile metrics for cfo1 on 2023-01-31\n",
            "Entropy calculation for cfo1 on 2023-01-31\n",
            "Entropy calculated: 4.843\n",
            "Mutual information: cfo1 vs aimp on 2023-01-31\n",
            "MI calculated: 0.000\n",
            "Processing column: cso1\n",
            "Basic metrics for cso1 on 2023-01-31\n",
            "Distribution metrics for cso1 on 2023-01-31\n",
            "Quantile metrics for cso1 on 2023-01-31\n",
            "Entropy calculation for cso1 on 2023-01-31\n",
            "Entropy calculated: 5.202\n",
            "Mutual information: cso1 vs aimp on 2023-01-31\n",
            "MI calculated: 0.000\n",
            "Processing column: y\n",
            "Basic metrics for y on 2023-01-31\n",
            "Distribution metrics for y on 2023-01-31\n",
            "Quantile metrics for y on 2023-01-31\n",
            "Entropy calculation for y on 2023-01-31\n",
            "Entropy calculated: 0.534\n",
            "Mutual information: y vs aimp on 2023-01-31\n",
            "MI calculated: 0.000\n",
            "Processing column: category\n",
            "Basic metrics for category on 2023-01-31\n",
            "Distribution metrics for category on 2023-01-31\n",
            "Quantile metrics for category on 2023-01-31\n",
            "Entropy calculation for category on 2023-01-31\n",
            "Entropy calculated: 0.342\n",
            "Mutual information: category vs aimp on 2023-01-31\n",
            "MI calculated: 0.000\n",
            "Completed 2023-01-31 - Generated 662 features\n",
            "Processing date 32/58: 2023-02-01\n",
            "Processing 86400 records\n",
            "Correlation matrix for 2023-02-01\n",
            "Correlation matrix calculated for 19 columns\n",
            "Processing column: aimp\n",
            "Basic metrics for aimp on 2023-02-01\n",
            "Distribution metrics for aimp on 2023-02-01\n",
            "Quantile metrics for aimp on 2023-02-01\n",
            "Entropy calculation for aimp on 2023-02-01\n",
            "Entropy calculated: 0.081\n",
            "Processing column: amud\n",
            "Basic metrics for amud on 2023-02-01\n",
            "Distribution metrics for amud on 2023-02-01\n",
            "Quantile metrics for amud on 2023-02-01\n",
            "Entropy calculation for amud on 2023-02-01\n",
            "Entropy calculated: 4.328\n",
            "Mutual information: amud vs aimp on 2023-02-01\n",
            "MI calculated: 0.000\n",
            "Processing column: arnd\n",
            "Basic metrics for arnd on 2023-02-01\n",
            "Distribution metrics for arnd on 2023-02-01\n",
            "Quantile metrics for arnd on 2023-02-01\n",
            "Entropy calculation for arnd on 2023-02-01\n",
            "Entropy calculated: 5.227\n",
            "Mutual information: arnd vs aimp on 2023-02-01\n",
            "MI calculated: 0.000\n",
            "Processing column: asin1\n",
            "Basic metrics for asin1 on 2023-02-01\n",
            "Distribution metrics for asin1 on 2023-02-01\n",
            "Quantile metrics for asin1 on 2023-02-01\n",
            "Entropy calculation for asin1 on 2023-02-01\n",
            "Entropy calculated: 4.932\n",
            "Mutual information: asin1 vs aimp on 2023-02-01\n",
            "MI calculated: 0.000\n",
            "Processing column: asin2\n",
            "Basic metrics for asin2 on 2023-02-01\n",
            "Distribution metrics for asin2 on 2023-02-01\n",
            "Quantile metrics for asin2 on 2023-02-01\n",
            "Entropy calculation for asin2 on 2023-02-01\n",
            "Entropy calculated: 5.376\n",
            "Mutual information: asin2 vs aimp on 2023-02-01\n",
            "MI calculated: 0.000\n",
            "Processing column: adbr\n",
            "Basic metrics for adbr on 2023-02-01\n",
            "Distribution metrics for adbr on 2023-02-01\n",
            "Quantile metrics for adbr on 2023-02-01\n",
            "Entropy calculation for adbr on 2023-02-01\n",
            "Entropy calculated: 0.999\n",
            "Mutual information: adbr vs aimp on 2023-02-01\n",
            "MI calculated: 0.000\n",
            "Processing column: adfl\n",
            "Basic metrics for adfl on 2023-02-01\n",
            "Distribution metrics for adfl on 2023-02-01\n",
            "Quantile metrics for adfl on 2023-02-01\n",
            "Entropy calculation for adfl on 2023-02-01\n",
            "Entropy calculated: 0.967\n",
            "Mutual information: adfl vs aimp on 2023-02-01\n",
            "MI calculated: 0.000\n",
            "Processing column: bed1\n",
            "Basic metrics for bed1 on 2023-02-01\n",
            "Distribution metrics for bed1 on 2023-02-01\n",
            "Quantile metrics for bed1 on 2023-02-01\n",
            "Entropy calculation for bed1 on 2023-02-01\n",
            "Entropy calculated: 4.797\n",
            "Mutual information: bed1 vs aimp on 2023-02-01\n",
            "MI calculated: 0.014\n",
            "Processing column: bed2\n",
            "Basic metrics for bed2 on 2023-02-01\n",
            "Distribution metrics for bed2 on 2023-02-01\n",
            "Quantile metrics for bed2 on 2023-02-01\n",
            "Entropy calculation for bed2 on 2023-02-01\n",
            "Entropy calculated: 1.817\n",
            "Mutual information: bed2 vs aimp on 2023-02-01\n",
            "MI calculated: 0.036\n",
            "Processing column: bfo1\n",
            "Basic metrics for bfo1 on 2023-02-01\n",
            "Distribution metrics for bfo1 on 2023-02-01\n",
            "Quantile metrics for bfo1 on 2023-02-01\n",
            "Entropy calculation for bfo1 on 2023-02-01\n",
            "Entropy calculated: 4.492\n",
            "Mutual information: bfo1 vs aimp on 2023-02-01\n",
            "MI calculated: 0.000\n",
            "Processing column: bfo2\n",
            "Basic metrics for bfo2 on 2023-02-01\n",
            "Distribution metrics for bfo2 on 2023-02-01\n",
            "Quantile metrics for bfo2 on 2023-02-01\n",
            "Entropy calculation for bfo2 on 2023-02-01\n",
            "Entropy calculated: 3.482\n",
            "Mutual information: bfo2 vs aimp on 2023-02-01\n",
            "MI calculated: 0.000\n",
            "Processing column: bso1\n",
            "Basic metrics for bso1 on 2023-02-01\n",
            "Distribution metrics for bso1 on 2023-02-01\n",
            "Quantile metrics for bso1 on 2023-02-01\n",
            "Entropy calculation for bso1 on 2023-02-01\n",
            "Entropy calculated: 4.908\n",
            "Mutual information: bso1 vs aimp on 2023-02-01\n",
            "MI calculated: 0.000\n",
            "Processing column: bso2\n",
            "Basic metrics for bso2 on 2023-02-01\n",
            "Distribution metrics for bso2 on 2023-02-01\n",
            "Quantile metrics for bso2 on 2023-02-01\n",
            "Entropy calculation for bso2 on 2023-02-01\n",
            "Entropy calculated: 5.521\n",
            "Mutual information: bso2 vs aimp on 2023-02-01\n",
            "MI calculated: 0.000\n",
            "Processing column: bso3\n",
            "Basic metrics for bso3 on 2023-02-01\n",
            "Distribution metrics for bso3 on 2023-02-01\n",
            "Quantile metrics for bso3 on 2023-02-01\n",
            "Entropy calculation for bso3 on 2023-02-01\n",
            "Entropy calculated: 5.261\n",
            "Mutual information: bso3 vs aimp on 2023-02-01\n",
            "MI calculated: 0.000\n",
            "Processing column: ced1\n",
            "Basic metrics for ced1 on 2023-02-01\n",
            "Distribution metrics for ced1 on 2023-02-01\n",
            "Quantile metrics for ced1 on 2023-02-01\n",
            "Entropy calculation for ced1 on 2023-02-01\n",
            "Entropy calculated: 2.356\n",
            "Mutual information: ced1 vs aimp on 2023-02-01\n",
            "MI calculated: 0.000\n",
            "Processing column: cfo1\n",
            "Basic metrics for cfo1 on 2023-02-01\n",
            "Distribution metrics for cfo1 on 2023-02-01\n",
            "Quantile metrics for cfo1 on 2023-02-01\n",
            "Entropy calculation for cfo1 on 2023-02-01\n",
            "Entropy calculated: 5.288\n",
            "Mutual information: cfo1 vs aimp on 2023-02-01\n",
            "MI calculated: 0.000\n",
            "Processing column: cso1\n",
            "Basic metrics for cso1 on 2023-02-01\n",
            "Distribution metrics for cso1 on 2023-02-01\n",
            "Quantile metrics for cso1 on 2023-02-01\n",
            "Entropy calculation for cso1 on 2023-02-01\n",
            "Entropy calculated: 3.598\n",
            "Mutual information: cso1 vs aimp on 2023-02-01\n",
            "MI calculated: 0.000\n",
            "Processing column: y\n",
            "Basic metrics for y on 2023-02-01\n",
            "Distribution metrics for y on 2023-02-01\n",
            "Quantile metrics for y on 2023-02-01\n",
            "Entropy calculation for y on 2023-02-01\n",
            "Entropy calculated: 0.493\n",
            "Mutual information: y vs aimp on 2023-02-01\n",
            "MI calculated: 0.000\n",
            "Processing column: category\n",
            "Basic metrics for category on 2023-02-01\n",
            "Distribution metrics for category on 2023-02-01\n",
            "Quantile metrics for category on 2023-02-01\n",
            "Entropy calculation for category on 2023-02-01\n",
            "Entropy calculated: 0.645\n",
            "Mutual information: category vs aimp on 2023-02-01\n",
            "MI calculated: 0.000\n",
            "Completed 2023-02-01 - Generated 662 features\n",
            "Processing date 33/58: 2023-02-02\n",
            "Processing 86400 records\n",
            "Correlation matrix for 2023-02-02\n",
            "Correlation matrix calculated for 19 columns\n",
            "Processing column: aimp\n",
            "Basic metrics for aimp on 2023-02-02\n",
            "Distribution metrics for aimp on 2023-02-02\n",
            "Quantile metrics for aimp on 2023-02-02\n",
            "Entropy calculation for aimp on 2023-02-02\n",
            "Entropy calculated: 0.083\n",
            "Processing column: amud\n",
            "Basic metrics for amud on 2023-02-02\n",
            "Distribution metrics for amud on 2023-02-02\n",
            "Quantile metrics for amud on 2023-02-02\n",
            "Entropy calculation for amud on 2023-02-02\n",
            "Entropy calculated: 4.198\n",
            "Mutual information: amud vs aimp on 2023-02-02\n",
            "MI calculated: 0.000\n",
            "Processing column: arnd\n",
            "Basic metrics for arnd on 2023-02-02\n",
            "Distribution metrics for arnd on 2023-02-02\n",
            "Quantile metrics for arnd on 2023-02-02\n",
            "Entropy calculation for arnd on 2023-02-02\n",
            "Entropy calculated: 4.797\n",
            "Mutual information: arnd vs aimp on 2023-02-02\n",
            "MI calculated: 0.000\n",
            "Processing column: asin1\n",
            "Basic metrics for asin1 on 2023-02-02\n",
            "Distribution metrics for asin1 on 2023-02-02\n",
            "Quantile metrics for asin1 on 2023-02-02\n",
            "Entropy calculation for asin1 on 2023-02-02\n",
            "Entropy calculated: 5.587\n",
            "Mutual information: asin1 vs aimp on 2023-02-02\n",
            "MI calculated: 0.000\n",
            "Processing column: asin2\n",
            "Basic metrics for asin2 on 2023-02-02\n",
            "Distribution metrics for asin2 on 2023-02-02\n",
            "Quantile metrics for asin2 on 2023-02-02\n",
            "Entropy calculation for asin2 on 2023-02-02\n",
            "Entropy calculated: 5.363\n",
            "Mutual information: asin2 vs aimp on 2023-02-02\n",
            "MI calculated: 0.000\n",
            "Processing column: adbr\n",
            "Basic metrics for adbr on 2023-02-02\n",
            "Distribution metrics for adbr on 2023-02-02\n",
            "Quantile metrics for adbr on 2023-02-02\n",
            "Entropy calculation for adbr on 2023-02-02\n",
            "Entropy calculated: 1.000\n",
            "Mutual information: adbr vs aimp on 2023-02-02\n",
            "MI calculated: 0.000\n",
            "Processing column: adfl\n",
            "Basic metrics for adfl on 2023-02-02\n",
            "Distribution metrics for adfl on 2023-02-02\n",
            "Quantile metrics for adfl on 2023-02-02\n",
            "Entropy calculation for adfl on 2023-02-02\n",
            "Entropy calculated: 0.972\n",
            "Mutual information: adfl vs aimp on 2023-02-02\n",
            "MI calculated: 0.000\n",
            "Processing column: bed1\n",
            "Basic metrics for bed1 on 2023-02-02\n",
            "Distribution metrics for bed1 on 2023-02-02\n",
            "Quantile metrics for bed1 on 2023-02-02\n",
            "Entropy calculation for bed1 on 2023-02-02\n",
            "Entropy calculated: 4.270\n",
            "Mutual information: bed1 vs aimp on 2023-02-02\n",
            "MI calculated: 0.012\n",
            "Processing column: bed2\n",
            "Basic metrics for bed2 on 2023-02-02\n",
            "Distribution metrics for bed2 on 2023-02-02\n",
            "Quantile metrics for bed2 on 2023-02-02\n",
            "Entropy calculation for bed2 on 2023-02-02\n",
            "Entropy calculated: 2.989\n",
            "Mutual information: bed2 vs aimp on 2023-02-02\n",
            "MI calculated: 0.040\n",
            "Processing column: bfo1\n",
            "Basic metrics for bfo1 on 2023-02-02\n",
            "Distribution metrics for bfo1 on 2023-02-02\n",
            "Quantile metrics for bfo1 on 2023-02-02\n",
            "Entropy calculation for bfo1 on 2023-02-02\n",
            "Entropy calculated: 4.591\n",
            "Mutual information: bfo1 vs aimp on 2023-02-02\n",
            "MI calculated: 0.000\n",
            "Processing column: bfo2\n",
            "Basic metrics for bfo2 on 2023-02-02\n",
            "Distribution metrics for bfo2 on 2023-02-02\n",
            "Quantile metrics for bfo2 on 2023-02-02\n",
            "Entropy calculation for bfo2 on 2023-02-02\n",
            "Entropy calculated: 5.188\n",
            "Mutual information: bfo2 vs aimp on 2023-02-02\n",
            "MI calculated: 0.000\n",
            "Processing column: bso1\n",
            "Basic metrics for bso1 on 2023-02-02\n",
            "Distribution metrics for bso1 on 2023-02-02\n",
            "Quantile metrics for bso1 on 2023-02-02\n",
            "Entropy calculation for bso1 on 2023-02-02\n",
            "Entropy calculated: 4.797\n",
            "Mutual information: bso1 vs aimp on 2023-02-02\n",
            "MI calculated: 0.000\n",
            "Processing column: bso2\n",
            "Basic metrics for bso2 on 2023-02-02\n",
            "Distribution metrics for bso2 on 2023-02-02\n",
            "Quantile metrics for bso2 on 2023-02-02\n",
            "Entropy calculation for bso2 on 2023-02-02\n",
            "Entropy calculated: 3.634\n",
            "Mutual information: bso2 vs aimp on 2023-02-02\n",
            "MI calculated: 0.000\n",
            "Processing column: bso3\n",
            "Basic metrics for bso3 on 2023-02-02\n",
            "Distribution metrics for bso3 on 2023-02-02\n",
            "Quantile metrics for bso3 on 2023-02-02\n",
            "Entropy calculation for bso3 on 2023-02-02\n",
            "Entropy calculated: 5.179\n",
            "Mutual information: bso3 vs aimp on 2023-02-02\n",
            "MI calculated: 0.000\n",
            "Processing column: ced1\n",
            "Basic metrics for ced1 on 2023-02-02\n",
            "Distribution metrics for ced1 on 2023-02-02\n",
            "Quantile metrics for ced1 on 2023-02-02\n",
            "Entropy calculation for ced1 on 2023-02-02\n",
            "Entropy calculated: 5.008\n",
            "Mutual information: ced1 vs aimp on 2023-02-02\n",
            "MI calculated: 0.000\n",
            "Processing column: cfo1\n",
            "Basic metrics for cfo1 on 2023-02-02\n",
            "Distribution metrics for cfo1 on 2023-02-02\n",
            "Quantile metrics for cfo1 on 2023-02-02\n",
            "Entropy calculation for cfo1 on 2023-02-02\n",
            "Entropy calculated: 5.133\n",
            "Mutual information: cfo1 vs aimp on 2023-02-02\n",
            "MI calculated: 0.000\n",
            "Processing column: cso1\n",
            "Basic metrics for cso1 on 2023-02-02\n",
            "Distribution metrics for cso1 on 2023-02-02\n",
            "Quantile metrics for cso1 on 2023-02-02\n",
            "Entropy calculation for cso1 on 2023-02-02\n",
            "Entropy calculated: 5.283\n",
            "Mutual information: cso1 vs aimp on 2023-02-02\n",
            "MI calculated: 0.000\n",
            "Processing column: y\n",
            "Basic metrics for y on 2023-02-02\n",
            "Distribution metrics for y on 2023-02-02\n",
            "Quantile metrics for y on 2023-02-02\n",
            "Entropy calculation for y on 2023-02-02\n",
            "Entropy calculated: 0.120\n",
            "Mutual information: y vs aimp on 2023-02-02\n",
            "MI calculated: 0.000\n",
            "Processing column: category\n",
            "Basic metrics for category on 2023-02-02\n",
            "Distribution metrics for category on 2023-02-02\n",
            "Quantile metrics for category on 2023-02-02\n",
            "Entropy calculation for category on 2023-02-02\n",
            "Entropy calculated: 0.135\n",
            "Mutual information: category vs aimp on 2023-02-02\n",
            "MI calculated: 0.000\n",
            "Completed 2023-02-02 - Generated 662 features\n",
            "Processing date 34/58: 2023-02-03\n",
            "Processing 86400 records\n",
            "Correlation matrix for 2023-02-03\n",
            "Correlation matrix calculated for 19 columns\n",
            "Processing column: aimp\n",
            "Basic metrics for aimp on 2023-02-03\n",
            "Distribution metrics for aimp on 2023-02-03\n",
            "Quantile metrics for aimp on 2023-02-03\n",
            "Entropy calculation for aimp on 2023-02-03\n",
            "Entropy calculated: 0.082\n",
            "Processing column: amud\n",
            "Basic metrics for amud on 2023-02-03\n",
            "Distribution metrics for amud on 2023-02-03\n",
            "Quantile metrics for amud on 2023-02-03\n",
            "Entropy calculation for amud on 2023-02-03\n",
            "Entropy calculated: 3.990\n",
            "Mutual information: amud vs aimp on 2023-02-03\n",
            "MI calculated: 0.000\n",
            "Processing column: arnd\n",
            "Basic metrics for arnd on 2023-02-03\n",
            "Distribution metrics for arnd on 2023-02-03\n",
            "Quantile metrics for arnd on 2023-02-03\n",
            "Entropy calculation for arnd on 2023-02-03\n",
            "Entropy calculated: 5.173\n",
            "Mutual information: arnd vs aimp on 2023-02-03\n",
            "MI calculated: 0.000\n",
            "Processing column: asin1\n",
            "Basic metrics for asin1 on 2023-02-03\n",
            "Distribution metrics for asin1 on 2023-02-03\n",
            "Quantile metrics for asin1 on 2023-02-03\n",
            "Entropy calculation for asin1 on 2023-02-03\n",
            "Entropy calculated: 4.985\n",
            "Mutual information: asin1 vs aimp on 2023-02-03\n",
            "MI calculated: 0.000\n",
            "Processing column: asin2\n",
            "Basic metrics for asin2 on 2023-02-03\n",
            "Distribution metrics for asin2 on 2023-02-03\n",
            "Quantile metrics for asin2 on 2023-02-03\n",
            "Entropy calculation for asin2 on 2023-02-03\n",
            "Entropy calculated: 5.376\n",
            "Mutual information: asin2 vs aimp on 2023-02-03\n",
            "MI calculated: 0.000\n",
            "Processing column: adbr\n",
            "Basic metrics for adbr on 2023-02-03\n",
            "Distribution metrics for adbr on 2023-02-03\n",
            "Quantile metrics for adbr on 2023-02-03\n",
            "Entropy calculation for adbr on 2023-02-03\n",
            "Entropy calculated: 0.999\n",
            "Mutual information: adbr vs aimp on 2023-02-03\n",
            "MI calculated: 0.000\n",
            "Processing column: adfl\n",
            "Basic metrics for adfl on 2023-02-03\n",
            "Distribution metrics for adfl on 2023-02-03\n",
            "Quantile metrics for adfl on 2023-02-03\n",
            "Entropy calculation for adfl on 2023-02-03\n",
            "Entropy calculated: 0.963\n",
            "Mutual information: adfl vs aimp on 2023-02-03\n",
            "MI calculated: 0.000\n",
            "Processing column: bed1\n",
            "Basic metrics for bed1 on 2023-02-03\n",
            "Distribution metrics for bed1 on 2023-02-03\n",
            "Quantile metrics for bed1 on 2023-02-03\n",
            "Entropy calculation for bed1 on 2023-02-03\n",
            "Entropy calculated: 4.713\n",
            "Mutual information: bed1 vs aimp on 2023-02-03\n",
            "MI calculated: 0.014\n",
            "Processing column: bed2\n",
            "Basic metrics for bed2 on 2023-02-03\n",
            "Distribution metrics for bed2 on 2023-02-03\n",
            "Quantile metrics for bed2 on 2023-02-03\n",
            "Entropy calculation for bed2 on 2023-02-03\n",
            "Entropy calculated: 2.594\n",
            "Mutual information: bed2 vs aimp on 2023-02-03\n",
            "MI calculated: 0.037\n",
            "Processing column: bfo1\n",
            "Basic metrics for bfo1 on 2023-02-03\n",
            "Distribution metrics for bfo1 on 2023-02-03\n",
            "Quantile metrics for bfo1 on 2023-02-03\n",
            "Entropy calculation for bfo1 on 2023-02-03\n",
            "Entropy calculated: 4.677\n",
            "Mutual information: bfo1 vs aimp on 2023-02-03\n",
            "MI calculated: 0.000\n",
            "Processing column: bfo2\n",
            "Basic metrics for bfo2 on 2023-02-03\n",
            "Distribution metrics for bfo2 on 2023-02-03\n",
            "Quantile metrics for bfo2 on 2023-02-03\n",
            "Entropy calculation for bfo2 on 2023-02-03\n",
            "Entropy calculated: 5.294\n",
            "Mutual information: bfo2 vs aimp on 2023-02-03\n",
            "MI calculated: 0.000\n",
            "Processing column: bso1\n",
            "Basic metrics for bso1 on 2023-02-03\n",
            "Distribution metrics for bso1 on 2023-02-03\n",
            "Quantile metrics for bso1 on 2023-02-03\n",
            "Entropy calculation for bso1 on 2023-02-03\n",
            "Entropy calculated: 4.768\n",
            "Mutual information: bso1 vs aimp on 2023-02-03\n",
            "MI calculated: 0.000\n",
            "Processing column: bso2\n",
            "Basic metrics for bso2 on 2023-02-03\n",
            "Distribution metrics for bso2 on 2023-02-03\n",
            "Quantile metrics for bso2 on 2023-02-03\n",
            "Entropy calculation for bso2 on 2023-02-03\n",
            "Entropy calculated: 5.519\n",
            "Mutual information: bso2 vs aimp on 2023-02-03\n",
            "MI calculated: 0.000\n",
            "Processing column: bso3\n",
            "Basic metrics for bso3 on 2023-02-03\n",
            "Distribution metrics for bso3 on 2023-02-03\n",
            "Quantile metrics for bso3 on 2023-02-03\n",
            "Entropy calculation for bso3 on 2023-02-03\n",
            "Entropy calculated: 3.538\n",
            "Mutual information: bso3 vs aimp on 2023-02-03\n",
            "MI calculated: 0.000\n",
            "Processing column: ced1\n",
            "Basic metrics for ced1 on 2023-02-03\n",
            "Distribution metrics for ced1 on 2023-02-03\n",
            "Quantile metrics for ced1 on 2023-02-03\n",
            "Entropy calculation for ced1 on 2023-02-03\n",
            "Entropy calculated: 5.126\n",
            "Mutual information: ced1 vs aimp on 2023-02-03\n",
            "MI calculated: 0.000\n",
            "Processing column: cfo1\n",
            "Basic metrics for cfo1 on 2023-02-03\n",
            "Distribution metrics for cfo1 on 2023-02-03\n",
            "Quantile metrics for cfo1 on 2023-02-03\n",
            "Entropy calculation for cfo1 on 2023-02-03\n",
            "Entropy calculated: 5.012\n",
            "Mutual information: cfo1 vs aimp on 2023-02-03\n",
            "MI calculated: 0.000\n",
            "Processing column: cso1\n",
            "Basic metrics for cso1 on 2023-02-03\n",
            "Distribution metrics for cso1 on 2023-02-03\n",
            "Quantile metrics for cso1 on 2023-02-03\n",
            "Entropy calculation for cso1 on 2023-02-03\n",
            "Entropy calculated: 5.314\n",
            "Mutual information: cso1 vs aimp on 2023-02-03\n",
            "MI calculated: 0.000\n",
            "Processing column: y\n",
            "Basic metrics for y on 2023-02-03\n",
            "Distribution metrics for y on 2023-02-03\n",
            "Quantile metrics for y on 2023-02-03\n",
            "Entropy calculation for y on 2023-02-03\n",
            "Entropy calculated: 0.152\n",
            "Mutual information: y vs aimp on 2023-02-03\n",
            "MI calculated: 0.000\n",
            "Processing column: category\n",
            "Basic metrics for category on 2023-02-03\n",
            "Distribution metrics for category on 2023-02-03\n",
            "Quantile metrics for category on 2023-02-03\n",
            "Entropy calculation for category on 2023-02-03\n",
            "Entropy calculated: 0.174\n",
            "Mutual information: category vs aimp on 2023-02-03\n",
            "MI calculated: 0.000\n",
            "Completed 2023-02-03 - Generated 662 features\n",
            "Processing date 35/58: 2023-02-04\n",
            "Processing 86400 records\n",
            "Correlation matrix for 2023-02-04\n",
            "Correlation matrix calculated for 19 columns\n",
            "Processing column: aimp\n",
            "Basic metrics for aimp on 2023-02-04\n",
            "Distribution metrics for aimp on 2023-02-04\n",
            "Quantile metrics for aimp on 2023-02-04\n",
            "Entropy calculation for aimp on 2023-02-04\n",
            "Entropy calculated: 0.082\n",
            "Processing column: amud\n",
            "Basic metrics for amud on 2023-02-04\n",
            "Distribution metrics for amud on 2023-02-04\n",
            "Quantile metrics for amud on 2023-02-04\n",
            "Entropy calculation for amud on 2023-02-04\n",
            "Entropy calculated: 3.886\n",
            "Mutual information: amud vs aimp on 2023-02-04\n",
            "MI calculated: 0.000\n",
            "Processing column: arnd\n",
            "Basic metrics for arnd on 2023-02-04\n",
            "Distribution metrics for arnd on 2023-02-04\n",
            "Quantile metrics for arnd on 2023-02-04\n",
            "Entropy calculation for arnd on 2023-02-04\n",
            "Entropy calculated: 5.101\n",
            "Mutual information: arnd vs aimp on 2023-02-04\n",
            "MI calculated: 0.000\n",
            "Processing column: asin1\n",
            "Basic metrics for asin1 on 2023-02-04\n",
            "Distribution metrics for asin1 on 2023-02-04\n",
            "Quantile metrics for asin1 on 2023-02-04\n",
            "Entropy calculation for asin1 on 2023-02-04\n",
            "Entropy calculated: 5.631\n",
            "Mutual information: asin1 vs aimp on 2023-02-04\n",
            "MI calculated: 0.000\n",
            "Processing column: asin2\n",
            "Basic metrics for asin2 on 2023-02-04\n",
            "Distribution metrics for asin2 on 2023-02-04\n",
            "Quantile metrics for asin2 on 2023-02-04\n",
            "Entropy calculation for asin2 on 2023-02-04\n",
            "Entropy calculated: 5.363\n",
            "Mutual information: asin2 vs aimp on 2023-02-04\n",
            "MI calculated: 0.000\n",
            "Processing column: adbr\n",
            "Basic metrics for adbr on 2023-02-04\n",
            "Distribution metrics for adbr on 2023-02-04\n",
            "Quantile metrics for adbr on 2023-02-04\n",
            "Entropy calculation for adbr on 2023-02-04\n",
            "Entropy calculated: 0.997\n",
            "Mutual information: adbr vs aimp on 2023-02-04\n",
            "MI calculated: 0.000\n",
            "Processing column: adfl\n",
            "Basic metrics for adfl on 2023-02-04\n",
            "Distribution metrics for adfl on 2023-02-04\n",
            "Quantile metrics for adfl on 2023-02-04\n",
            "Entropy calculation for adfl on 2023-02-04\n",
            "Entropy calculated: 0.967\n",
            "Mutual information: adfl vs aimp on 2023-02-04\n",
            "MI calculated: 0.000\n",
            "Processing column: bed1\n",
            "Basic metrics for bed1 on 2023-02-04\n",
            "Distribution metrics for bed1 on 2023-02-04\n",
            "Quantile metrics for bed1 on 2023-02-04\n",
            "Entropy calculation for bed1 on 2023-02-04\n",
            "Entropy calculated: 4.463\n",
            "Mutual information: bed1 vs aimp on 2023-02-04\n",
            "MI calculated: 0.013\n",
            "Processing column: bed2\n",
            "Basic metrics for bed2 on 2023-02-04\n",
            "Distribution metrics for bed2 on 2023-02-04\n",
            "Quantile metrics for bed2 on 2023-02-04\n",
            "Entropy calculation for bed2 on 2023-02-04\n",
            "Entropy calculated: 2.779\n",
            "Mutual information: bed2 vs aimp on 2023-02-04\n",
            "MI calculated: 0.046\n",
            "Processing column: bfo1\n",
            "Basic metrics for bfo1 on 2023-02-04\n",
            "Distribution metrics for bfo1 on 2023-02-04\n",
            "Quantile metrics for bfo1 on 2023-02-04\n",
            "Entropy calculation for bfo1 on 2023-02-04\n",
            "Entropy calculated: 3.297\n",
            "Mutual information: bfo1 vs aimp on 2023-02-04\n",
            "MI calculated: 0.000\n",
            "Processing column: bfo2\n",
            "Basic metrics for bfo2 on 2023-02-04\n",
            "Distribution metrics for bfo2 on 2023-02-04\n",
            "Quantile metrics for bfo2 on 2023-02-04\n",
            "Entropy calculation for bfo2 on 2023-02-04\n",
            "Entropy calculated: 1.138\n",
            "Mutual information: bfo2 vs aimp on 2023-02-04\n",
            "MI calculated: 0.000\n",
            "Processing column: bso1\n",
            "Basic metrics for bso1 on 2023-02-04\n",
            "Distribution metrics for bso1 on 2023-02-04\n",
            "Quantile metrics for bso1 on 2023-02-04\n",
            "Entropy calculation for bso1 on 2023-02-04\n",
            "Entropy calculated: 4.939\n",
            "Mutual information: bso1 vs aimp on 2023-02-04\n",
            "MI calculated: 0.000\n",
            "Processing column: bso2\n",
            "Basic metrics for bso2 on 2023-02-04\n",
            "Distribution metrics for bso2 on 2023-02-04\n",
            "Quantile metrics for bso2 on 2023-02-04\n",
            "Entropy calculation for bso2 on 2023-02-04\n",
            "Entropy calculated: 3.481\n",
            "Mutual information: bso2 vs aimp on 2023-02-04\n",
            "MI calculated: 0.000\n",
            "Processing column: bso3\n",
            "Basic metrics for bso3 on 2023-02-04\n",
            "Distribution metrics for bso3 on 2023-02-04\n",
            "Quantile metrics for bso3 on 2023-02-04\n",
            "Entropy calculation for bso3 on 2023-02-04\n",
            "Entropy calculated: 5.265\n",
            "Mutual information: bso3 vs aimp on 2023-02-04\n",
            "MI calculated: 0.000\n",
            "Processing column: ced1\n",
            "Basic metrics for ced1 on 2023-02-04\n",
            "Distribution metrics for ced1 on 2023-02-04\n",
            "Quantile metrics for ced1 on 2023-02-04\n",
            "Entropy calculation for ced1 on 2023-02-04\n",
            "Entropy calculated: 4.807\n",
            "Mutual information: ced1 vs aimp on 2023-02-04\n",
            "MI calculated: 0.000\n",
            "Processing column: cfo1\n",
            "Basic metrics for cfo1 on 2023-02-04\n",
            "Distribution metrics for cfo1 on 2023-02-04\n",
            "Quantile metrics for cfo1 on 2023-02-04\n",
            "Entropy calculation for cfo1 on 2023-02-04\n",
            "Entropy calculated: 3.993\n",
            "Mutual information: cfo1 vs aimp on 2023-02-04\n",
            "MI calculated: 0.000\n",
            "Processing column: cso1\n",
            "Basic metrics for cso1 on 2023-02-04\n",
            "Distribution metrics for cso1 on 2023-02-04\n",
            "Quantile metrics for cso1 on 2023-02-04\n",
            "Entropy calculation for cso1 on 2023-02-04\n",
            "Entropy calculated: 4.205\n",
            "Mutual information: cso1 vs aimp on 2023-02-04\n",
            "MI calculated: 0.000\n",
            "Processing column: y\n",
            "Basic metrics for y on 2023-02-04\n",
            "Distribution metrics for y on 2023-02-04\n",
            "Quantile metrics for y on 2023-02-04\n",
            "Entropy calculation for y on 2023-02-04\n",
            "Entropy calculated: 0.295\n",
            "Mutual information: y vs aimp on 2023-02-04\n",
            "MI calculated: 0.000\n",
            "Processing column: category\n",
            "Basic metrics for category on 2023-02-04\n",
            "Distribution metrics for category on 2023-02-04\n",
            "Quantile metrics for category on 2023-02-04\n",
            "Entropy calculation for category on 2023-02-04\n",
            "Entropy calculated: 0.189\n",
            "Mutual information: category vs aimp on 2023-02-04\n",
            "MI calculated: 0.000\n",
            "Completed 2023-02-04 - Generated 662 features\n",
            "Processing date 36/58: 2023-02-05\n",
            "Processing 86400 records\n",
            "Correlation matrix for 2023-02-05\n",
            "Correlation matrix calculated for 19 columns\n",
            "Processing column: aimp\n",
            "Basic metrics for aimp on 2023-02-05\n",
            "Distribution metrics for aimp on 2023-02-05\n",
            "Quantile metrics for aimp on 2023-02-05\n",
            "Entropy calculation for aimp on 2023-02-05\n",
            "Entropy calculated: 0.082\n",
            "Processing column: amud\n",
            "Basic metrics for amud on 2023-02-05\n",
            "Distribution metrics for amud on 2023-02-05\n",
            "Quantile metrics for amud on 2023-02-05\n",
            "Entropy calculation for amud on 2023-02-05\n",
            "Entropy calculated: 3.369\n",
            "Mutual information: amud vs aimp on 2023-02-05\n",
            "MI calculated: 0.000\n",
            "Processing column: arnd\n",
            "Basic metrics for arnd on 2023-02-05\n",
            "Distribution metrics for arnd on 2023-02-05\n",
            "Quantile metrics for arnd on 2023-02-05\n",
            "Entropy calculation for arnd on 2023-02-05\n",
            "Entropy calculated: 5.042\n",
            "Mutual information: arnd vs aimp on 2023-02-05\n",
            "MI calculated: 0.000\n",
            "Processing column: asin1\n",
            "Basic metrics for asin1 on 2023-02-05\n",
            "Distribution metrics for asin1 on 2023-02-05\n",
            "Quantile metrics for asin1 on 2023-02-05\n",
            "Entropy calculation for asin1 on 2023-02-05\n",
            "Entropy calculated: 5.153\n",
            "Mutual information: asin1 vs aimp on 2023-02-05\n",
            "MI calculated: 0.000\n",
            "Processing column: asin2\n",
            "Basic metrics for asin2 on 2023-02-05\n",
            "Distribution metrics for asin2 on 2023-02-05\n",
            "Quantile metrics for asin2 on 2023-02-05\n",
            "Entropy calculation for asin2 on 2023-02-05\n",
            "Entropy calculated: 5.376\n",
            "Mutual information: asin2 vs aimp on 2023-02-05\n",
            "MI calculated: 0.000\n",
            "Processing column: adbr\n",
            "Basic metrics for adbr on 2023-02-05\n",
            "Distribution metrics for adbr on 2023-02-05\n",
            "Quantile metrics for adbr on 2023-02-05\n",
            "Entropy calculation for adbr on 2023-02-05\n",
            "Entropy calculated: 1.000\n",
            "Mutual information: adbr vs aimp on 2023-02-05\n",
            "MI calculated: 0.000\n",
            "Processing column: adfl\n",
            "Basic metrics for adfl on 2023-02-05\n",
            "Distribution metrics for adfl on 2023-02-05\n",
            "Quantile metrics for adfl on 2023-02-05\n",
            "Entropy calculation for adfl on 2023-02-05\n",
            "Entropy calculated: 0.969\n",
            "Mutual information: adfl vs aimp on 2023-02-05\n",
            "MI calculated: 0.000\n",
            "Processing column: bed1\n",
            "Basic metrics for bed1 on 2023-02-05\n",
            "Distribution metrics for bed1 on 2023-02-05\n",
            "Quantile metrics for bed1 on 2023-02-05\n",
            "Entropy calculation for bed1 on 2023-02-05\n",
            "Entropy calculated: 4.622\n",
            "Mutual information: bed1 vs aimp on 2023-02-05\n",
            "MI calculated: 0.013\n",
            "Processing column: bed2\n",
            "Basic metrics for bed2 on 2023-02-05\n",
            "Distribution metrics for bed2 on 2023-02-05\n",
            "Quantile metrics for bed2 on 2023-02-05\n",
            "Entropy calculation for bed2 on 2023-02-05\n",
            "Entropy calculated: 2.673\n",
            "Mutual information: bed2 vs aimp on 2023-02-05\n",
            "MI calculated: 0.036\n",
            "Processing column: bfo1\n",
            "Basic metrics for bfo1 on 2023-02-05\n",
            "Distribution metrics for bfo1 on 2023-02-05\n",
            "Quantile metrics for bfo1 on 2023-02-05\n",
            "Entropy calculation for bfo1 on 2023-02-05\n",
            "Entropy calculated: 4.576\n",
            "Mutual information: bfo1 vs aimp on 2023-02-05\n",
            "MI calculated: 0.000\n",
            "Processing column: bfo2\n",
            "Basic metrics for bfo2 on 2023-02-05\n",
            "Distribution metrics for bfo2 on 2023-02-05\n",
            "Quantile metrics for bfo2 on 2023-02-05\n",
            "Entropy calculation for bfo2 on 2023-02-05\n",
            "Entropy calculated: 3.902\n",
            "Mutual information: bfo2 vs aimp on 2023-02-05\n",
            "MI calculated: 0.000\n",
            "Processing column: bso1\n",
            "Basic metrics for bso1 on 2023-02-05\n",
            "Distribution metrics for bso1 on 2023-02-05\n",
            "Quantile metrics for bso1 on 2023-02-05\n",
            "Entropy calculation for bso1 on 2023-02-05\n",
            "Entropy calculated: 4.725\n",
            "Mutual information: bso1 vs aimp on 2023-02-05\n",
            "MI calculated: 0.000\n",
            "Processing column: bso2\n",
            "Basic metrics for bso2 on 2023-02-05\n",
            "Distribution metrics for bso2 on 2023-02-05\n",
            "Quantile metrics for bso2 on 2023-02-05\n",
            "Entropy calculation for bso2 on 2023-02-05\n",
            "Entropy calculated: 5.517\n",
            "Mutual information: bso2 vs aimp on 2023-02-05\n",
            "MI calculated: 0.000\n",
            "Processing column: bso3\n",
            "Basic metrics for bso3 on 2023-02-05\n",
            "Distribution metrics for bso3 on 2023-02-05\n",
            "Quantile metrics for bso3 on 2023-02-05\n",
            "Entropy calculation for bso3 on 2023-02-05\n",
            "Entropy calculated: 5.175\n",
            "Mutual information: bso3 vs aimp on 2023-02-05\n",
            "MI calculated: 0.000\n",
            "Processing column: ced1\n",
            "Basic metrics for ced1 on 2023-02-05\n",
            "Distribution metrics for ced1 on 2023-02-05\n",
            "Quantile metrics for ced1 on 2023-02-05\n",
            "Entropy calculation for ced1 on 2023-02-05\n",
            "Entropy calculated: 5.033\n",
            "Mutual information: ced1 vs aimp on 2023-02-05\n",
            "MI calculated: 0.000\n",
            "Processing column: cfo1\n",
            "Basic metrics for cfo1 on 2023-02-05\n",
            "Distribution metrics for cfo1 on 2023-02-05\n",
            "Quantile metrics for cfo1 on 2023-02-05\n",
            "Entropy calculation for cfo1 on 2023-02-05\n",
            "Entropy calculated: 5.181\n",
            "Mutual information: cfo1 vs aimp on 2023-02-05\n",
            "MI calculated: 0.000\n",
            "Processing column: cso1\n",
            "Basic metrics for cso1 on 2023-02-05\n",
            "Distribution metrics for cso1 on 2023-02-05\n",
            "Quantile metrics for cso1 on 2023-02-05\n",
            "Entropy calculation for cso1 on 2023-02-05\n",
            "Entropy calculated: 4.033\n",
            "Mutual information: cso1 vs aimp on 2023-02-05\n",
            "MI calculated: 0.000\n",
            "Processing column: y\n",
            "Basic metrics for y on 2023-02-05\n",
            "Distribution metrics for y on 2023-02-05\n",
            "Quantile metrics for y on 2023-02-05\n",
            "Entropy calculation for y on 2023-02-05\n",
            "Entropy calculated: 0.106\n",
            "Mutual information: y vs aimp on 2023-02-05\n",
            "MI calculated: 0.000\n",
            "Processing column: category\n",
            "Basic metrics for category on 2023-02-05\n",
            "Distribution metrics for category on 2023-02-05\n",
            "Quantile metrics for category on 2023-02-05\n",
            "Entropy calculation for category on 2023-02-05\n",
            "Entropy calculated: 0.106\n",
            "Mutual information: category vs aimp on 2023-02-05\n",
            "MI calculated: 0.000\n",
            "Completed 2023-02-05 - Generated 662 features\n",
            "Processing date 37/58: 2023-02-06\n",
            "Processing 86400 records\n",
            "Correlation matrix for 2023-02-06\n",
            "Correlation matrix calculated for 19 columns\n",
            "Processing column: aimp\n",
            "Basic metrics for aimp on 2023-02-06\n",
            "Distribution metrics for aimp on 2023-02-06\n",
            "Quantile metrics for aimp on 2023-02-06\n",
            "Entropy calculation for aimp on 2023-02-06\n",
            "Entropy calculated: 0.078\n",
            "Processing column: amud\n",
            "Basic metrics for amud on 2023-02-06\n",
            "Distribution metrics for amud on 2023-02-06\n",
            "Quantile metrics for amud on 2023-02-06\n",
            "Entropy calculation for amud on 2023-02-06\n",
            "Entropy calculated: 3.819\n",
            "Mutual information: amud vs aimp on 2023-02-06\n",
            "MI calculated: 0.000\n",
            "Processing column: arnd\n",
            "Basic metrics for arnd on 2023-02-06\n",
            "Distribution metrics for arnd on 2023-02-06\n",
            "Quantile metrics for arnd on 2023-02-06\n",
            "Entropy calculation for arnd on 2023-02-06\n",
            "Entropy calculated: 4.982\n",
            "Mutual information: arnd vs aimp on 2023-02-06\n",
            "MI calculated: 0.000\n",
            "Processing column: asin1\n",
            "Basic metrics for asin1 on 2023-02-06\n",
            "Distribution metrics for asin1 on 2023-02-06\n",
            "Quantile metrics for asin1 on 2023-02-06\n",
            "Entropy calculation for asin1 on 2023-02-06\n",
            "Entropy calculated: 5.617\n",
            "Mutual information: asin1 vs aimp on 2023-02-06\n",
            "MI calculated: 0.000\n",
            "Processing column: asin2\n",
            "Basic metrics for asin2 on 2023-02-06\n",
            "Distribution metrics for asin2 on 2023-02-06\n",
            "Quantile metrics for asin2 on 2023-02-06\n",
            "Entropy calculation for asin2 on 2023-02-06\n",
            "Entropy calculated: 5.362\n",
            "Mutual information: asin2 vs aimp on 2023-02-06\n",
            "MI calculated: 0.000\n",
            "Processing column: adbr\n",
            "Basic metrics for adbr on 2023-02-06\n",
            "Distribution metrics for adbr on 2023-02-06\n",
            "Quantile metrics for adbr on 2023-02-06\n",
            "Entropy calculation for adbr on 2023-02-06\n",
            "Entropy calculated: 0.996\n",
            "Mutual information: adbr vs aimp on 2023-02-06\n",
            "MI calculated: 0.000\n",
            "Processing column: adfl\n",
            "Basic metrics for adfl on 2023-02-06\n",
            "Distribution metrics for adfl on 2023-02-06\n",
            "Quantile metrics for adfl on 2023-02-06\n",
            "Entropy calculation for adfl on 2023-02-06\n",
            "Entropy calculated: 0.968\n",
            "Mutual information: adfl vs aimp on 2023-02-06\n",
            "MI calculated: 0.000\n",
            "Processing column: bed1\n",
            "Basic metrics for bed1 on 2023-02-06\n",
            "Distribution metrics for bed1 on 2023-02-06\n",
            "Quantile metrics for bed1 on 2023-02-06\n",
            "Entropy calculation for bed1 on 2023-02-06\n",
            "Entropy calculated: 4.546\n",
            "Mutual information: bed1 vs aimp on 2023-02-06\n",
            "MI calculated: 0.013\n",
            "Processing column: bed2\n",
            "Basic metrics for bed2 on 2023-02-06\n",
            "Distribution metrics for bed2 on 2023-02-06\n",
            "Quantile metrics for bed2 on 2023-02-06\n",
            "Entropy calculation for bed2 on 2023-02-06\n",
            "Entropy calculated: 1.556\n",
            "Mutual information: bed2 vs aimp on 2023-02-06\n",
            "MI calculated: 0.018\n",
            "Processing column: bfo1\n",
            "Basic metrics for bfo1 on 2023-02-06\n",
            "Distribution metrics for bfo1 on 2023-02-06\n",
            "Quantile metrics for bfo1 on 2023-02-06\n",
            "Entropy calculation for bfo1 on 2023-02-06\n",
            "Entropy calculated: 3.677\n",
            "Mutual information: bfo1 vs aimp on 2023-02-06\n",
            "MI calculated: 0.000\n",
            "Processing column: bfo2\n",
            "Basic metrics for bfo2 on 2023-02-06\n",
            "Distribution metrics for bfo2 on 2023-02-06\n",
            "Quantile metrics for bfo2 on 2023-02-06\n",
            "Entropy calculation for bfo2 on 2023-02-06\n",
            "Entropy calculated: 5.208\n",
            "Mutual information: bfo2 vs aimp on 2023-02-06\n",
            "MI calculated: 0.000\n",
            "Processing column: bso1\n",
            "Basic metrics for bso1 on 2023-02-06\n",
            "Distribution metrics for bso1 on 2023-02-06\n",
            "Quantile metrics for bso1 on 2023-02-06\n",
            "Entropy calculation for bso1 on 2023-02-06\n",
            "Entropy calculated: 4.440\n",
            "Mutual information: bso1 vs aimp on 2023-02-06\n",
            "MI calculated: 0.000\n",
            "Processing column: bso2\n",
            "Basic metrics for bso2 on 2023-02-06\n",
            "Distribution metrics for bso2 on 2023-02-06\n",
            "Quantile metrics for bso2 on 2023-02-06\n",
            "Entropy calculation for bso2 on 2023-02-06\n",
            "Entropy calculated: 5.518\n",
            "Mutual information: bso2 vs aimp on 2023-02-06\n",
            "MI calculated: 0.000\n",
            "Processing column: bso3\n",
            "Basic metrics for bso3 on 2023-02-06\n",
            "Distribution metrics for bso3 on 2023-02-06\n",
            "Quantile metrics for bso3 on 2023-02-06\n",
            "Entropy calculation for bso3 on 2023-02-06\n",
            "Entropy calculated: 5.161\n",
            "Mutual information: bso3 vs aimp on 2023-02-06\n",
            "MI calculated: 0.000\n",
            "Processing column: ced1\n",
            "Basic metrics for ced1 on 2023-02-06\n",
            "Distribution metrics for ced1 on 2023-02-06\n",
            "Quantile metrics for ced1 on 2023-02-06\n",
            "Entropy calculation for ced1 on 2023-02-06\n",
            "Entropy calculated: 4.366\n",
            "Mutual information: ced1 vs aimp on 2023-02-06\n",
            "MI calculated: 0.000\n",
            "Processing column: cfo1\n",
            "Basic metrics for cfo1 on 2023-02-06\n",
            "Distribution metrics for cfo1 on 2023-02-06\n",
            "Quantile metrics for cfo1 on 2023-02-06\n",
            "Entropy calculation for cfo1 on 2023-02-06\n",
            "Entropy calculated: 4.031\n",
            "Mutual information: cfo1 vs aimp on 2023-02-06\n",
            "MI calculated: 0.000\n",
            "Processing column: cso1\n",
            "Basic metrics for cso1 on 2023-02-06\n",
            "Distribution metrics for cso1 on 2023-02-06\n",
            "Quantile metrics for cso1 on 2023-02-06\n",
            "Entropy calculation for cso1 on 2023-02-06\n",
            "Entropy calculated: 5.199\n",
            "Mutual information: cso1 vs aimp on 2023-02-06\n",
            "MI calculated: 0.000\n",
            "Processing column: y\n",
            "Basic metrics for y on 2023-02-06\n",
            "Distribution metrics for y on 2023-02-06\n",
            "Quantile metrics for y on 2023-02-06\n",
            "Entropy calculation for y on 2023-02-06\n",
            "Entropy calculated: 0.449\n",
            "Mutual information: y vs aimp on 2023-02-06\n",
            "MI calculated: 0.000\n",
            "Processing column: category\n",
            "Basic metrics for category on 2023-02-06\n",
            "Distribution metrics for category on 2023-02-06\n",
            "Quantile metrics for category on 2023-02-06\n",
            "Entropy calculation for category on 2023-02-06\n",
            "Entropy calculated: 0.480\n",
            "Mutual information: category vs aimp on 2023-02-06\n",
            "MI calculated: 0.000\n",
            "Completed 2023-02-06 - Generated 662 features\n",
            "Processing date 38/58: 2023-02-07\n",
            "Processing 86400 records\n",
            "Correlation matrix for 2023-02-07\n",
            "Correlation matrix calculated for 19 columns\n",
            "Processing column: aimp\n",
            "Basic metrics for aimp on 2023-02-07\n",
            "Distribution metrics for aimp on 2023-02-07\n",
            "Quantile metrics for aimp on 2023-02-07\n",
            "Entropy calculation for aimp on 2023-02-07\n",
            "Entropy calculated: 0.080\n",
            "Processing column: amud\n",
            "Basic metrics for amud on 2023-02-07\n",
            "Distribution metrics for amud on 2023-02-07\n",
            "Quantile metrics for amud on 2023-02-07\n",
            "Entropy calculation for amud on 2023-02-07\n",
            "Entropy calculated: 4.064\n",
            "Mutual information: amud vs aimp on 2023-02-07\n",
            "MI calculated: 0.000\n",
            "Processing column: arnd\n",
            "Basic metrics for arnd on 2023-02-07\n",
            "Distribution metrics for arnd on 2023-02-07\n",
            "Quantile metrics for arnd on 2023-02-07\n",
            "Entropy calculation for arnd on 2023-02-07\n",
            "Entropy calculated: 4.865\n",
            "Mutual information: arnd vs aimp on 2023-02-07\n",
            "MI calculated: 0.000\n",
            "Processing column: asin1\n",
            "Basic metrics for asin1 on 2023-02-07\n",
            "Distribution metrics for asin1 on 2023-02-07\n",
            "Quantile metrics for asin1 on 2023-02-07\n",
            "Entropy calculation for asin1 on 2023-02-07\n",
            "Entropy calculated: 4.909\n",
            "Mutual information: asin1 vs aimp on 2023-02-07\n",
            "MI calculated: 0.000\n",
            "Processing column: asin2\n",
            "Basic metrics for asin2 on 2023-02-07\n",
            "Distribution metrics for asin2 on 2023-02-07\n",
            "Quantile metrics for asin2 on 2023-02-07\n",
            "Entropy calculation for asin2 on 2023-02-07\n",
            "Entropy calculated: 5.377\n",
            "Mutual information: asin2 vs aimp on 2023-02-07\n",
            "MI calculated: 0.000\n",
            "Processing column: adbr\n",
            "Basic metrics for adbr on 2023-02-07\n",
            "Distribution metrics for adbr on 2023-02-07\n",
            "Quantile metrics for adbr on 2023-02-07\n",
            "Entropy calculation for adbr on 2023-02-07\n",
            "Entropy calculated: 1.000\n",
            "Mutual information: adbr vs aimp on 2023-02-07\n",
            "MI calculated: 0.000\n",
            "Processing column: adfl\n",
            "Basic metrics for adfl on 2023-02-07\n",
            "Distribution metrics for adfl on 2023-02-07\n",
            "Quantile metrics for adfl on 2023-02-07\n",
            "Entropy calculation for adfl on 2023-02-07\n",
            "Entropy calculated: 0.969\n",
            "Mutual information: adfl vs aimp on 2023-02-07\n",
            "MI calculated: 0.000\n",
            "Processing column: bed1\n",
            "Basic metrics for bed1 on 2023-02-07\n",
            "Distribution metrics for bed1 on 2023-02-07\n",
            "Quantile metrics for bed1 on 2023-02-07\n",
            "Entropy calculation for bed1 on 2023-02-07\n",
            "Entropy calculated: 3.933\n",
            "Mutual information: bed1 vs aimp on 2023-02-07\n",
            "MI calculated: 0.012\n",
            "Processing column: bed2\n",
            "Basic metrics for bed2 on 2023-02-07\n",
            "Distribution metrics for bed2 on 2023-02-07\n",
            "Quantile metrics for bed2 on 2023-02-07\n",
            "Entropy calculation for bed2 on 2023-02-07\n",
            "Entropy calculated: 2.338\n",
            "Mutual information: bed2 vs aimp on 2023-02-07\n",
            "MI calculated: 0.045\n",
            "Processing column: bfo1\n",
            "Basic metrics for bfo1 on 2023-02-07\n",
            "Distribution metrics for bfo1 on 2023-02-07\n",
            "Quantile metrics for bfo1 on 2023-02-07\n",
            "Entropy calculation for bfo1 on 2023-02-07\n",
            "Entropy calculated: 4.302\n",
            "Mutual information: bfo1 vs aimp on 2023-02-07\n",
            "MI calculated: 0.000\n",
            "Processing column: bfo2\n",
            "Basic metrics for bfo2 on 2023-02-07\n",
            "Distribution metrics for bfo2 on 2023-02-07\n",
            "Quantile metrics for bfo2 on 2023-02-07\n",
            "Entropy calculation for bfo2 on 2023-02-07\n",
            "Entropy calculated: 5.424\n",
            "Mutual information: bfo2 vs aimp on 2023-02-07\n",
            "MI calculated: 0.000\n",
            "Processing column: bso1\n",
            "Basic metrics for bso1 on 2023-02-07\n",
            "Distribution metrics for bso1 on 2023-02-07\n",
            "Quantile metrics for bso1 on 2023-02-07\n",
            "Entropy calculation for bso1 on 2023-02-07\n",
            "Entropy calculated: 2.870\n",
            "Mutual information: bso1 vs aimp on 2023-02-07\n",
            "MI calculated: 0.000\n",
            "Processing column: bso2\n",
            "Basic metrics for bso2 on 2023-02-07\n",
            "Distribution metrics for bso2 on 2023-02-07\n",
            "Quantile metrics for bso2 on 2023-02-07\n",
            "Entropy calculation for bso2 on 2023-02-07\n",
            "Entropy calculated: 5.516\n",
            "Mutual information: bso2 vs aimp on 2023-02-07\n",
            "MI calculated: 0.000\n",
            "Processing column: bso3\n",
            "Basic metrics for bso3 on 2023-02-07\n",
            "Distribution metrics for bso3 on 2023-02-07\n",
            "Quantile metrics for bso3 on 2023-02-07\n",
            "Entropy calculation for bso3 on 2023-02-07\n",
            "Entropy calculated: 5.393\n",
            "Mutual information: bso3 vs aimp on 2023-02-07\n",
            "MI calculated: 0.000\n",
            "Processing column: ced1\n",
            "Basic metrics for ced1 on 2023-02-07\n",
            "Distribution metrics for ced1 on 2023-02-07\n",
            "Quantile metrics for ced1 on 2023-02-07\n",
            "Entropy calculation for ced1 on 2023-02-07\n",
            "Entropy calculated: 4.447\n",
            "Mutual information: ced1 vs aimp on 2023-02-07\n",
            "MI calculated: 0.000\n",
            "Processing column: cfo1\n",
            "Basic metrics for cfo1 on 2023-02-07\n",
            "Distribution metrics for cfo1 on 2023-02-07\n",
            "Quantile metrics for cfo1 on 2023-02-07\n",
            "Entropy calculation for cfo1 on 2023-02-07\n",
            "Entropy calculated: 3.904\n",
            "Mutual information: cfo1 vs aimp on 2023-02-07\n",
            "MI calculated: 0.000\n",
            "Processing column: cso1\n",
            "Basic metrics for cso1 on 2023-02-07\n",
            "Distribution metrics for cso1 on 2023-02-07\n",
            "Quantile metrics for cso1 on 2023-02-07\n",
            "Entropy calculation for cso1 on 2023-02-07\n",
            "Entropy calculated: 5.345\n",
            "Mutual information: cso1 vs aimp on 2023-02-07\n",
            "MI calculated: 0.000\n",
            "Processing column: y\n",
            "Basic metrics for y on 2023-02-07\n",
            "Distribution metrics for y on 2023-02-07\n",
            "Quantile metrics for y on 2023-02-07\n",
            "Entropy calculation for y on 2023-02-07\n",
            "Entropy calculated: 0.265\n",
            "Mutual information: y vs aimp on 2023-02-07\n",
            "MI calculated: 0.000\n",
            "Processing column: category\n",
            "Basic metrics for category on 2023-02-07\n",
            "Distribution metrics for category on 2023-02-07\n",
            "Quantile metrics for category on 2023-02-07\n",
            "Entropy calculation for category on 2023-02-07\n",
            "Entropy calculated: 0.335\n",
            "Mutual information: category vs aimp on 2023-02-07\n",
            "MI calculated: 0.000\n",
            "Completed 2023-02-07 - Generated 662 features\n",
            "Processing date 39/58: 2023-02-08\n",
            "Processing 86400 records\n",
            "Correlation matrix for 2023-02-08\n",
            "Correlation matrix calculated for 19 columns\n",
            "Processing column: aimp\n",
            "Basic metrics for aimp on 2023-02-08\n",
            "Distribution metrics for aimp on 2023-02-08\n",
            "Quantile metrics for aimp on 2023-02-08\n",
            "Entropy calculation for aimp on 2023-02-08\n",
            "Entropy calculated: 0.083\n",
            "Processing column: amud\n",
            "Basic metrics for amud on 2023-02-08\n",
            "Distribution metrics for amud on 2023-02-08\n",
            "Quantile metrics for amud on 2023-02-08\n",
            "Entropy calculation for amud on 2023-02-08\n",
            "Entropy calculated: 4.502\n",
            "Mutual information: amud vs aimp on 2023-02-08\n",
            "MI calculated: 0.000\n",
            "Processing column: arnd\n",
            "Basic metrics for arnd on 2023-02-08\n",
            "Distribution metrics for arnd on 2023-02-08\n",
            "Quantile metrics for arnd on 2023-02-08\n",
            "Entropy calculation for arnd on 2023-02-08\n",
            "Entropy calculated: 4.706\n",
            "Mutual information: arnd vs aimp on 2023-02-08\n",
            "MI calculated: 0.000\n",
            "Processing column: asin1\n",
            "Basic metrics for asin1 on 2023-02-08\n",
            "Distribution metrics for asin1 on 2023-02-08\n",
            "Quantile metrics for asin1 on 2023-02-08\n",
            "Entropy calculation for asin1 on 2023-02-08\n",
            "Entropy calculated: 5.517\n",
            "Mutual information: asin1 vs aimp on 2023-02-08\n",
            "MI calculated: 0.000\n",
            "Processing column: asin2\n",
            "Basic metrics for asin2 on 2023-02-08\n",
            "Distribution metrics for asin2 on 2023-02-08\n",
            "Quantile metrics for asin2 on 2023-02-08\n",
            "Entropy calculation for asin2 on 2023-02-08\n",
            "Entropy calculated: 5.362\n",
            "Mutual information: asin2 vs aimp on 2023-02-08\n",
            "MI calculated: 0.000\n",
            "Processing column: adbr\n",
            "Basic metrics for adbr on 2023-02-08\n",
            "Distribution metrics for adbr on 2023-02-08\n",
            "Quantile metrics for adbr on 2023-02-08\n",
            "Entropy calculation for adbr on 2023-02-08\n",
            "Entropy calculated: 0.998\n",
            "Mutual information: adbr vs aimp on 2023-02-08\n",
            "MI calculated: 0.000\n",
            "Processing column: adfl\n",
            "Basic metrics for adfl on 2023-02-08\n",
            "Distribution metrics for adfl on 2023-02-08\n",
            "Quantile metrics for adfl on 2023-02-08\n",
            "Entropy calculation for adfl on 2023-02-08\n",
            "Entropy calculated: 0.974\n",
            "Mutual information: adfl vs aimp on 2023-02-08\n",
            "MI calculated: 0.000\n",
            "Processing column: bed1\n",
            "Basic metrics for bed1 on 2023-02-08\n",
            "Distribution metrics for bed1 on 2023-02-08\n",
            "Quantile metrics for bed1 on 2023-02-08\n",
            "Entropy calculation for bed1 on 2023-02-08\n",
            "Entropy calculated: 4.735\n",
            "Mutual information: bed1 vs aimp on 2023-02-08\n",
            "MI calculated: 0.014\n",
            "Processing column: bed2\n",
            "Basic metrics for bed2 on 2023-02-08\n",
            "Distribution metrics for bed2 on 2023-02-08\n",
            "Quantile metrics for bed2 on 2023-02-08\n",
            "Entropy calculation for bed2 on 2023-02-08\n",
            "Entropy calculated: 2.803\n",
            "Mutual information: bed2 vs aimp on 2023-02-08\n",
            "MI calculated: 0.047\n",
            "Processing column: bfo1\n",
            "Basic metrics for bfo1 on 2023-02-08\n",
            "Distribution metrics for bfo1 on 2023-02-08\n",
            "Quantile metrics for bfo1 on 2023-02-08\n",
            "Entropy calculation for bfo1 on 2023-02-08\n",
            "Entropy calculated: 4.449\n",
            "Mutual information: bfo1 vs aimp on 2023-02-08\n",
            "MI calculated: 0.000\n",
            "Processing column: bfo2\n",
            "Basic metrics for bfo2 on 2023-02-08\n",
            "Distribution metrics for bfo2 on 2023-02-08\n",
            "Quantile metrics for bfo2 on 2023-02-08\n",
            "Entropy calculation for bfo2 on 2023-02-08\n",
            "Entropy calculated: 5.101\n",
            "Mutual information: bfo2 vs aimp on 2023-02-08\n",
            "MI calculated: 0.000\n",
            "Processing column: bso1\n",
            "Basic metrics for bso1 on 2023-02-08\n",
            "Distribution metrics for bso1 on 2023-02-08\n",
            "Quantile metrics for bso1 on 2023-02-08\n",
            "Entropy calculation for bso1 on 2023-02-08\n",
            "Entropy calculated: 4.878\n",
            "Mutual information: bso1 vs aimp on 2023-02-08\n",
            "MI calculated: 0.000\n",
            "Processing column: bso2\n",
            "Basic metrics for bso2 on 2023-02-08\n",
            "Distribution metrics for bso2 on 2023-02-08\n",
            "Quantile metrics for bso2 on 2023-02-08\n",
            "Entropy calculation for bso2 on 2023-02-08\n",
            "Entropy calculated: 5.528\n",
            "Mutual information: bso2 vs aimp on 2023-02-08\n",
            "MI calculated: 0.000\n",
            "Processing column: bso3\n",
            "Basic metrics for bso3 on 2023-02-08\n",
            "Distribution metrics for bso3 on 2023-02-08\n",
            "Quantile metrics for bso3 on 2023-02-08\n",
            "Entropy calculation for bso3 on 2023-02-08\n",
            "Entropy calculated: 5.395\n",
            "Mutual information: bso3 vs aimp on 2023-02-08\n",
            "MI calculated: 0.000\n",
            "Processing column: ced1\n",
            "Basic metrics for ced1 on 2023-02-08\n",
            "Distribution metrics for ced1 on 2023-02-08\n",
            "Quantile metrics for ced1 on 2023-02-08\n",
            "Entropy calculation for ced1 on 2023-02-08\n",
            "Entropy calculated: 5.131\n",
            "Mutual information: ced1 vs aimp on 2023-02-08\n",
            "MI calculated: 0.000\n",
            "Processing column: cfo1\n",
            "Basic metrics for cfo1 on 2023-02-08\n",
            "Distribution metrics for cfo1 on 2023-02-08\n",
            "Quantile metrics for cfo1 on 2023-02-08\n",
            "Entropy calculation for cfo1 on 2023-02-08\n",
            "Entropy calculated: 5.195\n",
            "Mutual information: cfo1 vs aimp on 2023-02-08\n",
            "MI calculated: 0.000\n",
            "Processing column: cso1\n",
            "Basic metrics for cso1 on 2023-02-08\n",
            "Distribution metrics for cso1 on 2023-02-08\n",
            "Quantile metrics for cso1 on 2023-02-08\n",
            "Entropy calculation for cso1 on 2023-02-08\n",
            "Entropy calculated: 5.236\n",
            "Mutual information: cso1 vs aimp on 2023-02-08\n",
            "MI calculated: 0.000\n",
            "Processing column: y\n",
            "Basic metrics for y on 2023-02-08\n",
            "Distribution metrics for y on 2023-02-08\n",
            "Quantile metrics for y on 2023-02-08\n",
            "Entropy calculation for y on 2023-02-08\n",
            "Entropy calculated: 0.159\n",
            "Mutual information: y vs aimp on 2023-02-08\n",
            "MI calculated: 0.000\n",
            "Processing column: category\n",
            "Basic metrics for category on 2023-02-08\n",
            "Distribution metrics for category on 2023-02-08\n",
            "Quantile metrics for category on 2023-02-08\n",
            "Entropy calculation for category on 2023-02-08\n",
            "Entropy calculated: 0.159\n",
            "Mutual information: category vs aimp on 2023-02-08\n",
            "MI calculated: 0.000\n",
            "Completed 2023-02-08 - Generated 662 features\n",
            "Processing date 40/58: 2023-02-09\n",
            "Processing 86400 records\n",
            "Correlation matrix for 2023-02-09\n",
            "Correlation matrix calculated for 19 columns\n",
            "Processing column: aimp\n",
            "Basic metrics for aimp on 2023-02-09\n",
            "Distribution metrics for aimp on 2023-02-09\n",
            "Quantile metrics for aimp on 2023-02-09\n",
            "Entropy calculation for aimp on 2023-02-09\n",
            "Entropy calculated: 0.080\n",
            "Processing column: amud\n",
            "Basic metrics for amud on 2023-02-09\n",
            "Distribution metrics for amud on 2023-02-09\n",
            "Quantile metrics for amud on 2023-02-09\n",
            "Entropy calculation for amud on 2023-02-09\n",
            "Entropy calculated: 4.495\n",
            "Mutual information: amud vs aimp on 2023-02-09\n",
            "MI calculated: 0.000\n",
            "Processing column: arnd\n",
            "Basic metrics for arnd on 2023-02-09\n",
            "Distribution metrics for arnd on 2023-02-09\n",
            "Quantile metrics for arnd on 2023-02-09\n",
            "Entropy calculation for arnd on 2023-02-09\n",
            "Entropy calculated: 4.673\n",
            "Mutual information: arnd vs aimp on 2023-02-09\n",
            "MI calculated: 0.000\n",
            "Processing column: asin1\n",
            "Basic metrics for asin1 on 2023-02-09\n",
            "Distribution metrics for asin1 on 2023-02-09\n",
            "Quantile metrics for asin1 on 2023-02-09\n",
            "Entropy calculation for asin1 on 2023-02-09\n",
            "Entropy calculated: 5.110\n",
            "Mutual information: asin1 vs aimp on 2023-02-09\n",
            "MI calculated: 0.000\n",
            "Processing column: asin2\n",
            "Basic metrics for asin2 on 2023-02-09\n",
            "Distribution metrics for asin2 on 2023-02-09\n",
            "Quantile metrics for asin2 on 2023-02-09\n",
            "Entropy calculation for asin2 on 2023-02-09\n",
            "Entropy calculated: 5.377\n",
            "Mutual information: asin2 vs aimp on 2023-02-09\n",
            "MI calculated: 0.000\n",
            "Processing column: adbr\n",
            "Basic metrics for adbr on 2023-02-09\n",
            "Distribution metrics for adbr on 2023-02-09\n",
            "Quantile metrics for adbr on 2023-02-09\n",
            "Entropy calculation for adbr on 2023-02-09\n",
            "Entropy calculated: 0.999\n",
            "Mutual information: adbr vs aimp on 2023-02-09\n",
            "MI calculated: 0.000\n",
            "Processing column: adfl\n",
            "Basic metrics for adfl on 2023-02-09\n",
            "Distribution metrics for adfl on 2023-02-09\n",
            "Quantile metrics for adfl on 2023-02-09\n",
            "Entropy calculation for adfl on 2023-02-09\n",
            "Entropy calculated: 0.968\n",
            "Mutual information: adfl vs aimp on 2023-02-09\n",
            "MI calculated: 0.000\n",
            "Processing column: bed1\n",
            "Basic metrics for bed1 on 2023-02-09\n",
            "Distribution metrics for bed1 on 2023-02-09\n",
            "Quantile metrics for bed1 on 2023-02-09\n",
            "Entropy calculation for bed1 on 2023-02-09\n",
            "Entropy calculated: 4.008\n",
            "Mutual information: bed1 vs aimp on 2023-02-09\n",
            "MI calculated: 0.013\n",
            "Processing column: bed2\n",
            "Basic metrics for bed2 on 2023-02-09\n",
            "Distribution metrics for bed2 on 2023-02-09\n",
            "Quantile metrics for bed2 on 2023-02-09\n",
            "Entropy calculation for bed2 on 2023-02-09\n",
            "Entropy calculated: 2.498\n",
            "Mutual information: bed2 vs aimp on 2023-02-09\n",
            "MI calculated: 0.039\n",
            "Processing column: bfo1\n",
            "Basic metrics for bfo1 on 2023-02-09\n",
            "Distribution metrics for bfo1 on 2023-02-09\n",
            "Quantile metrics for bfo1 on 2023-02-09\n",
            "Entropy calculation for bfo1 on 2023-02-09\n",
            "Entropy calculated: 4.386\n",
            "Mutual information: bfo1 vs aimp on 2023-02-09\n",
            "MI calculated: 0.000\n",
            "Processing column: bfo2\n",
            "Basic metrics for bfo2 on 2023-02-09\n",
            "Distribution metrics for bfo2 on 2023-02-09\n",
            "Quantile metrics for bfo2 on 2023-02-09\n",
            "Entropy calculation for bfo2 on 2023-02-09\n",
            "Entropy calculated: 3.333\n",
            "Mutual information: bfo2 vs aimp on 2023-02-09\n",
            "MI calculated: 0.000\n",
            "Processing column: bso1\n",
            "Basic metrics for bso1 on 2023-02-09\n",
            "Distribution metrics for bso1 on 2023-02-09\n",
            "Quantile metrics for bso1 on 2023-02-09\n",
            "Entropy calculation for bso1 on 2023-02-09\n",
            "Entropy calculated: 5.018\n",
            "Mutual information: bso1 vs aimp on 2023-02-09\n",
            "MI calculated: 0.000\n",
            "Processing column: bso2\n",
            "Basic metrics for bso2 on 2023-02-09\n",
            "Distribution metrics for bso2 on 2023-02-09\n",
            "Quantile metrics for bso2 on 2023-02-09\n",
            "Entropy calculation for bso2 on 2023-02-09\n",
            "Entropy calculated: 5.517\n",
            "Mutual information: bso2 vs aimp on 2023-02-09\n",
            "MI calculated: 0.000\n",
            "Processing column: bso3\n",
            "Basic metrics for bso3 on 2023-02-09\n",
            "Distribution metrics for bso3 on 2023-02-09\n",
            "Quantile metrics for bso3 on 2023-02-09\n",
            "Entropy calculation for bso3 on 2023-02-09\n",
            "Entropy calculated: 4.475\n",
            "Mutual information: bso3 vs aimp on 2023-02-09\n",
            "MI calculated: 0.000\n",
            "Processing column: ced1\n",
            "Basic metrics for ced1 on 2023-02-09\n",
            "Distribution metrics for ced1 on 2023-02-09\n",
            "Quantile metrics for ced1 on 2023-02-09\n",
            "Entropy calculation for ced1 on 2023-02-09\n",
            "Entropy calculated: 4.691\n",
            "Mutual information: ced1 vs aimp on 2023-02-09\n",
            "MI calculated: 0.000\n",
            "Processing column: cfo1\n",
            "Basic metrics for cfo1 on 2023-02-09\n",
            "Distribution metrics for cfo1 on 2023-02-09\n",
            "Quantile metrics for cfo1 on 2023-02-09\n",
            "Entropy calculation for cfo1 on 2023-02-09\n",
            "Entropy calculated: 5.103\n",
            "Mutual information: cfo1 vs aimp on 2023-02-09\n",
            "MI calculated: 0.000\n",
            "Processing column: cso1\n",
            "Basic metrics for cso1 on 2023-02-09\n",
            "Distribution metrics for cso1 on 2023-02-09\n",
            "Quantile metrics for cso1 on 2023-02-09\n",
            "Entropy calculation for cso1 on 2023-02-09\n",
            "Entropy calculated: 3.934\n",
            "Mutual information: cso1 vs aimp on 2023-02-09\n",
            "MI calculated: 0.000\n",
            "Processing column: y\n",
            "Basic metrics for y on 2023-02-09\n",
            "Distribution metrics for y on 2023-02-09\n",
            "Quantile metrics for y on 2023-02-09\n",
            "Entropy calculation for y on 2023-02-09\n",
            "Entropy calculated: 0.260\n",
            "Mutual information: y vs aimp on 2023-02-09\n",
            "MI calculated: 0.000\n",
            "Processing column: category\n",
            "Basic metrics for category on 2023-02-09\n",
            "Distribution metrics for category on 2023-02-09\n",
            "Quantile metrics for category on 2023-02-09\n",
            "Entropy calculation for category on 2023-02-09\n",
            "Entropy calculated: 0.317\n",
            "Mutual information: category vs aimp on 2023-02-09\n",
            "MI calculated: 0.000\n",
            "Completed 2023-02-09 - Generated 662 features\n",
            "Processing date 41/58: 2023-02-10\n",
            "Processing 86400 records\n",
            "Correlation matrix for 2023-02-10\n",
            "Correlation matrix calculated for 19 columns\n",
            "Processing column: aimp\n",
            "Basic metrics for aimp on 2023-02-10\n",
            "Distribution metrics for aimp on 2023-02-10\n",
            "Quantile metrics for aimp on 2023-02-10\n",
            "Entropy calculation for aimp on 2023-02-10\n",
            "Entropy calculated: 0.079\n",
            "Processing column: amud\n",
            "Basic metrics for amud on 2023-02-10\n",
            "Distribution metrics for amud on 2023-02-10\n",
            "Quantile metrics for amud on 2023-02-10\n",
            "Entropy calculation for amud on 2023-02-10\n",
            "Entropy calculated: 4.480\n",
            "Mutual information: amud vs aimp on 2023-02-10\n",
            "MI calculated: 0.000\n",
            "Processing column: arnd\n",
            "Basic metrics for arnd on 2023-02-10\n",
            "Distribution metrics for arnd on 2023-02-10\n",
            "Quantile metrics for arnd on 2023-02-10\n",
            "Entropy calculation for arnd on 2023-02-10\n",
            "Entropy calculated: 5.148\n",
            "Mutual information: arnd vs aimp on 2023-02-10\n",
            "MI calculated: 0.000\n",
            "Processing column: asin1\n",
            "Basic metrics for asin1 on 2023-02-10\n",
            "Distribution metrics for asin1 on 2023-02-10\n",
            "Quantile metrics for asin1 on 2023-02-10\n",
            "Entropy calculation for asin1 on 2023-02-10\n",
            "Entropy calculated: 5.091\n",
            "Mutual information: asin1 vs aimp on 2023-02-10\n",
            "MI calculated: 0.000\n",
            "Processing column: asin2\n",
            "Basic metrics for asin2 on 2023-02-10\n",
            "Distribution metrics for asin2 on 2023-02-10\n",
            "Quantile metrics for asin2 on 2023-02-10\n",
            "Entropy calculation for asin2 on 2023-02-10\n",
            "Entropy calculated: 5.362\n",
            "Mutual information: asin2 vs aimp on 2023-02-10\n",
            "MI calculated: 0.000\n",
            "Processing column: adbr\n",
            "Basic metrics for adbr on 2023-02-10\n",
            "Distribution metrics for adbr on 2023-02-10\n",
            "Quantile metrics for adbr on 2023-02-10\n",
            "Entropy calculation for adbr on 2023-02-10\n",
            "Entropy calculated: 0.999\n",
            "Mutual information: adbr vs aimp on 2023-02-10\n",
            "MI calculated: 0.000\n",
            "Processing column: adfl\n",
            "Basic metrics for adfl on 2023-02-10\n",
            "Distribution metrics for adfl on 2023-02-10\n",
            "Quantile metrics for adfl on 2023-02-10\n",
            "Entropy calculation for adfl on 2023-02-10\n",
            "Entropy calculated: 0.975\n",
            "Mutual information: adfl vs aimp on 2023-02-10\n",
            "MI calculated: 0.000\n",
            "Processing column: bed1\n",
            "Basic metrics for bed1 on 2023-02-10\n",
            "Distribution metrics for bed1 on 2023-02-10\n",
            "Quantile metrics for bed1 on 2023-02-10\n",
            "Entropy calculation for bed1 on 2023-02-10\n",
            "Entropy calculated: 2.929\n",
            "Mutual information: bed1 vs aimp on 2023-02-10\n",
            "MI calculated: 0.007\n",
            "Processing column: bed2\n",
            "Basic metrics for bed2 on 2023-02-10\n",
            "Distribution metrics for bed2 on 2023-02-10\n",
            "Quantile metrics for bed2 on 2023-02-10\n",
            "Entropy calculation for bed2 on 2023-02-10\n",
            "Entropy calculated: 2.741\n",
            "Mutual information: bed2 vs aimp on 2023-02-10\n",
            "MI calculated: 0.043\n",
            "Processing column: bfo1\n",
            "Basic metrics for bfo1 on 2023-02-10\n",
            "Distribution metrics for bfo1 on 2023-02-10\n",
            "Quantile metrics for bfo1 on 2023-02-10\n",
            "Entropy calculation for bfo1 on 2023-02-10\n",
            "Entropy calculated: 2.646\n",
            "Mutual information: bfo1 vs aimp on 2023-02-10\n",
            "MI calculated: 0.000\n",
            "Processing column: bfo2\n",
            "Basic metrics for bfo2 on 2023-02-10\n",
            "Distribution metrics for bfo2 on 2023-02-10\n",
            "Quantile metrics for bfo2 on 2023-02-10\n",
            "Entropy calculation for bfo2 on 2023-02-10\n",
            "Entropy calculated: 4.802\n",
            "Mutual information: bfo2 vs aimp on 2023-02-10\n",
            "MI calculated: 0.000\n",
            "Processing column: bso1\n",
            "Basic metrics for bso1 on 2023-02-10\n",
            "Distribution metrics for bso1 on 2023-02-10\n",
            "Quantile metrics for bso1 on 2023-02-10\n",
            "Entropy calculation for bso1 on 2023-02-10\n",
            "Entropy calculated: 4.797\n",
            "Mutual information: bso1 vs aimp on 2023-02-10\n",
            "MI calculated: 0.000\n",
            "Processing column: bso2\n",
            "Basic metrics for bso2 on 2023-02-10\n",
            "Distribution metrics for bso2 on 2023-02-10\n",
            "Quantile metrics for bso2 on 2023-02-10\n",
            "Entropy calculation for bso2 on 2023-02-10\n",
            "Entropy calculated: 5.529\n",
            "Mutual information: bso2 vs aimp on 2023-02-10\n",
            "MI calculated: 0.000\n",
            "Processing column: bso3\n",
            "Basic metrics for bso3 on 2023-02-10\n",
            "Distribution metrics for bso3 on 2023-02-10\n",
            "Quantile metrics for bso3 on 2023-02-10\n",
            "Entropy calculation for bso3 on 2023-02-10\n",
            "Entropy calculated: 5.268\n",
            "Mutual information: bso3 vs aimp on 2023-02-10\n",
            "MI calculated: 0.000\n",
            "Processing column: ced1\n",
            "Basic metrics for ced1 on 2023-02-10\n",
            "Distribution metrics for ced1 on 2023-02-10\n",
            "Quantile metrics for ced1 on 2023-02-10\n",
            "Entropy calculation for ced1 on 2023-02-10\n",
            "Entropy calculated: 3.927\n",
            "Mutual information: ced1 vs aimp on 2023-02-10\n",
            "MI calculated: 0.000\n",
            "Processing column: cfo1\n",
            "Basic metrics for cfo1 on 2023-02-10\n",
            "Distribution metrics for cfo1 on 2023-02-10\n",
            "Quantile metrics for cfo1 on 2023-02-10\n",
            "Entropy calculation for cfo1 on 2023-02-10\n",
            "Entropy calculated: 4.230\n",
            "Mutual information: cfo1 vs aimp on 2023-02-10\n",
            "MI calculated: 0.000\n",
            "Processing column: cso1\n",
            "Basic metrics for cso1 on 2023-02-10\n",
            "Distribution metrics for cso1 on 2023-02-10\n",
            "Quantile metrics for cso1 on 2023-02-10\n",
            "Entropy calculation for cso1 on 2023-02-10\n",
            "Entropy calculated: 5.294\n",
            "Mutual information: cso1 vs aimp on 2023-02-10\n",
            "MI calculated: 0.000\n",
            "Processing column: y\n",
            "Basic metrics for y on 2023-02-10\n",
            "Distribution metrics for y on 2023-02-10\n",
            "Quantile metrics for y on 2023-02-10\n",
            "Entropy calculation for y on 2023-02-10\n",
            "Entropy calculated: 0.159\n",
            "Mutual information: y vs aimp on 2023-02-10\n",
            "MI calculated: 0.000\n",
            "Processing column: category\n",
            "Basic metrics for category on 2023-02-10\n",
            "Distribution metrics for category on 2023-02-10\n",
            "Quantile metrics for category on 2023-02-10\n",
            "Entropy calculation for category on 2023-02-10\n",
            "Entropy calculated: 0.142\n",
            "Mutual information: category vs aimp on 2023-02-10\n",
            "MI calculated: 0.000\n",
            "Completed 2023-02-10 - Generated 662 features\n",
            "Processing date 42/58: 2023-02-11\n",
            "Processing 86400 records\n",
            "Correlation matrix for 2023-02-11\n",
            "Correlation matrix calculated for 19 columns\n",
            "Processing column: aimp\n",
            "Basic metrics for aimp on 2023-02-11\n",
            "Distribution metrics for aimp on 2023-02-11\n",
            "Quantile metrics for aimp on 2023-02-11\n",
            "Entropy calculation for aimp on 2023-02-11\n",
            "Entropy calculated: 0.079\n",
            "Processing column: amud\n",
            "Basic metrics for amud on 2023-02-11\n",
            "Distribution metrics for amud on 2023-02-11\n",
            "Quantile metrics for amud on 2023-02-11\n",
            "Entropy calculation for amud on 2023-02-11\n",
            "Entropy calculated: 4.211\n",
            "Mutual information: amud vs aimp on 2023-02-11\n",
            "MI calculated: 0.000\n",
            "Processing column: arnd\n",
            "Basic metrics for arnd on 2023-02-11\n",
            "Distribution metrics for arnd on 2023-02-11\n",
            "Quantile metrics for arnd on 2023-02-11\n",
            "Entropy calculation for arnd on 2023-02-11\n",
            "Entropy calculated: 5.162\n",
            "Mutual information: arnd vs aimp on 2023-02-11\n",
            "MI calculated: 0.000\n",
            "Processing column: asin1\n",
            "Basic metrics for asin1 on 2023-02-11\n",
            "Distribution metrics for asin1 on 2023-02-11\n",
            "Quantile metrics for asin1 on 2023-02-11\n",
            "Entropy calculation for asin1 on 2023-02-11\n",
            "Entropy calculated: 5.523\n",
            "Mutual information: asin1 vs aimp on 2023-02-11\n",
            "MI calculated: 0.000\n",
            "Processing column: asin2\n",
            "Basic metrics for asin2 on 2023-02-11\n",
            "Distribution metrics for asin2 on 2023-02-11\n",
            "Quantile metrics for asin2 on 2023-02-11\n",
            "Entropy calculation for asin2 on 2023-02-11\n",
            "Entropy calculated: 5.377\n",
            "Mutual information: asin2 vs aimp on 2023-02-11\n",
            "MI calculated: 0.000\n",
            "Processing column: adbr\n",
            "Basic metrics for adbr on 2023-02-11\n",
            "Distribution metrics for adbr on 2023-02-11\n",
            "Quantile metrics for adbr on 2023-02-11\n",
            "Entropy calculation for adbr on 2023-02-11\n",
            "Entropy calculated: 0.999\n",
            "Mutual information: adbr vs aimp on 2023-02-11\n",
            "MI calculated: 0.000\n",
            "Processing column: adfl\n",
            "Basic metrics for adfl on 2023-02-11\n",
            "Distribution metrics for adfl on 2023-02-11\n",
            "Quantile metrics for adfl on 2023-02-11\n",
            "Entropy calculation for adfl on 2023-02-11\n",
            "Entropy calculated: 0.964\n",
            "Mutual information: adfl vs aimp on 2023-02-11\n",
            "MI calculated: 0.000\n",
            "Processing column: bed1\n",
            "Basic metrics for bed1 on 2023-02-11\n",
            "Distribution metrics for bed1 on 2023-02-11\n",
            "Quantile metrics for bed1 on 2023-02-11\n",
            "Entropy calculation for bed1 on 2023-02-11\n",
            "Entropy calculated: 4.768\n",
            "Mutual information: bed1 vs aimp on 2023-02-11\n",
            "MI calculated: 0.014\n",
            "Processing column: bed2\n",
            "Basic metrics for bed2 on 2023-02-11\n",
            "Distribution metrics for bed2 on 2023-02-11\n",
            "Quantile metrics for bed2 on 2023-02-11\n",
            "Entropy calculation for bed2 on 2023-02-11\n",
            "Entropy calculated: 2.859\n",
            "Mutual information: bed2 vs aimp on 2023-02-11\n",
            "MI calculated: 0.039\n",
            "Processing column: bfo1\n",
            "Basic metrics for bfo1 on 2023-02-11\n",
            "Distribution metrics for bfo1 on 2023-02-11\n",
            "Quantile metrics for bfo1 on 2023-02-11\n",
            "Entropy calculation for bfo1 on 2023-02-11\n",
            "Entropy calculated: 4.658\n",
            "Mutual information: bfo1 vs aimp on 2023-02-11\n",
            "MI calculated: 0.000\n",
            "Processing column: bfo2\n",
            "Basic metrics for bfo2 on 2023-02-11\n",
            "Distribution metrics for bfo2 on 2023-02-11\n",
            "Quantile metrics for bfo2 on 2023-02-11\n",
            "Entropy calculation for bfo2 on 2023-02-11\n",
            "Entropy calculated: 2.509\n",
            "Mutual information: bfo2 vs aimp on 2023-02-11\n",
            "MI calculated: 0.000\n",
            "Processing column: bso1\n",
            "Basic metrics for bso1 on 2023-02-11\n",
            "Distribution metrics for bso1 on 2023-02-11\n",
            "Quantile metrics for bso1 on 2023-02-11\n",
            "Entropy calculation for bso1 on 2023-02-11\n",
            "Entropy calculated: 4.647\n",
            "Mutual information: bso1 vs aimp on 2023-02-11\n",
            "MI calculated: 0.000\n",
            "Processing column: bso2\n",
            "Basic metrics for bso2 on 2023-02-11\n",
            "Distribution metrics for bso2 on 2023-02-11\n",
            "Quantile metrics for bso2 on 2023-02-11\n",
            "Entropy calculation for bso2 on 2023-02-11\n",
            "Entropy calculated: 5.509\n",
            "Mutual information: bso2 vs aimp on 2023-02-11\n",
            "MI calculated: 0.000\n",
            "Processing column: bso3\n",
            "Basic metrics for bso3 on 2023-02-11\n",
            "Distribution metrics for bso3 on 2023-02-11\n",
            "Quantile metrics for bso3 on 2023-02-11\n",
            "Entropy calculation for bso3 on 2023-02-11\n",
            "Entropy calculated: 4.123\n",
            "Mutual information: bso3 vs aimp on 2023-02-11\n",
            "MI calculated: 0.000\n",
            "Processing column: ced1\n",
            "Basic metrics for ced1 on 2023-02-11\n",
            "Distribution metrics for ced1 on 2023-02-11\n",
            "Quantile metrics for ced1 on 2023-02-11\n",
            "Entropy calculation for ced1 on 2023-02-11\n",
            "Entropy calculated: 5.145\n",
            "Mutual information: ced1 vs aimp on 2023-02-11\n",
            "MI calculated: 0.000\n",
            "Processing column: cfo1\n",
            "Basic metrics for cfo1 on 2023-02-11\n",
            "Distribution metrics for cfo1 on 2023-02-11\n",
            "Quantile metrics for cfo1 on 2023-02-11\n",
            "Entropy calculation for cfo1 on 2023-02-11\n",
            "Entropy calculated: 5.061\n",
            "Mutual information: cfo1 vs aimp on 2023-02-11\n",
            "MI calculated: 0.000\n",
            "Processing column: cso1\n",
            "Basic metrics for cso1 on 2023-02-11\n",
            "Distribution metrics for cso1 on 2023-02-11\n",
            "Quantile metrics for cso1 on 2023-02-11\n",
            "Entropy calculation for cso1 on 2023-02-11\n",
            "Entropy calculated: 4.094\n",
            "Mutual information: cso1 vs aimp on 2023-02-11\n",
            "MI calculated: 0.000\n",
            "Processing column: y\n",
            "Basic metrics for y on 2023-02-11\n",
            "Distribution metrics for y on 2023-02-11\n",
            "Quantile metrics for y on 2023-02-11\n",
            "Entropy calculation for y on 2023-02-11\n",
            "Entropy calculated: 0.091\n",
            "Mutual information: y vs aimp on 2023-02-11\n",
            "MI calculated: 0.000\n",
            "Processing column: category\n",
            "Basic metrics for category on 2023-02-11\n",
            "Distribution metrics for category on 2023-02-11\n",
            "Quantile metrics for category on 2023-02-11\n",
            "Entropy calculation for category on 2023-02-11\n",
            "Entropy calculated: 0.103\n",
            "Mutual information: category vs aimp on 2023-02-11\n",
            "MI calculated: 0.000\n",
            "Completed 2023-02-11 - Generated 662 features\n",
            "Processing date 43/58: 2023-02-12\n",
            "Processing 86400 records\n",
            "Correlation matrix for 2023-02-12\n",
            "Correlation matrix calculated for 19 columns\n",
            "Processing column: aimp\n",
            "Basic metrics for aimp on 2023-02-12\n",
            "Distribution metrics for aimp on 2023-02-12\n",
            "Quantile metrics for aimp on 2023-02-12\n",
            "Entropy calculation for aimp on 2023-02-12\n",
            "Entropy calculated: 0.082\n",
            "Processing column: amud\n",
            "Basic metrics for amud on 2023-02-12\n",
            "Distribution metrics for amud on 2023-02-12\n",
            "Quantile metrics for amud on 2023-02-12\n",
            "Entropy calculation for amud on 2023-02-12\n",
            "Entropy calculated: 3.791\n",
            "Mutual information: amud vs aimp on 2023-02-12\n",
            "MI calculated: 0.000\n",
            "Processing column: arnd\n",
            "Basic metrics for arnd on 2023-02-12\n",
            "Distribution metrics for arnd on 2023-02-12\n",
            "Quantile metrics for arnd on 2023-02-12\n",
            "Entropy calculation for arnd on 2023-02-12\n",
            "Entropy calculated: 5.601\n",
            "Mutual information: arnd vs aimp on 2023-02-12\n",
            "MI calculated: 0.000\n",
            "Processing column: asin1\n",
            "Basic metrics for asin1 on 2023-02-12\n",
            "Distribution metrics for asin1 on 2023-02-12\n",
            "Quantile metrics for asin1 on 2023-02-12\n",
            "Entropy calculation for asin1 on 2023-02-12\n",
            "Entropy calculated: 4.909\n",
            "Mutual information: asin1 vs aimp on 2023-02-12\n",
            "MI calculated: 0.000\n",
            "Processing column: asin2\n",
            "Basic metrics for asin2 on 2023-02-12\n",
            "Distribution metrics for asin2 on 2023-02-12\n",
            "Quantile metrics for asin2 on 2023-02-12\n",
            "Entropy calculation for asin2 on 2023-02-12\n",
            "Entropy calculated: 5.361\n",
            "Mutual information: asin2 vs aimp on 2023-02-12\n",
            "MI calculated: 0.000\n",
            "Processing column: adbr\n",
            "Basic metrics for adbr on 2023-02-12\n",
            "Distribution metrics for adbr on 2023-02-12\n",
            "Quantile metrics for adbr on 2023-02-12\n",
            "Entropy calculation for adbr on 2023-02-12\n",
            "Entropy calculated: 0.992\n",
            "Mutual information: adbr vs aimp on 2023-02-12\n",
            "MI calculated: 0.000\n",
            "Processing column: adfl\n",
            "Basic metrics for adfl on 2023-02-12\n",
            "Distribution metrics for adfl on 2023-02-12\n",
            "Quantile metrics for adfl on 2023-02-12\n",
            "Entropy calculation for adfl on 2023-02-12\n",
            "Entropy calculated: 0.970\n",
            "Mutual information: adfl vs aimp on 2023-02-12\n",
            "MI calculated: 0.000\n",
            "Processing column: bed1\n",
            "Basic metrics for bed1 on 2023-02-12\n",
            "Distribution metrics for bed1 on 2023-02-12\n",
            "Quantile metrics for bed1 on 2023-02-12\n",
            "Entropy calculation for bed1 on 2023-02-12\n",
            "Entropy calculated: 4.746\n",
            "Mutual information: bed1 vs aimp on 2023-02-12\n",
            "MI calculated: 0.014\n",
            "Processing column: bed2\n",
            "Basic metrics for bed2 on 2023-02-12\n",
            "Distribution metrics for bed2 on 2023-02-12\n",
            "Quantile metrics for bed2 on 2023-02-12\n",
            "Entropy calculation for bed2 on 2023-02-12\n",
            "Entropy calculated: 2.927\n",
            "Mutual information: bed2 vs aimp on 2023-02-12\n",
            "MI calculated: 0.040\n",
            "Processing column: bfo1\n",
            "Basic metrics for bfo1 on 2023-02-12\n",
            "Distribution metrics for bfo1 on 2023-02-12\n",
            "Quantile metrics for bfo1 on 2023-02-12\n",
            "Entropy calculation for bfo1 on 2023-02-12\n",
            "Entropy calculated: 2.049\n",
            "Mutual information: bfo1 vs aimp on 2023-02-12\n",
            "MI calculated: 0.000\n",
            "Processing column: bfo2\n",
            "Basic metrics for bfo2 on 2023-02-12\n",
            "Distribution metrics for bfo2 on 2023-02-12\n",
            "Quantile metrics for bfo2 on 2023-02-12\n",
            "Entropy calculation for bfo2 on 2023-02-12\n",
            "Entropy calculated: 2.409\n",
            "Mutual information: bfo2 vs aimp on 2023-02-12\n",
            "MI calculated: 0.000\n",
            "Processing column: bso1\n",
            "Basic metrics for bso1 on 2023-02-12\n",
            "Distribution metrics for bso1 on 2023-02-12\n",
            "Quantile metrics for bso1 on 2023-02-12\n",
            "Entropy calculation for bso1 on 2023-02-12\n",
            "Entropy calculated: 5.110\n",
            "Mutual information: bso1 vs aimp on 2023-02-12\n",
            "MI calculated: 0.000\n",
            "Processing column: bso2\n",
            "Basic metrics for bso2 on 2023-02-12\n",
            "Distribution metrics for bso2 on 2023-02-12\n",
            "Quantile metrics for bso2 on 2023-02-12\n",
            "Entropy calculation for bso2 on 2023-02-12\n",
            "Entropy calculated: 3.788\n",
            "Mutual information: bso2 vs aimp on 2023-02-12\n",
            "MI calculated: 0.000\n",
            "Processing column: bso3\n",
            "Basic metrics for bso3 on 2023-02-12\n",
            "Distribution metrics for bso3 on 2023-02-12\n",
            "Quantile metrics for bso3 on 2023-02-12\n",
            "Entropy calculation for bso3 on 2023-02-12\n",
            "Entropy calculated: 5.345\n",
            "Mutual information: bso3 vs aimp on 2023-02-12\n",
            "MI calculated: 0.000\n",
            "Processing column: ced1\n",
            "Basic metrics for ced1 on 2023-02-12\n",
            "Distribution metrics for ced1 on 2023-02-12\n",
            "Quantile metrics for ced1 on 2023-02-12\n",
            "Entropy calculation for ced1 on 2023-02-12\n",
            "Entropy calculated: 5.247\n",
            "Mutual information: ced1 vs aimp on 2023-02-12\n",
            "MI calculated: 0.000\n",
            "Processing column: cfo1\n",
            "Basic metrics for cfo1 on 2023-02-12\n",
            "Distribution metrics for cfo1 on 2023-02-12\n",
            "Quantile metrics for cfo1 on 2023-02-12\n",
            "Entropy calculation for cfo1 on 2023-02-12\n",
            "Entropy calculated: 4.900\n",
            "Mutual information: cfo1 vs aimp on 2023-02-12\n",
            "MI calculated: 0.000\n",
            "Processing column: cso1\n",
            "Basic metrics for cso1 on 2023-02-12\n",
            "Distribution metrics for cso1 on 2023-02-12\n",
            "Quantile metrics for cso1 on 2023-02-12\n",
            "Entropy calculation for cso1 on 2023-02-12\n",
            "Entropy calculated: 4.040\n",
            "Mutual information: cso1 vs aimp on 2023-02-12\n",
            "MI calculated: 0.000\n",
            "Processing column: y\n",
            "Basic metrics for y on 2023-02-12\n",
            "Distribution metrics for y on 2023-02-12\n",
            "Quantile metrics for y on 2023-02-12\n",
            "Entropy calculation for y on 2023-02-12\n",
            "Entropy calculated: 0.098\n",
            "Mutual information: y vs aimp on 2023-02-12\n",
            "MI calculated: 0.000\n",
            "Processing column: category\n",
            "Basic metrics for category on 2023-02-12\n",
            "Distribution metrics for category on 2023-02-12\n",
            "Quantile metrics for category on 2023-02-12\n",
            "Entropy calculation for category on 2023-02-12\n",
            "Entropy calculated: 0.076\n",
            "Mutual information: category vs aimp on 2023-02-12\n",
            "MI calculated: 0.000\n",
            "Completed 2023-02-12 - Generated 662 features\n",
            "Processing date 44/58: 2023-02-13\n",
            "Processing 86400 records\n",
            "Correlation matrix for 2023-02-13\n",
            "Correlation matrix calculated for 19 columns\n",
            "Processing column: aimp\n",
            "Basic metrics for aimp on 2023-02-13\n",
            "Distribution metrics for aimp on 2023-02-13\n",
            "Quantile metrics for aimp on 2023-02-13\n",
            "Entropy calculation for aimp on 2023-02-13\n",
            "Entropy calculated: 0.081\n",
            "Processing column: amud\n",
            "Basic metrics for amud on 2023-02-13\n",
            "Distribution metrics for amud on 2023-02-13\n",
            "Quantile metrics for amud on 2023-02-13\n",
            "Entropy calculation for amud on 2023-02-13\n",
            "Entropy calculated: 4.106\n",
            "Mutual information: amud vs aimp on 2023-02-13\n",
            "MI calculated: 0.000\n",
            "Processing column: arnd\n",
            "Basic metrics for arnd on 2023-02-13\n",
            "Distribution metrics for arnd on 2023-02-13\n",
            "Quantile metrics for arnd on 2023-02-13\n",
            "Entropy calculation for arnd on 2023-02-13\n",
            "Entropy calculated: 5.246\n",
            "Mutual information: arnd vs aimp on 2023-02-13\n",
            "MI calculated: 0.000\n",
            "Processing column: asin1\n",
            "Basic metrics for asin1 on 2023-02-13\n",
            "Distribution metrics for asin1 on 2023-02-13\n",
            "Quantile metrics for asin1 on 2023-02-13\n",
            "Entropy calculation for asin1 on 2023-02-13\n",
            "Entropy calculated: 5.619\n",
            "Mutual information: asin1 vs aimp on 2023-02-13\n",
            "MI calculated: 0.000\n",
            "Processing column: asin2\n",
            "Basic metrics for asin2 on 2023-02-13\n",
            "Distribution metrics for asin2 on 2023-02-13\n",
            "Quantile metrics for asin2 on 2023-02-13\n",
            "Entropy calculation for asin2 on 2023-02-13\n",
            "Entropy calculated: 5.378\n",
            "Mutual information: asin2 vs aimp on 2023-02-13\n",
            "MI calculated: 0.000\n",
            "Processing column: adbr\n",
            "Basic metrics for adbr on 2023-02-13\n",
            "Distribution metrics for adbr on 2023-02-13\n",
            "Quantile metrics for adbr on 2023-02-13\n",
            "Entropy calculation for adbr on 2023-02-13\n",
            "Entropy calculated: 0.999\n",
            "Mutual information: adbr vs aimp on 2023-02-13\n",
            "MI calculated: 0.000\n",
            "Processing column: adfl\n",
            "Basic metrics for adfl on 2023-02-13\n",
            "Distribution metrics for adfl on 2023-02-13\n",
            "Quantile metrics for adfl on 2023-02-13\n",
            "Entropy calculation for adfl on 2023-02-13\n",
            "Entropy calculated: 0.967\n",
            "Mutual information: adfl vs aimp on 2023-02-13\n",
            "MI calculated: 0.000\n",
            "Processing column: bed1\n",
            "Basic metrics for bed1 on 2023-02-13\n",
            "Distribution metrics for bed1 on 2023-02-13\n",
            "Quantile metrics for bed1 on 2023-02-13\n",
            "Entropy calculation for bed1 on 2023-02-13\n",
            "Entropy calculated: 4.818\n",
            "Mutual information: bed1 vs aimp on 2023-02-13\n",
            "MI calculated: 0.013\n",
            "Processing column: bed2\n",
            "Basic metrics for bed2 on 2023-02-13\n",
            "Distribution metrics for bed2 on 2023-02-13\n",
            "Quantile metrics for bed2 on 2023-02-13\n",
            "Entropy calculation for bed2 on 2023-02-13\n",
            "Entropy calculated: 2.940\n",
            "Mutual information: bed2 vs aimp on 2023-02-13\n",
            "MI calculated: 0.039\n",
            "Processing column: bfo1\n",
            "Basic metrics for bfo1 on 2023-02-13\n",
            "Distribution metrics for bfo1 on 2023-02-13\n",
            "Quantile metrics for bfo1 on 2023-02-13\n",
            "Entropy calculation for bfo1 on 2023-02-13\n",
            "Entropy calculated: 4.715\n",
            "Mutual information: bfo1 vs aimp on 2023-02-13\n",
            "MI calculated: 0.000\n",
            "Processing column: bfo2\n",
            "Basic metrics for bfo2 on 2023-02-13\n",
            "Distribution metrics for bfo2 on 2023-02-13\n",
            "Quantile metrics for bfo2 on 2023-02-13\n",
            "Entropy calculation for bfo2 on 2023-02-13\n",
            "Entropy calculated: 5.189\n",
            "Mutual information: bfo2 vs aimp on 2023-02-13\n",
            "MI calculated: 0.000\n",
            "Processing column: bso1\n",
            "Basic metrics for bso1 on 2023-02-13\n",
            "Distribution metrics for bso1 on 2023-02-13\n",
            "Quantile metrics for bso1 on 2023-02-13\n",
            "Entropy calculation for bso1 on 2023-02-13\n",
            "Entropy calculated: 4.721\n",
            "Mutual information: bso1 vs aimp on 2023-02-13\n",
            "MI calculated: 0.000\n",
            "Processing column: bso2\n",
            "Basic metrics for bso2 on 2023-02-13\n",
            "Distribution metrics for bso2 on 2023-02-13\n",
            "Quantile metrics for bso2 on 2023-02-13\n",
            "Entropy calculation for bso2 on 2023-02-13\n",
            "Entropy calculated: 5.524\n",
            "Mutual information: bso2 vs aimp on 2023-02-13\n",
            "MI calculated: 0.000\n",
            "Processing column: bso3\n",
            "Basic metrics for bso3 on 2023-02-13\n",
            "Distribution metrics for bso3 on 2023-02-13\n",
            "Quantile metrics for bso3 on 2023-02-13\n",
            "Entropy calculation for bso3 on 2023-02-13\n",
            "Entropy calculated: 4.046\n",
            "Mutual information: bso3 vs aimp on 2023-02-13\n",
            "MI calculated: 0.000\n",
            "Processing column: ced1\n",
            "Basic metrics for ced1 on 2023-02-13\n",
            "Distribution metrics for ced1 on 2023-02-13\n",
            "Quantile metrics for ced1 on 2023-02-13\n",
            "Entropy calculation for ced1 on 2023-02-13\n",
            "Entropy calculated: 5.230\n",
            "Mutual information: ced1 vs aimp on 2023-02-13\n",
            "MI calculated: 0.000\n",
            "Processing column: cfo1\n",
            "Basic metrics for cfo1 on 2023-02-13\n",
            "Distribution metrics for cfo1 on 2023-02-13\n",
            "Quantile metrics for cfo1 on 2023-02-13\n",
            "Entropy calculation for cfo1 on 2023-02-13\n",
            "Entropy calculated: 5.216\n",
            "Mutual information: cfo1 vs aimp on 2023-02-13\n",
            "MI calculated: 0.000\n",
            "Processing column: cso1\n",
            "Basic metrics for cso1 on 2023-02-13\n",
            "Distribution metrics for cso1 on 2023-02-13\n",
            "Quantile metrics for cso1 on 2023-02-13\n",
            "Entropy calculation for cso1 on 2023-02-13\n",
            "Entropy calculated: 5.194\n",
            "Mutual information: cso1 vs aimp on 2023-02-13\n",
            "MI calculated: 0.000\n",
            "Processing column: y\n",
            "Basic metrics for y on 2023-02-13\n",
            "Distribution metrics for y on 2023-02-13\n",
            "Quantile metrics for y on 2023-02-13\n",
            "Entropy calculation for y on 2023-02-13\n",
            "Entropy calculated: 0.212\n",
            "Mutual information: y vs aimp on 2023-02-13\n",
            "MI calculated: 0.000\n",
            "Processing column: category\n",
            "Basic metrics for category on 2023-02-13\n",
            "Distribution metrics for category on 2023-02-13\n",
            "Quantile metrics for category on 2023-02-13\n",
            "Entropy calculation for category on 2023-02-13\n",
            "Entropy calculated: 0.245\n",
            "Mutual information: category vs aimp on 2023-02-13\n",
            "MI calculated: 0.000\n",
            "Completed 2023-02-13 - Generated 662 features\n",
            "Processing date 45/58: 2023-02-14\n",
            "Processing 86400 records\n",
            "Correlation matrix for 2023-02-14\n",
            "Correlation matrix calculated for 19 columns\n",
            "Processing column: aimp\n",
            "Basic metrics for aimp on 2023-02-14\n",
            "Distribution metrics for aimp on 2023-02-14\n",
            "Quantile metrics for aimp on 2023-02-14\n",
            "Entropy calculation for aimp on 2023-02-14\n",
            "Entropy calculated: 0.082\n",
            "Processing column: amud\n",
            "Basic metrics for amud on 2023-02-14\n",
            "Distribution metrics for amud on 2023-02-14\n",
            "Quantile metrics for amud on 2023-02-14\n",
            "Entropy calculation for amud on 2023-02-14\n",
            "Entropy calculated: 4.378\n",
            "Mutual information: amud vs aimp on 2023-02-14\n",
            "MI calculated: 0.000\n",
            "Processing column: arnd\n",
            "Basic metrics for arnd on 2023-02-14\n",
            "Distribution metrics for arnd on 2023-02-14\n",
            "Quantile metrics for arnd on 2023-02-14\n",
            "Entropy calculation for arnd on 2023-02-14\n",
            "Entropy calculated: 5.370\n",
            "Mutual information: arnd vs aimp on 2023-02-14\n",
            "MI calculated: 0.000\n",
            "Processing column: asin1\n",
            "Basic metrics for asin1 on 2023-02-14\n",
            "Distribution metrics for asin1 on 2023-02-14\n",
            "Quantile metrics for asin1 on 2023-02-14\n",
            "Entropy calculation for asin1 on 2023-02-14\n",
            "Entropy calculated: 5.168\n",
            "Mutual information: asin1 vs aimp on 2023-02-14\n",
            "MI calculated: 0.000\n",
            "Processing column: asin2\n",
            "Basic metrics for asin2 on 2023-02-14\n",
            "Distribution metrics for asin2 on 2023-02-14\n",
            "Quantile metrics for asin2 on 2023-02-14\n",
            "Entropy calculation for asin2 on 2023-02-14\n",
            "Entropy calculated: 5.361\n",
            "Mutual information: asin2 vs aimp on 2023-02-14\n",
            "MI calculated: 0.000\n",
            "Processing column: adbr\n",
            "Basic metrics for adbr on 2023-02-14\n",
            "Distribution metrics for adbr on 2023-02-14\n",
            "Quantile metrics for adbr on 2023-02-14\n",
            "Entropy calculation for adbr on 2023-02-14\n",
            "Entropy calculated: 1.000\n",
            "Mutual information: adbr vs aimp on 2023-02-14\n",
            "MI calculated: 0.000\n",
            "Processing column: adfl\n",
            "Basic metrics for adfl on 2023-02-14\n",
            "Distribution metrics for adfl on 2023-02-14\n",
            "Quantile metrics for adfl on 2023-02-14\n",
            "Entropy calculation for adfl on 2023-02-14\n",
            "Entropy calculated: 0.973\n",
            "Mutual information: adfl vs aimp on 2023-02-14\n",
            "MI calculated: 0.000\n",
            "Processing column: bed1\n",
            "Basic metrics for bed1 on 2023-02-14\n",
            "Distribution metrics for bed1 on 2023-02-14\n",
            "Quantile metrics for bed1 on 2023-02-14\n",
            "Entropy calculation for bed1 on 2023-02-14\n",
            "Entropy calculated: 4.603\n",
            "Mutual information: bed1 vs aimp on 2023-02-14\n",
            "MI calculated: 0.014\n",
            "Processing column: bed2\n",
            "Basic metrics for bed2 on 2023-02-14\n",
            "Distribution metrics for bed2 on 2023-02-14\n",
            "Quantile metrics for bed2 on 2023-02-14\n",
            "Entropy calculation for bed2 on 2023-02-14\n",
            "Entropy calculated: 2.495\n",
            "Mutual information: bed2 vs aimp on 2023-02-14\n",
            "MI calculated: 0.041\n",
            "Processing column: bfo1\n",
            "Basic metrics for bfo1 on 2023-02-14\n",
            "Distribution metrics for bfo1 on 2023-02-14\n",
            "Quantile metrics for bfo1 on 2023-02-14\n",
            "Entropy calculation for bfo1 on 2023-02-14\n",
            "Entropy calculated: 4.656\n",
            "Mutual information: bfo1 vs aimp on 2023-02-14\n",
            "MI calculated: 0.000\n",
            "Processing column: bfo2\n",
            "Basic metrics for bfo2 on 2023-02-14\n",
            "Distribution metrics for bfo2 on 2023-02-14\n",
            "Quantile metrics for bfo2 on 2023-02-14\n",
            "Entropy calculation for bfo2 on 2023-02-14\n",
            "Entropy calculated: 3.342\n",
            "Mutual information: bfo2 vs aimp on 2023-02-14\n",
            "MI calculated: 0.000\n",
            "Processing column: bso1\n",
            "Basic metrics for bso1 on 2023-02-14\n",
            "Distribution metrics for bso1 on 2023-02-14\n",
            "Quantile metrics for bso1 on 2023-02-14\n",
            "Entropy calculation for bso1 on 2023-02-14\n",
            "Entropy calculated: 5.056\n",
            "Mutual information: bso1 vs aimp on 2023-02-14\n",
            "MI calculated: 0.000\n",
            "Processing column: bso2\n",
            "Basic metrics for bso2 on 2023-02-14\n",
            "Distribution metrics for bso2 on 2023-02-14\n",
            "Quantile metrics for bso2 on 2023-02-14\n",
            "Entropy calculation for bso2 on 2023-02-14\n",
            "Entropy calculated: 3.618\n",
            "Mutual information: bso2 vs aimp on 2023-02-14\n",
            "MI calculated: 0.000\n",
            "Processing column: bso3\n",
            "Basic metrics for bso3 on 2023-02-14\n",
            "Distribution metrics for bso3 on 2023-02-14\n",
            "Quantile metrics for bso3 on 2023-02-14\n",
            "Entropy calculation for bso3 on 2023-02-14\n",
            "Entropy calculated: 5.216\n",
            "Mutual information: bso3 vs aimp on 2023-02-14\n",
            "MI calculated: 0.000\n",
            "Processing column: ced1\n",
            "Basic metrics for ced1 on 2023-02-14\n",
            "Distribution metrics for ced1 on 2023-02-14\n",
            "Quantile metrics for ced1 on 2023-02-14\n",
            "Entropy calculation for ced1 on 2023-02-14\n",
            "Entropy calculated: 4.817\n",
            "Mutual information: ced1 vs aimp on 2023-02-14\n",
            "MI calculated: 0.000\n",
            "Processing column: cfo1\n",
            "Basic metrics for cfo1 on 2023-02-14\n",
            "Distribution metrics for cfo1 on 2023-02-14\n",
            "Quantile metrics for cfo1 on 2023-02-14\n",
            "Entropy calculation for cfo1 on 2023-02-14\n",
            "Entropy calculated: 5.082\n",
            "Mutual information: cfo1 vs aimp on 2023-02-14\n",
            "MI calculated: 0.000\n",
            "Processing column: cso1\n",
            "Basic metrics for cso1 on 2023-02-14\n",
            "Distribution metrics for cso1 on 2023-02-14\n",
            "Quantile metrics for cso1 on 2023-02-14\n",
            "Entropy calculation for cso1 on 2023-02-14\n",
            "Entropy calculated: 3.670\n",
            "Mutual information: cso1 vs aimp on 2023-02-14\n",
            "MI calculated: 0.000\n",
            "Processing column: y\n",
            "Basic metrics for y on 2023-02-14\n",
            "Distribution metrics for y on 2023-02-14\n",
            "Quantile metrics for y on 2023-02-14\n",
            "Entropy calculation for y on 2023-02-14\n",
            "Entropy calculated: 0.560\n",
            "Mutual information: y vs aimp on 2023-02-14\n",
            "MI calculated: 0.000\n",
            "Processing column: category\n",
            "Basic metrics for category on 2023-02-14\n",
            "Distribution metrics for category on 2023-02-14\n",
            "Quantile metrics for category on 2023-02-14\n",
            "Entropy calculation for category on 2023-02-14\n",
            "Entropy calculated: 0.735\n",
            "Mutual information: category vs aimp on 2023-02-14\n",
            "MI calculated: 0.000\n",
            "Completed 2023-02-14 - Generated 662 features\n",
            "Processing date 46/58: 2023-02-15\n",
            "Processing 86400 records\n",
            "Correlation matrix for 2023-02-15\n",
            "Correlation matrix calculated for 19 columns\n",
            "Processing column: aimp\n",
            "Basic metrics for aimp on 2023-02-15\n",
            "Distribution metrics for aimp on 2023-02-15\n",
            "Quantile metrics for aimp on 2023-02-15\n",
            "Entropy calculation for aimp on 2023-02-15\n",
            "Entropy calculated: 0.081\n",
            "Processing column: amud\n",
            "Basic metrics for amud on 2023-02-15\n",
            "Distribution metrics for amud on 2023-02-15\n",
            "Quantile metrics for amud on 2023-02-15\n",
            "Entropy calculation for amud on 2023-02-15\n",
            "Entropy calculated: 4.300\n",
            "Mutual information: amud vs aimp on 2023-02-15\n",
            "MI calculated: 0.000\n",
            "Processing column: arnd\n",
            "Basic metrics for arnd on 2023-02-15\n",
            "Distribution metrics for arnd on 2023-02-15\n",
            "Quantile metrics for arnd on 2023-02-15\n",
            "Entropy calculation for arnd on 2023-02-15\n",
            "Entropy calculated: 5.350\n",
            "Mutual information: arnd vs aimp on 2023-02-15\n",
            "MI calculated: 0.000\n",
            "Processing column: asin1\n",
            "Basic metrics for asin1 on 2023-02-15\n",
            "Distribution metrics for asin1 on 2023-02-15\n",
            "Quantile metrics for asin1 on 2023-02-15\n",
            "Entropy calculation for asin1 on 2023-02-15\n",
            "Entropy calculated: 5.631\n",
            "Mutual information: asin1 vs aimp on 2023-02-15\n",
            "MI calculated: 0.000\n",
            "Processing column: asin2\n",
            "Basic metrics for asin2 on 2023-02-15\n",
            "Distribution metrics for asin2 on 2023-02-15\n",
            "Quantile metrics for asin2 on 2023-02-15\n",
            "Entropy calculation for asin2 on 2023-02-15\n",
            "Entropy calculated: 5.378\n",
            "Mutual information: asin2 vs aimp on 2023-02-15\n",
            "MI calculated: 0.000\n",
            "Processing column: adbr\n",
            "Basic metrics for adbr on 2023-02-15\n",
            "Distribution metrics for adbr on 2023-02-15\n",
            "Quantile metrics for adbr on 2023-02-15\n",
            "Entropy calculation for adbr on 2023-02-15\n",
            "Entropy calculated: 0.995\n",
            "Mutual information: adbr vs aimp on 2023-02-15\n",
            "MI calculated: 0.000\n",
            "Processing column: adfl\n",
            "Basic metrics for adfl on 2023-02-15\n",
            "Distribution metrics for adfl on 2023-02-15\n",
            "Quantile metrics for adfl on 2023-02-15\n",
            "Entropy calculation for adfl on 2023-02-15\n",
            "Entropy calculated: 0.972\n",
            "Mutual information: adfl vs aimp on 2023-02-15\n",
            "MI calculated: 0.000\n",
            "Processing column: bed1\n",
            "Basic metrics for bed1 on 2023-02-15\n",
            "Distribution metrics for bed1 on 2023-02-15\n",
            "Quantile metrics for bed1 on 2023-02-15\n",
            "Entropy calculation for bed1 on 2023-02-15\n",
            "Entropy calculated: 4.549\n",
            "Mutual information: bed1 vs aimp on 2023-02-15\n",
            "MI calculated: 0.014\n",
            "Processing column: bed2\n",
            "Basic metrics for bed2 on 2023-02-15\n",
            "Distribution metrics for bed2 on 2023-02-15\n",
            "Quantile metrics for bed2 on 2023-02-15\n",
            "Entropy calculation for bed2 on 2023-02-15\n",
            "Entropy calculated: 2.822\n",
            "Mutual information: bed2 vs aimp on 2023-02-15\n",
            "MI calculated: 0.043\n",
            "Processing column: bfo1\n",
            "Basic metrics for bfo1 on 2023-02-15\n",
            "Distribution metrics for bfo1 on 2023-02-15\n",
            "Quantile metrics for bfo1 on 2023-02-15\n",
            "Entropy calculation for bfo1 on 2023-02-15\n",
            "Entropy calculated: 2.973\n",
            "Mutual information: bfo1 vs aimp on 2023-02-15\n",
            "MI calculated: 0.000\n",
            "Processing column: bfo2\n",
            "Basic metrics for bfo2 on 2023-02-15\n",
            "Distribution metrics for bfo2 on 2023-02-15\n",
            "Quantile metrics for bfo2 on 2023-02-15\n",
            "Entropy calculation for bfo2 on 2023-02-15\n",
            "Entropy calculated: 3.948\n",
            "Mutual information: bfo2 vs aimp on 2023-02-15\n",
            "MI calculated: 0.000\n",
            "Processing column: bso1\n",
            "Basic metrics for bso1 on 2023-02-15\n",
            "Distribution metrics for bso1 on 2023-02-15\n",
            "Quantile metrics for bso1 on 2023-02-15\n",
            "Entropy calculation for bso1 on 2023-02-15\n",
            "Entropy calculated: 4.742\n",
            "Mutual information: bso1 vs aimp on 2023-02-15\n",
            "MI calculated: 0.000\n",
            "Processing column: bso2\n",
            "Basic metrics for bso2 on 2023-02-15\n",
            "Distribution metrics for bso2 on 2023-02-15\n",
            "Quantile metrics for bso2 on 2023-02-15\n",
            "Entropy calculation for bso2 on 2023-02-15\n",
            "Entropy calculated: 5.516\n",
            "Mutual information: bso2 vs aimp on 2023-02-15\n",
            "MI calculated: 0.000\n",
            "Processing column: bso3\n",
            "Basic metrics for bso3 on 2023-02-15\n",
            "Distribution metrics for bso3 on 2023-02-15\n",
            "Quantile metrics for bso3 on 2023-02-15\n",
            "Entropy calculation for bso3 on 2023-02-15\n",
            "Entropy calculated: 5.282\n",
            "Mutual information: bso3 vs aimp on 2023-02-15\n",
            "MI calculated: 0.000\n",
            "Processing column: ced1\n",
            "Basic metrics for ced1 on 2023-02-15\n",
            "Distribution metrics for ced1 on 2023-02-15\n",
            "Quantile metrics for ced1 on 2023-02-15\n",
            "Entropy calculation for ced1 on 2023-02-15\n",
            "Entropy calculated: 4.783\n",
            "Mutual information: ced1 vs aimp on 2023-02-15\n",
            "MI calculated: 0.000\n",
            "Processing column: cfo1\n",
            "Basic metrics for cfo1 on 2023-02-15\n",
            "Distribution metrics for cfo1 on 2023-02-15\n",
            "Quantile metrics for cfo1 on 2023-02-15\n",
            "Entropy calculation for cfo1 on 2023-02-15\n",
            "Entropy calculated: 3.942\n",
            "Mutual information: cfo1 vs aimp on 2023-02-15\n",
            "MI calculated: 0.000\n",
            "Processing column: cso1\n",
            "Basic metrics for cso1 on 2023-02-15\n",
            "Distribution metrics for cso1 on 2023-02-15\n",
            "Quantile metrics for cso1 on 2023-02-15\n",
            "Entropy calculation for cso1 on 2023-02-15\n",
            "Entropy calculated: 3.814\n",
            "Mutual information: cso1 vs aimp on 2023-02-15\n",
            "MI calculated: 0.000\n",
            "Processing column: y\n",
            "Basic metrics for y on 2023-02-15\n",
            "Distribution metrics for y on 2023-02-15\n",
            "Quantile metrics for y on 2023-02-15\n",
            "Entropy calculation for y on 2023-02-15\n",
            "Entropy calculated: 0.275\n",
            "Mutual information: y vs aimp on 2023-02-15\n",
            "MI calculated: 0.000\n",
            "Processing column: category\n",
            "Basic metrics for category on 2023-02-15\n",
            "Distribution metrics for category on 2023-02-15\n",
            "Quantile metrics for category on 2023-02-15\n",
            "Entropy calculation for category on 2023-02-15\n",
            "Entropy calculated: 0.294\n",
            "Mutual information: category vs aimp on 2023-02-15\n",
            "MI calculated: 0.000\n",
            "Completed 2023-02-15 - Generated 662 features\n",
            "Processing date 47/58: 2023-02-16\n",
            "Processing 86400 records\n",
            "Correlation matrix for 2023-02-16\n",
            "Correlation matrix calculated for 19 columns\n",
            "Processing column: aimp\n",
            "Basic metrics for aimp on 2023-02-16\n",
            "Distribution metrics for aimp on 2023-02-16\n",
            "Quantile metrics for aimp on 2023-02-16\n",
            "Entropy calculation for aimp on 2023-02-16\n",
            "Entropy calculated: 0.081\n",
            "Processing column: amud\n",
            "Basic metrics for amud on 2023-02-16\n",
            "Distribution metrics for amud on 2023-02-16\n",
            "Quantile metrics for amud on 2023-02-16\n",
            "Entropy calculation for amud on 2023-02-16\n",
            "Entropy calculated: 4.101\n",
            "Mutual information: amud vs aimp on 2023-02-16\n",
            "MI calculated: 0.000\n",
            "Processing column: arnd\n",
            "Basic metrics for arnd on 2023-02-16\n",
            "Distribution metrics for arnd on 2023-02-16\n",
            "Quantile metrics for arnd on 2023-02-16\n",
            "Entropy calculation for arnd on 2023-02-16\n",
            "Entropy calculated: 4.768\n",
            "Mutual information: arnd vs aimp on 2023-02-16\n",
            "MI calculated: 0.000\n",
            "Processing column: asin1\n",
            "Basic metrics for asin1 on 2023-02-16\n",
            "Distribution metrics for asin1 on 2023-02-16\n",
            "Quantile metrics for asin1 on 2023-02-16\n",
            "Entropy calculation for asin1 on 2023-02-16\n",
            "Entropy calculated: 4.977\n",
            "Mutual information: asin1 vs aimp on 2023-02-16\n",
            "MI calculated: 0.000\n",
            "Processing column: asin2\n",
            "Basic metrics for asin2 on 2023-02-16\n",
            "Distribution metrics for asin2 on 2023-02-16\n",
            "Quantile metrics for asin2 on 2023-02-16\n",
            "Entropy calculation for asin2 on 2023-02-16\n",
            "Entropy calculated: 5.361\n",
            "Mutual information: asin2 vs aimp on 2023-02-16\n",
            "MI calculated: 0.000\n",
            "Processing column: adbr\n",
            "Basic metrics for adbr on 2023-02-16\n",
            "Distribution metrics for adbr on 2023-02-16\n",
            "Quantile metrics for adbr on 2023-02-16\n",
            "Entropy calculation for adbr on 2023-02-16\n",
            "Entropy calculated: 0.998\n",
            "Mutual information: adbr vs aimp on 2023-02-16\n",
            "MI calculated: 0.000\n",
            "Processing column: adfl\n",
            "Basic metrics for adfl on 2023-02-16\n",
            "Distribution metrics for adfl on 2023-02-16\n",
            "Quantile metrics for adfl on 2023-02-16\n",
            "Entropy calculation for adfl on 2023-02-16\n",
            "Entropy calculated: 0.965\n",
            "Mutual information: adfl vs aimp on 2023-02-16\n",
            "MI calculated: 0.000\n",
            "Processing column: bed1\n",
            "Basic metrics for bed1 on 2023-02-16\n",
            "Distribution metrics for bed1 on 2023-02-16\n",
            "Quantile metrics for bed1 on 2023-02-16\n",
            "Entropy calculation for bed1 on 2023-02-16\n",
            "Entropy calculated: 3.940\n",
            "Mutual information: bed1 vs aimp on 2023-02-16\n",
            "MI calculated: 0.012\n",
            "Processing column: bed2\n",
            "Basic metrics for bed2 on 2023-02-16\n",
            "Distribution metrics for bed2 on 2023-02-16\n",
            "Quantile metrics for bed2 on 2023-02-16\n",
            "Entropy calculation for bed2 on 2023-02-16\n",
            "Entropy calculated: 2.523\n",
            "Mutual information: bed2 vs aimp on 2023-02-16\n",
            "MI calculated: 0.031\n",
            "Processing column: bfo1\n",
            "Basic metrics for bfo1 on 2023-02-16\n",
            "Distribution metrics for bfo1 on 2023-02-16\n",
            "Quantile metrics for bfo1 on 2023-02-16\n",
            "Entropy calculation for bfo1 on 2023-02-16\n",
            "Entropy calculated: 4.310\n",
            "Mutual information: bfo1 vs aimp on 2023-02-16\n",
            "MI calculated: 0.000\n",
            "Processing column: bfo2\n",
            "Basic metrics for bfo2 on 2023-02-16\n",
            "Distribution metrics for bfo2 on 2023-02-16\n",
            "Quantile metrics for bfo2 on 2023-02-16\n",
            "Entropy calculation for bfo2 on 2023-02-16\n",
            "Entropy calculated: 3.766\n",
            "Mutual information: bfo2 vs aimp on 2023-02-16\n",
            "MI calculated: 0.000\n",
            "Processing column: bso1\n",
            "Basic metrics for bso1 on 2023-02-16\n",
            "Distribution metrics for bso1 on 2023-02-16\n",
            "Quantile metrics for bso1 on 2023-02-16\n",
            "Entropy calculation for bso1 on 2023-02-16\n",
            "Entropy calculated: 4.220\n",
            "Mutual information: bso1 vs aimp on 2023-02-16\n",
            "MI calculated: 0.000\n",
            "Processing column: bso2\n",
            "Basic metrics for bso2 on 2023-02-16\n",
            "Distribution metrics for bso2 on 2023-02-16\n",
            "Quantile metrics for bso2 on 2023-02-16\n",
            "Entropy calculation for bso2 on 2023-02-16\n",
            "Entropy calculated: 4.892\n",
            "Mutual information: bso2 vs aimp on 2023-02-16\n",
            "MI calculated: 0.000\n",
            "Processing column: bso3\n",
            "Basic metrics for bso3 on 2023-02-16\n",
            "Distribution metrics for bso3 on 2023-02-16\n",
            "Quantile metrics for bso3 on 2023-02-16\n",
            "Entropy calculation for bso3 on 2023-02-16\n",
            "Entropy calculated: 5.261\n",
            "Mutual information: bso3 vs aimp on 2023-02-16\n",
            "MI calculated: 0.000\n",
            "Processing column: ced1\n",
            "Basic metrics for ced1 on 2023-02-16\n",
            "Distribution metrics for ced1 on 2023-02-16\n",
            "Quantile metrics for ced1 on 2023-02-16\n",
            "Entropy calculation for ced1 on 2023-02-16\n",
            "Entropy calculated: 4.221\n",
            "Mutual information: ced1 vs aimp on 2023-02-16\n",
            "MI calculated: 0.000\n",
            "Processing column: cfo1\n",
            "Basic metrics for cfo1 on 2023-02-16\n",
            "Distribution metrics for cfo1 on 2023-02-16\n",
            "Quantile metrics for cfo1 on 2023-02-16\n",
            "Entropy calculation for cfo1 on 2023-02-16\n",
            "Entropy calculated: 4.707\n",
            "Mutual information: cfo1 vs aimp on 2023-02-16\n",
            "MI calculated: 0.000\n",
            "Processing column: cso1\n",
            "Basic metrics for cso1 on 2023-02-16\n",
            "Distribution metrics for cso1 on 2023-02-16\n",
            "Quantile metrics for cso1 on 2023-02-16\n",
            "Entropy calculation for cso1 on 2023-02-16\n",
            "Entropy calculated: 3.849\n",
            "Mutual information: cso1 vs aimp on 2023-02-16\n",
            "MI calculated: 0.000\n",
            "Processing column: y\n",
            "Basic metrics for y on 2023-02-16\n",
            "Distribution metrics for y on 2023-02-16\n",
            "Quantile metrics for y on 2023-02-16\n",
            "Entropy calculation for y on 2023-02-16\n",
            "Entropy calculated: 0.402\n",
            "Mutual information: y vs aimp on 2023-02-16\n",
            "MI calculated: 0.000\n",
            "Processing column: category\n",
            "Basic metrics for category on 2023-02-16\n",
            "Distribution metrics for category on 2023-02-16\n",
            "Quantile metrics for category on 2023-02-16\n",
            "Entropy calculation for category on 2023-02-16\n",
            "Entropy calculated: 0.551\n",
            "Mutual information: category vs aimp on 2023-02-16\n",
            "MI calculated: 0.000\n",
            "Completed 2023-02-16 - Generated 662 features\n",
            "Processing date 48/58: 2023-02-17\n",
            "Processing 86400 records\n",
            "Correlation matrix for 2023-02-17\n",
            "Correlation matrix calculated for 19 columns\n",
            "Processing column: aimp\n",
            "Basic metrics for aimp on 2023-02-17\n",
            "Distribution metrics for aimp on 2023-02-17\n",
            "Quantile metrics for aimp on 2023-02-17\n",
            "Entropy calculation for aimp on 2023-02-17\n",
            "Entropy calculated: 0.079\n",
            "Processing column: amud\n",
            "Basic metrics for amud on 2023-02-17\n",
            "Distribution metrics for amud on 2023-02-17\n",
            "Quantile metrics for amud on 2023-02-17\n",
            "Entropy calculation for amud on 2023-02-17\n",
            "Entropy calculated: 4.511\n",
            "Mutual information: amud vs aimp on 2023-02-17\n",
            "MI calculated: 0.000\n",
            "Processing column: arnd\n",
            "Basic metrics for arnd on 2023-02-17\n",
            "Distribution metrics for arnd on 2023-02-17\n",
            "Quantile metrics for arnd on 2023-02-17\n",
            "Entropy calculation for arnd on 2023-02-17\n",
            "Entropy calculated: 4.963\n",
            "Mutual information: arnd vs aimp on 2023-02-17\n",
            "MI calculated: 0.000\n",
            "Processing column: asin1\n",
            "Basic metrics for asin1 on 2023-02-17\n",
            "Distribution metrics for asin1 on 2023-02-17\n",
            "Quantile metrics for asin1 on 2023-02-17\n",
            "Entropy calculation for asin1 on 2023-02-17\n",
            "Entropy calculated: 5.584\n",
            "Mutual information: asin1 vs aimp on 2023-02-17\n",
            "MI calculated: 0.000\n",
            "Processing column: asin2\n",
            "Basic metrics for asin2 on 2023-02-17\n",
            "Distribution metrics for asin2 on 2023-02-17\n",
            "Quantile metrics for asin2 on 2023-02-17\n",
            "Entropy calculation for asin2 on 2023-02-17\n",
            "Entropy calculated: 5.379\n",
            "Mutual information: asin2 vs aimp on 2023-02-17\n",
            "MI calculated: 0.000\n",
            "Processing column: adbr\n",
            "Basic metrics for adbr on 2023-02-17\n",
            "Distribution metrics for adbr on 2023-02-17\n",
            "Quantile metrics for adbr on 2023-02-17\n",
            "Entropy calculation for adbr on 2023-02-17\n",
            "Entropy calculated: 0.998\n",
            "Mutual information: adbr vs aimp on 2023-02-17\n",
            "MI calculated: 0.000\n",
            "Processing column: adfl\n",
            "Basic metrics for adfl on 2023-02-17\n",
            "Distribution metrics for adfl on 2023-02-17\n",
            "Quantile metrics for adfl on 2023-02-17\n",
            "Entropy calculation for adfl on 2023-02-17\n",
            "Entropy calculated: 0.967\n",
            "Mutual information: adfl vs aimp on 2023-02-17\n",
            "MI calculated: 0.000\n",
            "Processing column: bed1\n",
            "Basic metrics for bed1 on 2023-02-17\n",
            "Distribution metrics for bed1 on 2023-02-17\n",
            "Quantile metrics for bed1 on 2023-02-17\n",
            "Entropy calculation for bed1 on 2023-02-17\n",
            "Entropy calculated: 4.611\n",
            "Mutual information: bed1 vs aimp on 2023-02-17\n",
            "MI calculated: 0.014\n",
            "Processing column: bed2\n",
            "Basic metrics for bed2 on 2023-02-17\n",
            "Distribution metrics for bed2 on 2023-02-17\n",
            "Quantile metrics for bed2 on 2023-02-17\n",
            "Entropy calculation for bed2 on 2023-02-17\n",
            "Entropy calculated: 2.839\n",
            "Mutual information: bed2 vs aimp on 2023-02-17\n",
            "MI calculated: 0.039\n",
            "Processing column: bfo1\n",
            "Basic metrics for bfo1 on 2023-02-17\n",
            "Distribution metrics for bfo1 on 2023-02-17\n",
            "Quantile metrics for bfo1 on 2023-02-17\n",
            "Entropy calculation for bfo1 on 2023-02-17\n",
            "Entropy calculated: 4.736\n",
            "Mutual information: bfo1 vs aimp on 2023-02-17\n",
            "MI calculated: 0.000\n",
            "Processing column: bfo2\n",
            "Basic metrics for bfo2 on 2023-02-17\n",
            "Distribution metrics for bfo2 on 2023-02-17\n",
            "Quantile metrics for bfo2 on 2023-02-17\n",
            "Entropy calculation for bfo2 on 2023-02-17\n",
            "Entropy calculated: 2.472\n",
            "Mutual information: bfo2 vs aimp on 2023-02-17\n",
            "MI calculated: 0.000\n",
            "Processing column: bso1\n",
            "Basic metrics for bso1 on 2023-02-17\n",
            "Distribution metrics for bso1 on 2023-02-17\n",
            "Quantile metrics for bso1 on 2023-02-17\n",
            "Entropy calculation for bso1 on 2023-02-17\n",
            "Entropy calculated: 4.060\n",
            "Mutual information: bso1 vs aimp on 2023-02-17\n",
            "MI calculated: 0.000\n",
            "Processing column: bso2\n",
            "Basic metrics for bso2 on 2023-02-17\n",
            "Distribution metrics for bso2 on 2023-02-17\n",
            "Quantile metrics for bso2 on 2023-02-17\n",
            "Entropy calculation for bso2 on 2023-02-17\n",
            "Entropy calculated: 3.884\n",
            "Mutual information: bso2 vs aimp on 2023-02-17\n",
            "MI calculated: 0.000\n",
            "Processing column: bso3\n",
            "Basic metrics for bso3 on 2023-02-17\n",
            "Distribution metrics for bso3 on 2023-02-17\n",
            "Quantile metrics for bso3 on 2023-02-17\n",
            "Entropy calculation for bso3 on 2023-02-17\n",
            "Entropy calculated: 3.240\n",
            "Mutual information: bso3 vs aimp on 2023-02-17\n",
            "MI calculated: 0.000\n",
            "Processing column: ced1\n",
            "Basic metrics for ced1 on 2023-02-17\n",
            "Distribution metrics for ced1 on 2023-02-17\n",
            "Quantile metrics for ced1 on 2023-02-17\n",
            "Entropy calculation for ced1 on 2023-02-17\n",
            "Entropy calculated: 5.099\n",
            "Mutual information: ced1 vs aimp on 2023-02-17\n",
            "MI calculated: 0.000\n",
            "Processing column: cfo1\n",
            "Basic metrics for cfo1 on 2023-02-17\n",
            "Distribution metrics for cfo1 on 2023-02-17\n",
            "Quantile metrics for cfo1 on 2023-02-17\n",
            "Entropy calculation for cfo1 on 2023-02-17\n",
            "Entropy calculated: 4.376\n",
            "Mutual information: cfo1 vs aimp on 2023-02-17\n",
            "MI calculated: 0.000\n",
            "Processing column: cso1\n",
            "Basic metrics for cso1 on 2023-02-17\n",
            "Distribution metrics for cso1 on 2023-02-17\n",
            "Quantile metrics for cso1 on 2023-02-17\n",
            "Entropy calculation for cso1 on 2023-02-17\n",
            "Entropy calculated: 4.299\n",
            "Mutual information: cso1 vs aimp on 2023-02-17\n",
            "MI calculated: 0.000\n",
            "Processing column: y\n",
            "Basic metrics for y on 2023-02-17\n",
            "Distribution metrics for y on 2023-02-17\n",
            "Quantile metrics for y on 2023-02-17\n",
            "Entropy calculation for y on 2023-02-17\n",
            "Entropy calculated: 0.300\n",
            "Mutual information: y vs aimp on 2023-02-17\n",
            "MI calculated: 0.000\n",
            "Processing column: category\n",
            "Basic metrics for category on 2023-02-17\n",
            "Distribution metrics for category on 2023-02-17\n",
            "Quantile metrics for category on 2023-02-17\n",
            "Entropy calculation for category on 2023-02-17\n",
            "Entropy calculated: 0.411\n",
            "Mutual information: category vs aimp on 2023-02-17\n",
            "MI calculated: 0.000\n",
            "Completed 2023-02-17 - Generated 662 features\n",
            "Processing date 49/58: 2023-02-18\n",
            "Processing 86400 records\n",
            "Correlation matrix for 2023-02-18\n",
            "Correlation matrix calculated for 19 columns\n",
            "Processing column: aimp\n",
            "Basic metrics for aimp on 2023-02-18\n",
            "Distribution metrics for aimp on 2023-02-18\n",
            "Quantile metrics for aimp on 2023-02-18\n",
            "Entropy calculation for aimp on 2023-02-18\n",
            "Entropy calculated: 0.082\n",
            "Processing column: amud\n",
            "Basic metrics for amud on 2023-02-18\n",
            "Distribution metrics for amud on 2023-02-18\n",
            "Quantile metrics for amud on 2023-02-18\n",
            "Entropy calculation for amud on 2023-02-18\n",
            "Entropy calculated: 4.434\n",
            "Mutual information: amud vs aimp on 2023-02-18\n",
            "MI calculated: 0.000\n",
            "Processing column: arnd\n",
            "Basic metrics for arnd on 2023-02-18\n",
            "Distribution metrics for arnd on 2023-02-18\n",
            "Quantile metrics for arnd on 2023-02-18\n",
            "Entropy calculation for arnd on 2023-02-18\n",
            "Entropy calculated: 4.761\n",
            "Mutual information: arnd vs aimp on 2023-02-18\n",
            "MI calculated: 0.000\n",
            "Processing column: asin1\n",
            "Basic metrics for asin1 on 2023-02-18\n",
            "Distribution metrics for asin1 on 2023-02-18\n",
            "Quantile metrics for asin1 on 2023-02-18\n",
            "Entropy calculation for asin1 on 2023-02-18\n",
            "Entropy calculated: 4.940\n",
            "Mutual information: asin1 vs aimp on 2023-02-18\n",
            "MI calculated: 0.000\n",
            "Processing column: asin2\n",
            "Basic metrics for asin2 on 2023-02-18\n",
            "Distribution metrics for asin2 on 2023-02-18\n",
            "Quantile metrics for asin2 on 2023-02-18\n",
            "Entropy calculation for asin2 on 2023-02-18\n",
            "Entropy calculated: 5.360\n",
            "Mutual information: asin2 vs aimp on 2023-02-18\n",
            "MI calculated: 0.000\n",
            "Processing column: adbr\n",
            "Basic metrics for adbr on 2023-02-18\n",
            "Distribution metrics for adbr on 2023-02-18\n",
            "Quantile metrics for adbr on 2023-02-18\n",
            "Entropy calculation for adbr on 2023-02-18\n",
            "Entropy calculated: 0.999\n",
            "Mutual information: adbr vs aimp on 2023-02-18\n",
            "MI calculated: 0.000\n",
            "Processing column: adfl\n",
            "Basic metrics for adfl on 2023-02-18\n",
            "Distribution metrics for adfl on 2023-02-18\n",
            "Quantile metrics for adfl on 2023-02-18\n",
            "Entropy calculation for adfl on 2023-02-18\n",
            "Entropy calculated: 0.969\n",
            "Mutual information: adfl vs aimp on 2023-02-18\n",
            "MI calculated: 0.000\n",
            "Processing column: bed1\n",
            "Basic metrics for bed1 on 2023-02-18\n",
            "Distribution metrics for bed1 on 2023-02-18\n",
            "Quantile metrics for bed1 on 2023-02-18\n",
            "Entropy calculation for bed1 on 2023-02-18\n",
            "Entropy calculated: 4.658\n",
            "Mutual information: bed1 vs aimp on 2023-02-18\n",
            "MI calculated: 0.014\n",
            "Processing column: bed2\n",
            "Basic metrics for bed2 on 2023-02-18\n",
            "Distribution metrics for bed2 on 2023-02-18\n",
            "Quantile metrics for bed2 on 2023-02-18\n",
            "Entropy calculation for bed2 on 2023-02-18\n",
            "Entropy calculated: 2.885\n",
            "Mutual information: bed2 vs aimp on 2023-02-18\n",
            "MI calculated: 0.041\n",
            "Processing column: bfo1\n",
            "Basic metrics for bfo1 on 2023-02-18\n",
            "Distribution metrics for bfo1 on 2023-02-18\n",
            "Quantile metrics for bfo1 on 2023-02-18\n",
            "Entropy calculation for bfo1 on 2023-02-18\n",
            "Entropy calculated: 4.515\n",
            "Mutual information: bfo1 vs aimp on 2023-02-18\n",
            "MI calculated: 0.000\n",
            "Processing column: bfo2\n",
            "Basic metrics for bfo2 on 2023-02-18\n",
            "Distribution metrics for bfo2 on 2023-02-18\n",
            "Quantile metrics for bfo2 on 2023-02-18\n",
            "Entropy calculation for bfo2 on 2023-02-18\n",
            "Entropy calculated: 4.935\n",
            "Mutual information: bfo2 vs aimp on 2023-02-18\n",
            "MI calculated: 0.000\n",
            "Processing column: bso1\n",
            "Basic metrics for bso1 on 2023-02-18\n",
            "Distribution metrics for bso1 on 2023-02-18\n",
            "Quantile metrics for bso1 on 2023-02-18\n",
            "Entropy calculation for bso1 on 2023-02-18\n",
            "Entropy calculated: 4.878\n",
            "Mutual information: bso1 vs aimp on 2023-02-18\n",
            "MI calculated: 0.000\n",
            "Processing column: bso2\n",
            "Basic metrics for bso2 on 2023-02-18\n",
            "Distribution metrics for bso2 on 2023-02-18\n",
            "Quantile metrics for bso2 on 2023-02-18\n",
            "Entropy calculation for bso2 on 2023-02-18\n",
            "Entropy calculated: 4.035\n",
            "Mutual information: bso2 vs aimp on 2023-02-18\n",
            "MI calculated: 0.000\n",
            "Processing column: bso3\n",
            "Basic metrics for bso3 on 2023-02-18\n",
            "Distribution metrics for bso3 on 2023-02-18\n",
            "Quantile metrics for bso3 on 2023-02-18\n",
            "Entropy calculation for bso3 on 2023-02-18\n",
            "Entropy calculated: 4.402\n",
            "Mutual information: bso3 vs aimp on 2023-02-18\n",
            "MI calculated: 0.000\n",
            "Processing column: ced1\n",
            "Basic metrics for ced1 on 2023-02-18\n",
            "Distribution metrics for ced1 on 2023-02-18\n",
            "Quantile metrics for ced1 on 2023-02-18\n",
            "Entropy calculation for ced1 on 2023-02-18\n",
            "Entropy calculated: 4.997\n",
            "Mutual information: ced1 vs aimp on 2023-02-18\n",
            "MI calculated: 0.000\n",
            "Processing column: cfo1\n",
            "Basic metrics for cfo1 on 2023-02-18\n",
            "Distribution metrics for cfo1 on 2023-02-18\n",
            "Quantile metrics for cfo1 on 2023-02-18\n",
            "Entropy calculation for cfo1 on 2023-02-18\n",
            "Entropy calculated: 5.460\n",
            "Mutual information: cfo1 vs aimp on 2023-02-18\n",
            "MI calculated: 0.000\n",
            "Processing column: cso1\n",
            "Basic metrics for cso1 on 2023-02-18\n",
            "Distribution metrics for cso1 on 2023-02-18\n",
            "Quantile metrics for cso1 on 2023-02-18\n",
            "Entropy calculation for cso1 on 2023-02-18\n",
            "Entropy calculated: 5.135\n",
            "Mutual information: cso1 vs aimp on 2023-02-18\n",
            "MI calculated: 0.000\n",
            "Processing column: y\n",
            "Basic metrics for y on 2023-02-18\n",
            "Distribution metrics for y on 2023-02-18\n",
            "Quantile metrics for y on 2023-02-18\n",
            "Entropy calculation for y on 2023-02-18\n",
            "Entropy calculated: 0.146\n",
            "Mutual information: y vs aimp on 2023-02-18\n",
            "MI calculated: 0.000\n",
            "Processing column: category\n",
            "Basic metrics for category on 2023-02-18\n",
            "Distribution metrics for category on 2023-02-18\n",
            "Quantile metrics for category on 2023-02-18\n",
            "Entropy calculation for category on 2023-02-18\n",
            "Entropy calculated: 0.178\n",
            "Mutual information: category vs aimp on 2023-02-18\n",
            "MI calculated: 0.000\n",
            "Completed 2023-02-18 - Generated 662 features\n",
            "Processing date 50/58: 2023-02-19\n",
            "Processing 86400 records\n",
            "Correlation matrix for 2023-02-19\n",
            "Correlation matrix calculated for 19 columns\n",
            "Processing column: aimp\n",
            "Basic metrics for aimp on 2023-02-19\n",
            "Distribution metrics for aimp on 2023-02-19\n",
            "Quantile metrics for aimp on 2023-02-19\n",
            "Entropy calculation for aimp on 2023-02-19\n",
            "Entropy calculated: 0.075\n",
            "Processing column: amud\n",
            "Basic metrics for amud on 2023-02-19\n",
            "Distribution metrics for amud on 2023-02-19\n",
            "Quantile metrics for amud on 2023-02-19\n",
            "Entropy calculation for amud on 2023-02-19\n",
            "Entropy calculated: 3.689\n",
            "Mutual information: amud vs aimp on 2023-02-19\n",
            "MI calculated: 0.000\n",
            "Processing column: arnd\n",
            "Basic metrics for arnd on 2023-02-19\n",
            "Distribution metrics for arnd on 2023-02-19\n",
            "Quantile metrics for arnd on 2023-02-19\n",
            "Entropy calculation for arnd on 2023-02-19\n",
            "Entropy calculated: 4.794\n",
            "Mutual information: arnd vs aimp on 2023-02-19\n",
            "MI calculated: 0.000\n",
            "Processing column: asin1\n",
            "Basic metrics for asin1 on 2023-02-19\n",
            "Distribution metrics for asin1 on 2023-02-19\n",
            "Quantile metrics for asin1 on 2023-02-19\n",
            "Entropy calculation for asin1 on 2023-02-19\n",
            "Entropy calculated: 5.360\n",
            "Mutual information: asin1 vs aimp on 2023-02-19\n",
            "MI calculated: 0.000\n",
            "Processing column: asin2\n",
            "Basic metrics for asin2 on 2023-02-19\n",
            "Distribution metrics for asin2 on 2023-02-19\n",
            "Quantile metrics for asin2 on 2023-02-19\n",
            "Entropy calculation for asin2 on 2023-02-19\n",
            "Entropy calculated: 5.379\n",
            "Mutual information: asin2 vs aimp on 2023-02-19\n",
            "MI calculated: 0.000\n",
            "Processing column: adbr\n",
            "Basic metrics for adbr on 2023-02-19\n",
            "Distribution metrics for adbr on 2023-02-19\n",
            "Quantile metrics for adbr on 2023-02-19\n",
            "Entropy calculation for adbr on 2023-02-19\n",
            "Entropy calculated: 0.998\n",
            "Mutual information: adbr vs aimp on 2023-02-19\n",
            "MI calculated: 0.000\n",
            "Processing column: adfl\n",
            "Basic metrics for adfl on 2023-02-19\n",
            "Distribution metrics for adfl on 2023-02-19\n",
            "Quantile metrics for adfl on 2023-02-19\n",
            "Entropy calculation for adfl on 2023-02-19\n",
            "Entropy calculated: 0.970\n",
            "Mutual information: adfl vs aimp on 2023-02-19\n",
            "MI calculated: 0.000\n",
            "Processing column: bed1\n",
            "Basic metrics for bed1 on 2023-02-19\n",
            "Distribution metrics for bed1 on 2023-02-19\n",
            "Quantile metrics for bed1 on 2023-02-19\n",
            "Entropy calculation for bed1 on 2023-02-19\n",
            "Entropy calculated: 4.311\n",
            "Mutual information: bed1 vs aimp on 2023-02-19\n",
            "MI calculated: 0.013\n",
            "Processing column: bed2\n",
            "Basic metrics for bed2 on 2023-02-19\n",
            "Distribution metrics for bed2 on 2023-02-19\n",
            "Quantile metrics for bed2 on 2023-02-19\n",
            "Entropy calculation for bed2 on 2023-02-19\n",
            "Entropy calculated: 2.360\n",
            "Mutual information: bed2 vs aimp on 2023-02-19\n",
            "MI calculated: 0.048\n",
            "Processing column: bfo1\n",
            "Basic metrics for bfo1 on 2023-02-19\n",
            "Distribution metrics for bfo1 on 2023-02-19\n",
            "Quantile metrics for bfo1 on 2023-02-19\n",
            "Entropy calculation for bfo1 on 2023-02-19\n",
            "Entropy calculated: 3.932\n",
            "Mutual information: bfo1 vs aimp on 2023-02-19\n",
            "MI calculated: 0.000\n",
            "Processing column: bfo2\n",
            "Basic metrics for bfo2 on 2023-02-19\n",
            "Distribution metrics for bfo2 on 2023-02-19\n",
            "Quantile metrics for bfo2 on 2023-02-19\n",
            "Entropy calculation for bfo2 on 2023-02-19\n",
            "Entropy calculated: 5.317\n",
            "Mutual information: bfo2 vs aimp on 2023-02-19\n",
            "MI calculated: 0.000\n",
            "Processing column: bso1\n",
            "Basic metrics for bso1 on 2023-02-19\n",
            "Distribution metrics for bso1 on 2023-02-19\n",
            "Quantile metrics for bso1 on 2023-02-19\n",
            "Entropy calculation for bso1 on 2023-02-19\n",
            "Entropy calculated: 4.725\n",
            "Mutual information: bso1 vs aimp on 2023-02-19\n",
            "MI calculated: 0.000\n",
            "Processing column: bso2\n",
            "Basic metrics for bso2 on 2023-02-19\n",
            "Distribution metrics for bso2 on 2023-02-19\n",
            "Quantile metrics for bso2 on 2023-02-19\n",
            "Entropy calculation for bso2 on 2023-02-19\n",
            "Entropy calculated: 5.520\n",
            "Mutual information: bso2 vs aimp on 2023-02-19\n",
            "MI calculated: 0.000\n",
            "Processing column: bso3\n",
            "Basic metrics for bso3 on 2023-02-19\n",
            "Distribution metrics for bso3 on 2023-02-19\n",
            "Quantile metrics for bso3 on 2023-02-19\n",
            "Entropy calculation for bso3 on 2023-02-19\n",
            "Entropy calculated: 5.233\n",
            "Mutual information: bso3 vs aimp on 2023-02-19\n",
            "MI calculated: 0.000\n",
            "Processing column: ced1\n",
            "Basic metrics for ced1 on 2023-02-19\n",
            "Distribution metrics for ced1 on 2023-02-19\n",
            "Quantile metrics for ced1 on 2023-02-19\n",
            "Entropy calculation for ced1 on 2023-02-19\n",
            "Entropy calculated: 5.033\n",
            "Mutual information: ced1 vs aimp on 2023-02-19\n",
            "MI calculated: 0.000\n",
            "Processing column: cfo1\n",
            "Basic metrics for cfo1 on 2023-02-19\n",
            "Distribution metrics for cfo1 on 2023-02-19\n",
            "Quantile metrics for cfo1 on 2023-02-19\n",
            "Entropy calculation for cfo1 on 2023-02-19\n",
            "Entropy calculated: 4.575\n",
            "Mutual information: cfo1 vs aimp on 2023-02-19\n",
            "MI calculated: 0.000\n",
            "Processing column: cso1\n",
            "Basic metrics for cso1 on 2023-02-19\n",
            "Distribution metrics for cso1 on 2023-02-19\n",
            "Quantile metrics for cso1 on 2023-02-19\n",
            "Entropy calculation for cso1 on 2023-02-19\n",
            "Entropy calculated: 5.152\n",
            "Mutual information: cso1 vs aimp on 2023-02-19\n",
            "MI calculated: 0.000\n",
            "Processing column: y\n",
            "Basic metrics for y on 2023-02-19\n",
            "Distribution metrics for y on 2023-02-19\n",
            "Quantile metrics for y on 2023-02-19\n",
            "Entropy calculation for y on 2023-02-19\n",
            "Entropy calculated: 0.165\n",
            "Mutual information: y vs aimp on 2023-02-19\n",
            "MI calculated: 0.000\n",
            "Processing column: category\n",
            "Basic metrics for category on 2023-02-19\n",
            "Distribution metrics for category on 2023-02-19\n",
            "Quantile metrics for category on 2023-02-19\n",
            "Entropy calculation for category on 2023-02-19\n",
            "Entropy calculated: 0.188\n",
            "Mutual information: category vs aimp on 2023-02-19\n",
            "MI calculated: 0.000\n",
            "Completed 2023-02-19 - Generated 662 features\n",
            "Processing date 51/58: 2023-02-20\n",
            "Processing 86400 records\n",
            "Correlation matrix for 2023-02-20\n",
            "Correlation matrix calculated for 19 columns\n",
            "Processing column: aimp\n",
            "Basic metrics for aimp on 2023-02-20\n",
            "Distribution metrics for aimp on 2023-02-20\n",
            "Quantile metrics for aimp on 2023-02-20\n",
            "Entropy calculation for aimp on 2023-02-20\n",
            "Entropy calculated: 0.081\n",
            "Processing column: amud\n",
            "Basic metrics for amud on 2023-02-20\n",
            "Distribution metrics for amud on 2023-02-20\n",
            "Quantile metrics for amud on 2023-02-20\n",
            "Entropy calculation for amud on 2023-02-20\n",
            "Entropy calculated: 3.639\n",
            "Mutual information: amud vs aimp on 2023-02-20\n",
            "MI calculated: 0.000\n",
            "Processing column: arnd\n",
            "Basic metrics for arnd on 2023-02-20\n",
            "Distribution metrics for arnd on 2023-02-20\n",
            "Quantile metrics for arnd on 2023-02-20\n",
            "Entropy calculation for arnd on 2023-02-20\n",
            "Entropy calculated: 5.177\n",
            "Mutual information: arnd vs aimp on 2023-02-20\n",
            "MI calculated: 0.000\n",
            "Processing column: asin1\n",
            "Basic metrics for asin1 on 2023-02-20\n",
            "Distribution metrics for asin1 on 2023-02-20\n",
            "Quantile metrics for asin1 on 2023-02-20\n",
            "Entropy calculation for asin1 on 2023-02-20\n",
            "Entropy calculated: 5.378\n",
            "Mutual information: asin1 vs aimp on 2023-02-20\n",
            "MI calculated: 0.000\n",
            "Processing column: asin2\n",
            "Basic metrics for asin2 on 2023-02-20\n",
            "Distribution metrics for asin2 on 2023-02-20\n",
            "Quantile metrics for asin2 on 2023-02-20\n",
            "Entropy calculation for asin2 on 2023-02-20\n",
            "Entropy calculated: 5.360\n",
            "Mutual information: asin2 vs aimp on 2023-02-20\n",
            "MI calculated: 0.000\n",
            "Processing column: adbr\n",
            "Basic metrics for adbr on 2023-02-20\n",
            "Distribution metrics for adbr on 2023-02-20\n",
            "Quantile metrics for adbr on 2023-02-20\n",
            "Entropy calculation for adbr on 2023-02-20\n",
            "Entropy calculated: 1.000\n",
            "Mutual information: adbr vs aimp on 2023-02-20\n",
            "MI calculated: 0.000\n",
            "Processing column: adfl\n",
            "Basic metrics for adfl on 2023-02-20\n",
            "Distribution metrics for adfl on 2023-02-20\n",
            "Quantile metrics for adfl on 2023-02-20\n",
            "Entropy calculation for adfl on 2023-02-20\n",
            "Entropy calculated: 0.967\n",
            "Mutual information: adfl vs aimp on 2023-02-20\n",
            "MI calculated: 0.000\n",
            "Processing column: bed1\n",
            "Basic metrics for bed1 on 2023-02-20\n",
            "Distribution metrics for bed1 on 2023-02-20\n",
            "Quantile metrics for bed1 on 2023-02-20\n",
            "Entropy calculation for bed1 on 2023-02-20\n",
            "Entropy calculated: 4.064\n",
            "Mutual information: bed1 vs aimp on 2023-02-20\n",
            "MI calculated: 0.012\n",
            "Processing column: bed2\n",
            "Basic metrics for bed2 on 2023-02-20\n",
            "Distribution metrics for bed2 on 2023-02-20\n",
            "Quantile metrics for bed2 on 2023-02-20\n",
            "Entropy calculation for bed2 on 2023-02-20\n",
            "Entropy calculated: 2.948\n",
            "Mutual information: bed2 vs aimp on 2023-02-20\n",
            "MI calculated: 0.039\n",
            "Processing column: bfo1\n",
            "Basic metrics for bfo1 on 2023-02-20\n",
            "Distribution metrics for bfo1 on 2023-02-20\n",
            "Quantile metrics for bfo1 on 2023-02-20\n",
            "Entropy calculation for bfo1 on 2023-02-20\n",
            "Entropy calculated: 4.568\n",
            "Mutual information: bfo1 vs aimp on 2023-02-20\n",
            "MI calculated: 0.000\n",
            "Processing column: bfo2\n",
            "Basic metrics for bfo2 on 2023-02-20\n",
            "Distribution metrics for bfo2 on 2023-02-20\n",
            "Quantile metrics for bfo2 on 2023-02-20\n",
            "Entropy calculation for bfo2 on 2023-02-20\n",
            "Entropy calculated: 5.260\n",
            "Mutual information: bfo2 vs aimp on 2023-02-20\n",
            "MI calculated: 0.000\n",
            "Processing column: bso1\n",
            "Basic metrics for bso1 on 2023-02-20\n",
            "Distribution metrics for bso1 on 2023-02-20\n",
            "Quantile metrics for bso1 on 2023-02-20\n",
            "Entropy calculation for bso1 on 2023-02-20\n",
            "Entropy calculated: 4.627\n",
            "Mutual information: bso1 vs aimp on 2023-02-20\n",
            "MI calculated: 0.000\n",
            "Processing column: bso2\n",
            "Basic metrics for bso2 on 2023-02-20\n",
            "Distribution metrics for bso2 on 2023-02-20\n",
            "Quantile metrics for bso2 on 2023-02-20\n",
            "Entropy calculation for bso2 on 2023-02-20\n",
            "Entropy calculated: 1.854\n",
            "Mutual information: bso2 vs aimp on 2023-02-20\n",
            "MI calculated: 0.000\n",
            "Processing column: bso3\n",
            "Basic metrics for bso3 on 2023-02-20\n",
            "Distribution metrics for bso3 on 2023-02-20\n",
            "Quantile metrics for bso3 on 2023-02-20\n",
            "Entropy calculation for bso3 on 2023-02-20\n",
            "Entropy calculated: 5.289\n",
            "Mutual information: bso3 vs aimp on 2023-02-20\n",
            "MI calculated: 0.000\n",
            "Processing column: ced1\n",
            "Basic metrics for ced1 on 2023-02-20\n",
            "Distribution metrics for ced1 on 2023-02-20\n",
            "Quantile metrics for ced1 on 2023-02-20\n",
            "Entropy calculation for ced1 on 2023-02-20\n",
            "Entropy calculated: 5.038\n",
            "Mutual information: ced1 vs aimp on 2023-02-20\n",
            "MI calculated: 0.000\n",
            "Processing column: cfo1\n",
            "Basic metrics for cfo1 on 2023-02-20\n",
            "Distribution metrics for cfo1 on 2023-02-20\n",
            "Quantile metrics for cfo1 on 2023-02-20\n",
            "Entropy calculation for cfo1 on 2023-02-20\n",
            "Entropy calculated: 4.932\n",
            "Mutual information: cfo1 vs aimp on 2023-02-20\n",
            "MI calculated: 0.000\n",
            "Processing column: cso1\n",
            "Basic metrics for cso1 on 2023-02-20\n",
            "Distribution metrics for cso1 on 2023-02-20\n",
            "Quantile metrics for cso1 on 2023-02-20\n",
            "Entropy calculation for cso1 on 2023-02-20\n",
            "Entropy calculated: 5.321\n",
            "Mutual information: cso1 vs aimp on 2023-02-20\n",
            "MI calculated: 0.000\n",
            "Processing column: y\n",
            "Basic metrics for y on 2023-02-20\n",
            "Distribution metrics for y on 2023-02-20\n",
            "Quantile metrics for y on 2023-02-20\n",
            "Entropy calculation for y on 2023-02-20\n",
            "Entropy calculated: 0.441\n",
            "Mutual information: y vs aimp on 2023-02-20\n",
            "MI calculated: 0.000\n",
            "Processing column: category\n",
            "Basic metrics for category on 2023-02-20\n",
            "Distribution metrics for category on 2023-02-20\n",
            "Quantile metrics for category on 2023-02-20\n",
            "Entropy calculation for category on 2023-02-20\n",
            "Entropy calculated: 0.264\n",
            "Mutual information: category vs aimp on 2023-02-20\n",
            "MI calculated: 0.000\n",
            "Completed 2023-02-20 - Generated 662 features\n",
            "Processing date 52/58: 2023-02-21\n",
            "Processing 86400 records\n",
            "Correlation matrix for 2023-02-21\n",
            "Correlation matrix calculated for 19 columns\n",
            "Processing column: aimp\n",
            "Basic metrics for aimp on 2023-02-21\n",
            "Distribution metrics for aimp on 2023-02-21\n",
            "Quantile metrics for aimp on 2023-02-21\n",
            "Entropy calculation for aimp on 2023-02-21\n",
            "Entropy calculated: 0.082\n",
            "Processing column: amud\n",
            "Basic metrics for amud on 2023-02-21\n",
            "Distribution metrics for amud on 2023-02-21\n",
            "Quantile metrics for amud on 2023-02-21\n",
            "Entropy calculation for amud on 2023-02-21\n",
            "Entropy calculated: 4.590\n",
            "Mutual information: amud vs aimp on 2023-02-21\n",
            "MI calculated: 0.000\n",
            "Processing column: arnd\n",
            "Basic metrics for arnd on 2023-02-21\n",
            "Distribution metrics for arnd on 2023-02-21\n",
            "Quantile metrics for arnd on 2023-02-21\n",
            "Entropy calculation for arnd on 2023-02-21\n",
            "Entropy calculated: 4.858\n",
            "Mutual information: arnd vs aimp on 2023-02-21\n",
            "MI calculated: 0.000\n",
            "Processing column: asin1\n",
            "Basic metrics for asin1 on 2023-02-21\n",
            "Distribution metrics for asin1 on 2023-02-21\n",
            "Quantile metrics for asin1 on 2023-02-21\n",
            "Entropy calculation for asin1 on 2023-02-21\n",
            "Entropy calculated: 4.931\n",
            "Mutual information: asin1 vs aimp on 2023-02-21\n",
            "MI calculated: 0.000\n",
            "Processing column: asin2\n",
            "Basic metrics for asin2 on 2023-02-21\n",
            "Distribution metrics for asin2 on 2023-02-21\n",
            "Quantile metrics for asin2 on 2023-02-21\n",
            "Entropy calculation for asin2 on 2023-02-21\n",
            "Entropy calculated: 5.379\n",
            "Mutual information: asin2 vs aimp on 2023-02-21\n",
            "MI calculated: 0.000\n",
            "Processing column: adbr\n",
            "Basic metrics for adbr on 2023-02-21\n",
            "Distribution metrics for adbr on 2023-02-21\n",
            "Quantile metrics for adbr on 2023-02-21\n",
            "Entropy calculation for adbr on 2023-02-21\n",
            "Entropy calculated: 0.999\n",
            "Mutual information: adbr vs aimp on 2023-02-21\n",
            "MI calculated: 0.000\n",
            "Processing column: adfl\n",
            "Basic metrics for adfl on 2023-02-21\n",
            "Distribution metrics for adfl on 2023-02-21\n",
            "Quantile metrics for adfl on 2023-02-21\n",
            "Entropy calculation for adfl on 2023-02-21\n",
            "Entropy calculated: 0.971\n",
            "Mutual information: adfl vs aimp on 2023-02-21\n",
            "MI calculated: 0.000\n",
            "Processing column: bed1\n",
            "Basic metrics for bed1 on 2023-02-21\n",
            "Distribution metrics for bed1 on 2023-02-21\n",
            "Quantile metrics for bed1 on 2023-02-21\n",
            "Entropy calculation for bed1 on 2023-02-21\n",
            "Entropy calculated: 4.791\n",
            "Mutual information: bed1 vs aimp on 2023-02-21\n",
            "MI calculated: 0.014\n",
            "Processing column: bed2\n",
            "Basic metrics for bed2 on 2023-02-21\n",
            "Distribution metrics for bed2 on 2023-02-21\n",
            "Quantile metrics for bed2 on 2023-02-21\n",
            "Entropy calculation for bed2 on 2023-02-21\n",
            "Entropy calculated: 3.011\n",
            "Mutual information: bed2 vs aimp on 2023-02-21\n",
            "MI calculated: 0.039\n",
            "Processing column: bfo1\n",
            "Basic metrics for bfo1 on 2023-02-21\n",
            "Distribution metrics for bfo1 on 2023-02-21\n",
            "Quantile metrics for bfo1 on 2023-02-21\n",
            "Entropy calculation for bfo1 on 2023-02-21\n",
            "Entropy calculated: 4.581\n",
            "Mutual information: bfo1 vs aimp on 2023-02-21\n",
            "MI calculated: 0.000\n",
            "Processing column: bfo2\n",
            "Basic metrics for bfo2 on 2023-02-21\n",
            "Distribution metrics for bfo2 on 2023-02-21\n",
            "Quantile metrics for bfo2 on 2023-02-21\n",
            "Entropy calculation for bfo2 on 2023-02-21\n",
            "Entropy calculated: 4.145\n",
            "Mutual information: bfo2 vs aimp on 2023-02-21\n",
            "MI calculated: 0.000\n",
            "Processing column: bso1\n",
            "Basic metrics for bso1 on 2023-02-21\n",
            "Distribution metrics for bso1 on 2023-02-21\n",
            "Quantile metrics for bso1 on 2023-02-21\n",
            "Entropy calculation for bso1 on 2023-02-21\n",
            "Entropy calculated: 5.154\n",
            "Mutual information: bso1 vs aimp on 2023-02-21\n",
            "MI calculated: 0.000\n",
            "Processing column: bso2\n",
            "Basic metrics for bso2 on 2023-02-21\n",
            "Distribution metrics for bso2 on 2023-02-21\n",
            "Quantile metrics for bso2 on 2023-02-21\n",
            "Entropy calculation for bso2 on 2023-02-21\n",
            "Entropy calculated: 5.513\n",
            "Mutual information: bso2 vs aimp on 2023-02-21\n",
            "MI calculated: 0.000\n",
            "Processing column: bso3\n",
            "Basic metrics for bso3 on 2023-02-21\n",
            "Distribution metrics for bso3 on 2023-02-21\n",
            "Quantile metrics for bso3 on 2023-02-21\n",
            "Entropy calculation for bso3 on 2023-02-21\n",
            "Entropy calculated: 3.461\n",
            "Mutual information: bso3 vs aimp on 2023-02-21\n",
            "MI calculated: 0.000\n",
            "Processing column: ced1\n",
            "Basic metrics for ced1 on 2023-02-21\n",
            "Distribution metrics for ced1 on 2023-02-21\n",
            "Quantile metrics for ced1 on 2023-02-21\n",
            "Entropy calculation for ced1 on 2023-02-21\n",
            "Entropy calculated: 4.918\n",
            "Mutual information: ced1 vs aimp on 2023-02-21\n",
            "MI calculated: 0.000\n",
            "Processing column: cfo1\n",
            "Basic metrics for cfo1 on 2023-02-21\n",
            "Distribution metrics for cfo1 on 2023-02-21\n",
            "Quantile metrics for cfo1 on 2023-02-21\n",
            "Entropy calculation for cfo1 on 2023-02-21\n",
            "Entropy calculated: 5.166\n",
            "Mutual information: cfo1 vs aimp on 2023-02-21\n",
            "MI calculated: 0.000\n",
            "Processing column: cso1\n",
            "Basic metrics for cso1 on 2023-02-21\n",
            "Distribution metrics for cso1 on 2023-02-21\n",
            "Quantile metrics for cso1 on 2023-02-21\n",
            "Entropy calculation for cso1 on 2023-02-21\n",
            "Entropy calculated: 4.361\n",
            "Mutual information: cso1 vs aimp on 2023-02-21\n",
            "MI calculated: 0.000\n",
            "Processing column: y\n",
            "Basic metrics for y on 2023-02-21\n",
            "Distribution metrics for y on 2023-02-21\n",
            "Quantile metrics for y on 2023-02-21\n",
            "Entropy calculation for y on 2023-02-21\n",
            "Entropy calculated: 0.152\n",
            "Mutual information: y vs aimp on 2023-02-21\n",
            "MI calculated: 0.000\n",
            "Processing column: category\n",
            "Basic metrics for category on 2023-02-21\n",
            "Distribution metrics for category on 2023-02-21\n",
            "Quantile metrics for category on 2023-02-21\n",
            "Entropy calculation for category on 2023-02-21\n",
            "Entropy calculated: 0.185\n",
            "Mutual information: category vs aimp on 2023-02-21\n",
            "MI calculated: 0.000\n",
            "Completed 2023-02-21 - Generated 662 features\n",
            "Processing date 53/58: 2023-02-22\n",
            "Processing 86400 records\n",
            "Correlation matrix for 2023-02-22\n",
            "Correlation matrix calculated for 19 columns\n",
            "Processing column: aimp\n",
            "Basic metrics for aimp on 2023-02-22\n",
            "Distribution metrics for aimp on 2023-02-22\n",
            "Quantile metrics for aimp on 2023-02-22\n",
            "Entropy calculation for aimp on 2023-02-22\n",
            "Entropy calculated: 0.083\n",
            "Processing column: amud\n",
            "Basic metrics for amud on 2023-02-22\n",
            "Distribution metrics for amud on 2023-02-22\n",
            "Quantile metrics for amud on 2023-02-22\n",
            "Entropy calculation for amud on 2023-02-22\n",
            "Entropy calculated: 3.946\n",
            "Mutual information: amud vs aimp on 2023-02-22\n",
            "MI calculated: 0.000\n",
            "Processing column: arnd\n",
            "Basic metrics for arnd on 2023-02-22\n",
            "Distribution metrics for arnd on 2023-02-22\n",
            "Quantile metrics for arnd on 2023-02-22\n",
            "Entropy calculation for arnd on 2023-02-22\n",
            "Entropy calculated: 4.257\n",
            "Mutual information: arnd vs aimp on 2023-02-22\n",
            "MI calculated: 0.000\n",
            "Processing column: asin1\n",
            "Basic metrics for asin1 on 2023-02-22\n",
            "Distribution metrics for asin1 on 2023-02-22\n",
            "Quantile metrics for asin1 on 2023-02-22\n",
            "Entropy calculation for asin1 on 2023-02-22\n",
            "Entropy calculated: 5.588\n",
            "Mutual information: asin1 vs aimp on 2023-02-22\n",
            "MI calculated: 0.000\n",
            "Processing column: asin2\n",
            "Basic metrics for asin2 on 2023-02-22\n",
            "Distribution metrics for asin2 on 2023-02-22\n",
            "Quantile metrics for asin2 on 2023-02-22\n",
            "Entropy calculation for asin2 on 2023-02-22\n",
            "Entropy calculated: 5.359\n",
            "Mutual information: asin2 vs aimp on 2023-02-22\n",
            "MI calculated: 0.000\n",
            "Processing column: adbr\n",
            "Basic metrics for adbr on 2023-02-22\n",
            "Distribution metrics for adbr on 2023-02-22\n",
            "Quantile metrics for adbr on 2023-02-22\n",
            "Entropy calculation for adbr on 2023-02-22\n",
            "Entropy calculated: 0.999\n",
            "Mutual information: adbr vs aimp on 2023-02-22\n",
            "MI calculated: 0.000\n",
            "Processing column: adfl\n",
            "Basic metrics for adfl on 2023-02-22\n",
            "Distribution metrics for adfl on 2023-02-22\n",
            "Quantile metrics for adfl on 2023-02-22\n",
            "Entropy calculation for adfl on 2023-02-22\n",
            "Entropy calculated: 0.962\n",
            "Mutual information: adfl vs aimp on 2023-02-22\n",
            "MI calculated: 0.000\n",
            "Processing column: bed1\n",
            "Basic metrics for bed1 on 2023-02-22\n",
            "Distribution metrics for bed1 on 2023-02-22\n",
            "Quantile metrics for bed1 on 2023-02-22\n",
            "Entropy calculation for bed1 on 2023-02-22\n",
            "Entropy calculated: 4.783\n",
            "Mutual information: bed1 vs aimp on 2023-02-22\n",
            "MI calculated: 0.014\n",
            "Processing column: bed2\n",
            "Basic metrics for bed2 on 2023-02-22\n",
            "Distribution metrics for bed2 on 2023-02-22\n",
            "Quantile metrics for bed2 on 2023-02-22\n",
            "Entropy calculation for bed2 on 2023-02-22\n",
            "Entropy calculated: 2.732\n",
            "Mutual information: bed2 vs aimp on 2023-02-22\n",
            "MI calculated: 0.052\n",
            "Processing column: bfo1\n",
            "Basic metrics for bfo1 on 2023-02-22\n",
            "Distribution metrics for bfo1 on 2023-02-22\n",
            "Quantile metrics for bfo1 on 2023-02-22\n",
            "Entropy calculation for bfo1 on 2023-02-22\n",
            "Entropy calculated: 4.234\n",
            "Mutual information: bfo1 vs aimp on 2023-02-22\n",
            "MI calculated: 0.000\n",
            "Processing column: bfo2\n",
            "Basic metrics for bfo2 on 2023-02-22\n",
            "Distribution metrics for bfo2 on 2023-02-22\n",
            "Quantile metrics for bfo2 on 2023-02-22\n",
            "Entropy calculation for bfo2 on 2023-02-22\n",
            "Entropy calculated: 1.442\n",
            "Mutual information: bfo2 vs aimp on 2023-02-22\n",
            "MI calculated: 0.000\n",
            "Processing column: bso1\n",
            "Basic metrics for bso1 on 2023-02-22\n",
            "Distribution metrics for bso1 on 2023-02-22\n",
            "Quantile metrics for bso1 on 2023-02-22\n",
            "Entropy calculation for bso1 on 2023-02-22\n",
            "Entropy calculated: 4.707\n",
            "Mutual information: bso1 vs aimp on 2023-02-22\n",
            "MI calculated: 0.000\n",
            "Processing column: bso2\n",
            "Basic metrics for bso2 on 2023-02-22\n",
            "Distribution metrics for bso2 on 2023-02-22\n",
            "Quantile metrics for bso2 on 2023-02-22\n",
            "Entropy calculation for bso2 on 2023-02-22\n",
            "Entropy calculated: 4.443\n",
            "Mutual information: bso2 vs aimp on 2023-02-22\n",
            "MI calculated: 0.000\n",
            "Processing column: bso3\n",
            "Basic metrics for bso3 on 2023-02-22\n",
            "Distribution metrics for bso3 on 2023-02-22\n",
            "Quantile metrics for bso3 on 2023-02-22\n",
            "Entropy calculation for bso3 on 2023-02-22\n",
            "Entropy calculated: 3.178\n",
            "Mutual information: bso3 vs aimp on 2023-02-22\n",
            "MI calculated: 0.000\n",
            "Processing column: ced1\n",
            "Basic metrics for ced1 on 2023-02-22\n",
            "Distribution metrics for ced1 on 2023-02-22\n",
            "Quantile metrics for ced1 on 2023-02-22\n",
            "Entropy calculation for ced1 on 2023-02-22\n",
            "Entropy calculated: 5.128\n",
            "Mutual information: ced1 vs aimp on 2023-02-22\n",
            "MI calculated: 0.000\n",
            "Processing column: cfo1\n",
            "Basic metrics for cfo1 on 2023-02-22\n",
            "Distribution metrics for cfo1 on 2023-02-22\n",
            "Quantile metrics for cfo1 on 2023-02-22\n",
            "Entropy calculation for cfo1 on 2023-02-22\n",
            "Entropy calculated: 5.032\n",
            "Mutual information: cfo1 vs aimp on 2023-02-22\n",
            "MI calculated: 0.000\n",
            "Processing column: cso1\n",
            "Basic metrics for cso1 on 2023-02-22\n",
            "Distribution metrics for cso1 on 2023-02-22\n",
            "Quantile metrics for cso1 on 2023-02-22\n",
            "Entropy calculation for cso1 on 2023-02-22\n",
            "Entropy calculated: 5.082\n",
            "Mutual information: cso1 vs aimp on 2023-02-22\n",
            "MI calculated: 0.000\n",
            "Processing column: y\n",
            "Basic metrics for y on 2023-02-22\n",
            "Distribution metrics for y on 2023-02-22\n",
            "Quantile metrics for y on 2023-02-22\n",
            "Entropy calculation for y on 2023-02-22\n",
            "Entropy calculated: 0.161\n",
            "Mutual information: y vs aimp on 2023-02-22\n",
            "MI calculated: 0.000\n",
            "Processing column: category\n",
            "Basic metrics for category on 2023-02-22\n",
            "Distribution metrics for category on 2023-02-22\n",
            "Quantile metrics for category on 2023-02-22\n",
            "Entropy calculation for category on 2023-02-22\n",
            "Entropy calculated: 0.131\n",
            "Mutual information: category vs aimp on 2023-02-22\n",
            "MI calculated: 0.000\n",
            "Completed 2023-02-22 - Generated 662 features\n",
            "Processing date 54/58: 2023-02-23\n",
            "Processing 86400 records\n",
            "Correlation matrix for 2023-02-23\n",
            "Correlation matrix calculated for 19 columns\n",
            "Processing column: aimp\n",
            "Basic metrics for aimp on 2023-02-23\n",
            "Distribution metrics for aimp on 2023-02-23\n",
            "Quantile metrics for aimp on 2023-02-23\n",
            "Entropy calculation for aimp on 2023-02-23\n",
            "Entropy calculated: 0.080\n",
            "Processing column: amud\n",
            "Basic metrics for amud on 2023-02-23\n",
            "Distribution metrics for amud on 2023-02-23\n",
            "Quantile metrics for amud on 2023-02-23\n",
            "Entropy calculation for amud on 2023-02-23\n",
            "Entropy calculated: 3.988\n",
            "Mutual information: amud vs aimp on 2023-02-23\n",
            "MI calculated: 0.000\n",
            "Processing column: arnd\n",
            "Basic metrics for arnd on 2023-02-23\n",
            "Distribution metrics for arnd on 2023-02-23\n",
            "Quantile metrics for arnd on 2023-02-23\n",
            "Entropy calculation for arnd on 2023-02-23\n",
            "Entropy calculated: 5.233\n",
            "Mutual information: arnd vs aimp on 2023-02-23\n",
            "MI calculated: 0.000\n",
            "Processing column: asin1\n",
            "Basic metrics for asin1 on 2023-02-23\n",
            "Distribution metrics for asin1 on 2023-02-23\n",
            "Quantile metrics for asin1 on 2023-02-23\n",
            "Entropy calculation for asin1 on 2023-02-23\n",
            "Entropy calculated: 4.986\n",
            "Mutual information: asin1 vs aimp on 2023-02-23\n",
            "MI calculated: 0.000\n",
            "Processing column: asin2\n",
            "Basic metrics for asin2 on 2023-02-23\n",
            "Distribution metrics for asin2 on 2023-02-23\n",
            "Quantile metrics for asin2 on 2023-02-23\n",
            "Entropy calculation for asin2 on 2023-02-23\n",
            "Entropy calculated: 5.380\n",
            "Mutual information: asin2 vs aimp on 2023-02-23\n",
            "MI calculated: 0.000\n",
            "Processing column: adbr\n",
            "Basic metrics for adbr on 2023-02-23\n",
            "Distribution metrics for adbr on 2023-02-23\n",
            "Quantile metrics for adbr on 2023-02-23\n",
            "Entropy calculation for adbr on 2023-02-23\n",
            "Entropy calculated: 1.000\n",
            "Mutual information: adbr vs aimp on 2023-02-23\n",
            "MI calculated: 0.000\n",
            "Processing column: adfl\n",
            "Basic metrics for adfl on 2023-02-23\n",
            "Distribution metrics for adfl on 2023-02-23\n",
            "Quantile metrics for adfl on 2023-02-23\n",
            "Entropy calculation for adfl on 2023-02-23\n",
            "Entropy calculated: 0.965\n",
            "Mutual information: adfl vs aimp on 2023-02-23\n",
            "MI calculated: 0.000\n",
            "Processing column: bed1\n",
            "Basic metrics for bed1 on 2023-02-23\n",
            "Distribution metrics for bed1 on 2023-02-23\n",
            "Quantile metrics for bed1 on 2023-02-23\n",
            "Entropy calculation for bed1 on 2023-02-23\n",
            "Entropy calculated: 4.473\n",
            "Mutual information: bed1 vs aimp on 2023-02-23\n",
            "MI calculated: 0.013\n",
            "Processing column: bed2\n",
            "Basic metrics for bed2 on 2023-02-23\n",
            "Distribution metrics for bed2 on 2023-02-23\n",
            "Quantile metrics for bed2 on 2023-02-23\n",
            "Entropy calculation for bed2 on 2023-02-23\n",
            "Entropy calculated: 2.369\n",
            "Mutual information: bed2 vs aimp on 2023-02-23\n",
            "MI calculated: 0.028\n",
            "Processing column: bfo1\n",
            "Basic metrics for bfo1 on 2023-02-23\n",
            "Distribution metrics for bfo1 on 2023-02-23\n",
            "Quantile metrics for bfo1 on 2023-02-23\n",
            "Entropy calculation for bfo1 on 2023-02-23\n",
            "Entropy calculated: 4.624\n",
            "Mutual information: bfo1 vs aimp on 2023-02-23\n",
            "MI calculated: 0.000\n",
            "Processing column: bfo2\n",
            "Basic metrics for bfo2 on 2023-02-23\n",
            "Distribution metrics for bfo2 on 2023-02-23\n",
            "Quantile metrics for bfo2 on 2023-02-23\n",
            "Entropy calculation for bfo2 on 2023-02-23\n",
            "Entropy calculated: 3.320\n",
            "Mutual information: bfo2 vs aimp on 2023-02-23\n",
            "MI calculated: 0.000\n",
            "Processing column: bso1\n",
            "Basic metrics for bso1 on 2023-02-23\n",
            "Distribution metrics for bso1 on 2023-02-23\n",
            "Quantile metrics for bso1 on 2023-02-23\n",
            "Entropy calculation for bso1 on 2023-02-23\n",
            "Entropy calculated: 4.908\n",
            "Mutual information: bso1 vs aimp on 2023-02-23\n",
            "MI calculated: 0.000\n",
            "Processing column: bso2\n",
            "Basic metrics for bso2 on 2023-02-23\n",
            "Distribution metrics for bso2 on 2023-02-23\n",
            "Quantile metrics for bso2 on 2023-02-23\n",
            "Entropy calculation for bso2 on 2023-02-23\n",
            "Entropy calculated: 1.700\n",
            "Mutual information: bso2 vs aimp on 2023-02-23\n",
            "MI calculated: 0.000\n",
            "Processing column: bso3\n",
            "Basic metrics for bso3 on 2023-02-23\n",
            "Distribution metrics for bso3 on 2023-02-23\n",
            "Quantile metrics for bso3 on 2023-02-23\n",
            "Entropy calculation for bso3 on 2023-02-23\n",
            "Entropy calculated: 5.287\n",
            "Mutual information: bso3 vs aimp on 2023-02-23\n",
            "MI calculated: 0.000\n",
            "Processing column: ced1\n",
            "Basic metrics for ced1 on 2023-02-23\n",
            "Distribution metrics for ced1 on 2023-02-23\n",
            "Quantile metrics for ced1 on 2023-02-23\n",
            "Entropy calculation for ced1 on 2023-02-23\n",
            "Entropy calculated: 2.852\n",
            "Mutual information: ced1 vs aimp on 2023-02-23\n",
            "MI calculated: 0.000\n",
            "Processing column: cfo1\n",
            "Basic metrics for cfo1 on 2023-02-23\n",
            "Distribution metrics for cfo1 on 2023-02-23\n",
            "Quantile metrics for cfo1 on 2023-02-23\n",
            "Entropy calculation for cfo1 on 2023-02-23\n",
            "Entropy calculated: 5.128\n",
            "Mutual information: cfo1 vs aimp on 2023-02-23\n",
            "MI calculated: 0.000\n",
            "Processing column: cso1\n",
            "Basic metrics for cso1 on 2023-02-23\n",
            "Distribution metrics for cso1 on 2023-02-23\n",
            "Quantile metrics for cso1 on 2023-02-23\n",
            "Entropy calculation for cso1 on 2023-02-23\n",
            "Entropy calculated: 3.638\n",
            "Mutual information: cso1 vs aimp on 2023-02-23\n",
            "MI calculated: 0.000\n",
            "Processing column: y\n",
            "Basic metrics for y on 2023-02-23\n",
            "Distribution metrics for y on 2023-02-23\n",
            "Quantile metrics for y on 2023-02-23\n",
            "Entropy calculation for y on 2023-02-23\n",
            "Entropy calculated: 0.210\n",
            "Mutual information: y vs aimp on 2023-02-23\n",
            "MI calculated: 0.000\n",
            "Processing column: category\n",
            "Basic metrics for category on 2023-02-23\n",
            "Distribution metrics for category on 2023-02-23\n",
            "Quantile metrics for category on 2023-02-23\n",
            "Entropy calculation for category on 2023-02-23\n",
            "Entropy calculated: 0.226\n",
            "Mutual information: category vs aimp on 2023-02-23\n",
            "MI calculated: 0.000\n",
            "Completed 2023-02-23 - Generated 662 features\n",
            "Processing date 55/58: 2023-02-24\n",
            "Processing 86400 records\n",
            "Correlation matrix for 2023-02-24\n",
            "Correlation matrix calculated for 19 columns\n",
            "Processing column: aimp\n",
            "Basic metrics for aimp on 2023-02-24\n",
            "Distribution metrics for aimp on 2023-02-24\n",
            "Quantile metrics for aimp on 2023-02-24\n",
            "Entropy calculation for aimp on 2023-02-24\n",
            "Entropy calculated: 0.083\n",
            "Processing column: amud\n",
            "Basic metrics for amud on 2023-02-24\n",
            "Distribution metrics for amud on 2023-02-24\n",
            "Quantile metrics for amud on 2023-02-24\n",
            "Entropy calculation for amud on 2023-02-24\n",
            "Entropy calculated: 4.118\n",
            "Mutual information: amud vs aimp on 2023-02-24\n",
            "MI calculated: 0.000\n",
            "Processing column: arnd\n",
            "Basic metrics for arnd on 2023-02-24\n",
            "Distribution metrics for arnd on 2023-02-24\n",
            "Quantile metrics for arnd on 2023-02-24\n",
            "Entropy calculation for arnd on 2023-02-24\n",
            "Entropy calculated: 5.001\n",
            "Mutual information: arnd vs aimp on 2023-02-24\n",
            "MI calculated: 0.000\n",
            "Processing column: asin1\n",
            "Basic metrics for asin1 on 2023-02-24\n",
            "Distribution metrics for asin1 on 2023-02-24\n",
            "Quantile metrics for asin1 on 2023-02-24\n",
            "Entropy calculation for asin1 on 2023-02-24\n",
            "Entropy calculated: 5.632\n",
            "Mutual information: asin1 vs aimp on 2023-02-24\n",
            "MI calculated: 0.000\n",
            "Processing column: asin2\n",
            "Basic metrics for asin2 on 2023-02-24\n",
            "Distribution metrics for asin2 on 2023-02-24\n",
            "Quantile metrics for asin2 on 2023-02-24\n",
            "Entropy calculation for asin2 on 2023-02-24\n",
            "Entropy calculated: 5.359\n",
            "Mutual information: asin2 vs aimp on 2023-02-24\n",
            "MI calculated: 0.000\n",
            "Processing column: adbr\n",
            "Basic metrics for adbr on 2023-02-24\n",
            "Distribution metrics for adbr on 2023-02-24\n",
            "Quantile metrics for adbr on 2023-02-24\n",
            "Entropy calculation for adbr on 2023-02-24\n",
            "Entropy calculated: 1.000\n",
            "Mutual information: adbr vs aimp on 2023-02-24\n",
            "MI calculated: 0.000\n",
            "Processing column: adfl\n",
            "Basic metrics for adfl on 2023-02-24\n",
            "Distribution metrics for adfl on 2023-02-24\n",
            "Quantile metrics for adfl on 2023-02-24\n",
            "Entropy calculation for adfl on 2023-02-24\n",
            "Entropy calculated: 0.970\n",
            "Mutual information: adfl vs aimp on 2023-02-24\n",
            "MI calculated: 0.000\n",
            "Processing column: bed1\n",
            "Basic metrics for bed1 on 2023-02-24\n",
            "Distribution metrics for bed1 on 2023-02-24\n",
            "Quantile metrics for bed1 on 2023-02-24\n",
            "Entropy calculation for bed1 on 2023-02-24\n",
            "Entropy calculated: 3.428\n",
            "Mutual information: bed1 vs aimp on 2023-02-24\n",
            "MI calculated: 0.012\n",
            "Processing column: bed2\n",
            "Basic metrics for bed2 on 2023-02-24\n",
            "Distribution metrics for bed2 on 2023-02-24\n",
            "Quantile metrics for bed2 on 2023-02-24\n",
            "Entropy calculation for bed2 on 2023-02-24\n",
            "Entropy calculated: 2.588\n",
            "Mutual information: bed2 vs aimp on 2023-02-24\n",
            "MI calculated: 0.034\n",
            "Processing column: bfo1\n",
            "Basic metrics for bfo1 on 2023-02-24\n",
            "Distribution metrics for bfo1 on 2023-02-24\n",
            "Quantile metrics for bfo1 on 2023-02-24\n",
            "Entropy calculation for bfo1 on 2023-02-24\n",
            "Entropy calculated: 4.718\n",
            "Mutual information: bfo1 vs aimp on 2023-02-24\n",
            "MI calculated: 0.000\n",
            "Processing column: bfo2\n",
            "Basic metrics for bfo2 on 2023-02-24\n",
            "Distribution metrics for bfo2 on 2023-02-24\n",
            "Quantile metrics for bfo2 on 2023-02-24\n",
            "Entropy calculation for bfo2 on 2023-02-24\n",
            "Entropy calculated: 3.396\n",
            "Mutual information: bfo2 vs aimp on 2023-02-24\n",
            "MI calculated: 0.000\n",
            "Processing column: bso1\n",
            "Basic metrics for bso1 on 2023-02-24\n",
            "Distribution metrics for bso1 on 2023-02-24\n",
            "Quantile metrics for bso1 on 2023-02-24\n",
            "Entropy calculation for bso1 on 2023-02-24\n",
            "Entropy calculated: 5.020\n",
            "Mutual information: bso1 vs aimp on 2023-02-24\n",
            "MI calculated: 0.000\n",
            "Processing column: bso2\n",
            "Basic metrics for bso2 on 2023-02-24\n",
            "Distribution metrics for bso2 on 2023-02-24\n",
            "Quantile metrics for bso2 on 2023-02-24\n",
            "Entropy calculation for bso2 on 2023-02-24\n",
            "Entropy calculated: 5.518\n",
            "Mutual information: bso2 vs aimp on 2023-02-24\n",
            "MI calculated: 0.000\n",
            "Processing column: bso3\n",
            "Basic metrics for bso3 on 2023-02-24\n",
            "Distribution metrics for bso3 on 2023-02-24\n",
            "Quantile metrics for bso3 on 2023-02-24\n",
            "Entropy calculation for bso3 on 2023-02-24\n",
            "Entropy calculated: 5.254\n",
            "Mutual information: bso3 vs aimp on 2023-02-24\n",
            "MI calculated: 0.000\n",
            "Processing column: ced1\n",
            "Basic metrics for ced1 on 2023-02-24\n",
            "Distribution metrics for ced1 on 2023-02-24\n",
            "Quantile metrics for ced1 on 2023-02-24\n",
            "Entropy calculation for ced1 on 2023-02-24\n",
            "Entropy calculated: 3.940\n",
            "Mutual information: ced1 vs aimp on 2023-02-24\n",
            "MI calculated: 0.000\n",
            "Processing column: cfo1\n",
            "Basic metrics for cfo1 on 2023-02-24\n",
            "Distribution metrics for cfo1 on 2023-02-24\n",
            "Quantile metrics for cfo1 on 2023-02-24\n",
            "Entropy calculation for cfo1 on 2023-02-24\n",
            "Entropy calculated: 5.347\n",
            "Mutual information: cfo1 vs aimp on 2023-02-24\n",
            "MI calculated: 0.000\n",
            "Processing column: cso1\n",
            "Basic metrics for cso1 on 2023-02-24\n",
            "Distribution metrics for cso1 on 2023-02-24\n",
            "Quantile metrics for cso1 on 2023-02-24\n",
            "Entropy calculation for cso1 on 2023-02-24\n",
            "Entropy calculated: 3.499\n",
            "Mutual information: cso1 vs aimp on 2023-02-24\n",
            "MI calculated: 0.000\n",
            "Processing column: y\n",
            "Basic metrics for y on 2023-02-24\n",
            "Distribution metrics for y on 2023-02-24\n",
            "Quantile metrics for y on 2023-02-24\n",
            "Entropy calculation for y on 2023-02-24\n",
            "Entropy calculated: 0.206\n",
            "Mutual information: y vs aimp on 2023-02-24\n",
            "MI calculated: 0.000\n",
            "Processing column: category\n",
            "Basic metrics for category on 2023-02-24\n",
            "Distribution metrics for category on 2023-02-24\n",
            "Quantile metrics for category on 2023-02-24\n",
            "Entropy calculation for category on 2023-02-24\n",
            "Entropy calculated: 0.206\n",
            "Mutual information: category vs aimp on 2023-02-24\n",
            "MI calculated: 0.000\n",
            "Completed 2023-02-24 - Generated 662 features\n",
            "Processing date 56/58: 2023-02-25\n",
            "Processing 86400 records\n",
            "Correlation matrix for 2023-02-25\n",
            "Correlation matrix calculated for 19 columns\n",
            "Processing column: aimp\n",
            "Basic metrics for aimp on 2023-02-25\n",
            "Distribution metrics for aimp on 2023-02-25\n",
            "Quantile metrics for aimp on 2023-02-25\n",
            "Entropy calculation for aimp on 2023-02-25\n",
            "Entropy calculated: 0.078\n",
            "Processing column: amud\n",
            "Basic metrics for amud on 2023-02-25\n",
            "Distribution metrics for amud on 2023-02-25\n",
            "Quantile metrics for amud on 2023-02-25\n",
            "Entropy calculation for amud on 2023-02-25\n",
            "Entropy calculated: 4.153\n",
            "Mutual information: amud vs aimp on 2023-02-25\n",
            "MI calculated: 0.000\n",
            "Processing column: arnd\n",
            "Basic metrics for arnd on 2023-02-25\n",
            "Distribution metrics for arnd on 2023-02-25\n",
            "Quantile metrics for arnd on 2023-02-25\n",
            "Entropy calculation for arnd on 2023-02-25\n",
            "Entropy calculated: 5.145\n",
            "Mutual information: arnd vs aimp on 2023-02-25\n",
            "MI calculated: 0.000\n",
            "Processing column: asin1\n",
            "Basic metrics for asin1 on 2023-02-25\n",
            "Distribution metrics for asin1 on 2023-02-25\n",
            "Quantile metrics for asin1 on 2023-02-25\n",
            "Entropy calculation for asin1 on 2023-02-25\n",
            "Entropy calculated: 5.149\n",
            "Mutual information: asin1 vs aimp on 2023-02-25\n",
            "MI calculated: 0.000\n",
            "Processing column: asin2\n",
            "Basic metrics for asin2 on 2023-02-25\n",
            "Distribution metrics for asin2 on 2023-02-25\n",
            "Quantile metrics for asin2 on 2023-02-25\n",
            "Entropy calculation for asin2 on 2023-02-25\n",
            "Entropy calculated: 5.380\n",
            "Mutual information: asin2 vs aimp on 2023-02-25\n",
            "MI calculated: 0.000\n",
            "Processing column: adbr\n",
            "Basic metrics for adbr on 2023-02-25\n",
            "Distribution metrics for adbr on 2023-02-25\n",
            "Quantile metrics for adbr on 2023-02-25\n",
            "Entropy calculation for adbr on 2023-02-25\n",
            "Entropy calculated: 1.000\n",
            "Mutual information: adbr vs aimp on 2023-02-25\n",
            "MI calculated: 0.000\n",
            "Processing column: adfl\n",
            "Basic metrics for adfl on 2023-02-25\n",
            "Distribution metrics for adfl on 2023-02-25\n",
            "Quantile metrics for adfl on 2023-02-25\n",
            "Entropy calculation for adfl on 2023-02-25\n",
            "Entropy calculated: 0.970\n",
            "Mutual information: adfl vs aimp on 2023-02-25\n",
            "MI calculated: 0.000\n",
            "Processing column: bed1\n",
            "Basic metrics for bed1 on 2023-02-25\n",
            "Distribution metrics for bed1 on 2023-02-25\n",
            "Quantile metrics for bed1 on 2023-02-25\n",
            "Entropy calculation for bed1 on 2023-02-25\n",
            "Entropy calculated: 4.732\n",
            "Mutual information: bed1 vs aimp on 2023-02-25\n",
            "MI calculated: 0.014\n",
            "Processing column: bed2\n",
            "Basic metrics for bed2 on 2023-02-25\n",
            "Distribution metrics for bed2 on 2023-02-25\n",
            "Quantile metrics for bed2 on 2023-02-25\n",
            "Entropy calculation for bed2 on 2023-02-25\n",
            "Entropy calculated: 2.729\n",
            "Mutual information: bed2 vs aimp on 2023-02-25\n",
            "MI calculated: 0.042\n",
            "Processing column: bfo1\n",
            "Basic metrics for bfo1 on 2023-02-25\n",
            "Distribution metrics for bfo1 on 2023-02-25\n",
            "Quantile metrics for bfo1 on 2023-02-25\n",
            "Entropy calculation for bfo1 on 2023-02-25\n",
            "Entropy calculated: 4.635\n",
            "Mutual information: bfo1 vs aimp on 2023-02-25\n",
            "MI calculated: 0.000\n",
            "Processing column: bfo2\n",
            "Basic metrics for bfo2 on 2023-02-25\n",
            "Distribution metrics for bfo2 on 2023-02-25\n",
            "Quantile metrics for bfo2 on 2023-02-25\n",
            "Entropy calculation for bfo2 on 2023-02-25\n",
            "Entropy calculated: 3.012\n",
            "Mutual information: bfo2 vs aimp on 2023-02-25\n",
            "MI calculated: 0.000\n",
            "Processing column: bso1\n",
            "Basic metrics for bso1 on 2023-02-25\n",
            "Distribution metrics for bso1 on 2023-02-25\n",
            "Quantile metrics for bso1 on 2023-02-25\n",
            "Entropy calculation for bso1 on 2023-02-25\n",
            "Entropy calculated: 4.711\n",
            "Mutual information: bso1 vs aimp on 2023-02-25\n",
            "MI calculated: 0.000\n",
            "Processing column: bso2\n",
            "Basic metrics for bso2 on 2023-02-25\n",
            "Distribution metrics for bso2 on 2023-02-25\n",
            "Quantile metrics for bso2 on 2023-02-25\n",
            "Entropy calculation for bso2 on 2023-02-25\n",
            "Entropy calculated: 5.526\n",
            "Mutual information: bso2 vs aimp on 2023-02-25\n",
            "MI calculated: 0.000\n",
            "Processing column: bso3\n",
            "Basic metrics for bso3 on 2023-02-25\n",
            "Distribution metrics for bso3 on 2023-02-25\n",
            "Quantile metrics for bso3 on 2023-02-25\n",
            "Entropy calculation for bso3 on 2023-02-25\n",
            "Entropy calculated: 5.316\n",
            "Mutual information: bso3 vs aimp on 2023-02-25\n",
            "MI calculated: 0.000\n",
            "Processing column: ced1\n",
            "Basic metrics for ced1 on 2023-02-25\n",
            "Distribution metrics for ced1 on 2023-02-25\n",
            "Quantile metrics for ced1 on 2023-02-25\n",
            "Entropy calculation for ced1 on 2023-02-25\n",
            "Entropy calculated: 5.132\n",
            "Mutual information: ced1 vs aimp on 2023-02-25\n",
            "MI calculated: 0.000\n",
            "Processing column: cfo1\n",
            "Basic metrics for cfo1 on 2023-02-25\n",
            "Distribution metrics for cfo1 on 2023-02-25\n",
            "Quantile metrics for cfo1 on 2023-02-25\n",
            "Entropy calculation for cfo1 on 2023-02-25\n",
            "Entropy calculated: 5.222\n",
            "Mutual information: cfo1 vs aimp on 2023-02-25\n",
            "MI calculated: 0.000\n",
            "Processing column: cso1\n",
            "Basic metrics for cso1 on 2023-02-25\n",
            "Distribution metrics for cso1 on 2023-02-25\n",
            "Quantile metrics for cso1 on 2023-02-25\n",
            "Entropy calculation for cso1 on 2023-02-25\n",
            "Entropy calculated: 3.562\n",
            "Mutual information: cso1 vs aimp on 2023-02-25\n",
            "MI calculated: 0.000\n",
            "Processing column: y\n",
            "Basic metrics for y on 2023-02-25\n",
            "Distribution metrics for y on 2023-02-25\n",
            "Quantile metrics for y on 2023-02-25\n",
            "Entropy calculation for y on 2023-02-25\n",
            "Entropy calculated: 0.091\n",
            "Mutual information: y vs aimp on 2023-02-25\n",
            "MI calculated: 0.000\n",
            "Processing column: category\n",
            "Basic metrics for category on 2023-02-25\n",
            "Distribution metrics for category on 2023-02-25\n",
            "Quantile metrics for category on 2023-02-25\n",
            "Entropy calculation for category on 2023-02-25\n",
            "Entropy calculated: 0.091\n",
            "Mutual information: category vs aimp on 2023-02-25\n",
            "MI calculated: 0.000\n",
            "Completed 2023-02-25 - Generated 662 features\n",
            "Processing date 57/58: 2023-02-26\n",
            "Processing 86400 records\n",
            "Correlation matrix for 2023-02-26\n",
            "Correlation matrix calculated for 19 columns\n",
            "Processing column: aimp\n",
            "Basic metrics for aimp on 2023-02-26\n",
            "Distribution metrics for aimp on 2023-02-26\n",
            "Quantile metrics for aimp on 2023-02-26\n",
            "Entropy calculation for aimp on 2023-02-26\n",
            "Entropy calculated: 0.083\n",
            "Processing column: amud\n",
            "Basic metrics for amud on 2023-02-26\n",
            "Distribution metrics for amud on 2023-02-26\n",
            "Quantile metrics for amud on 2023-02-26\n",
            "Entropy calculation for amud on 2023-02-26\n",
            "Entropy calculated: 4.374\n",
            "Mutual information: amud vs aimp on 2023-02-26\n",
            "MI calculated: 0.000\n",
            "Processing column: arnd\n",
            "Basic metrics for arnd on 2023-02-26\n",
            "Distribution metrics for arnd on 2023-02-26\n",
            "Quantile metrics for arnd on 2023-02-26\n",
            "Entropy calculation for arnd on 2023-02-26\n",
            "Entropy calculated: 4.833\n",
            "Mutual information: arnd vs aimp on 2023-02-26\n",
            "MI calculated: 0.000\n",
            "Processing column: asin1\n",
            "Basic metrics for asin1 on 2023-02-26\n",
            "Distribution metrics for asin1 on 2023-02-26\n",
            "Quantile metrics for asin1 on 2023-02-26\n",
            "Entropy calculation for asin1 on 2023-02-26\n",
            "Entropy calculated: 5.617\n",
            "Mutual information: asin1 vs aimp on 2023-02-26\n",
            "MI calculated: 0.000\n",
            "Processing column: asin2\n",
            "Basic metrics for asin2 on 2023-02-26\n",
            "Distribution metrics for asin2 on 2023-02-26\n",
            "Quantile metrics for asin2 on 2023-02-26\n",
            "Entropy calculation for asin2 on 2023-02-26\n",
            "Entropy calculated: 5.359\n",
            "Mutual information: asin2 vs aimp on 2023-02-26\n",
            "MI calculated: 0.000\n",
            "Processing column: adbr\n",
            "Basic metrics for adbr on 2023-02-26\n",
            "Distribution metrics for adbr on 2023-02-26\n",
            "Quantile metrics for adbr on 2023-02-26\n",
            "Entropy calculation for adbr on 2023-02-26\n",
            "Entropy calculated: 0.993\n",
            "Mutual information: adbr vs aimp on 2023-02-26\n",
            "MI calculated: 0.000\n",
            "Processing column: adfl\n",
            "Basic metrics for adfl on 2023-02-26\n",
            "Distribution metrics for adfl on 2023-02-26\n",
            "Quantile metrics for adfl on 2023-02-26\n",
            "Entropy calculation for adfl on 2023-02-26\n",
            "Entropy calculated: 0.964\n",
            "Mutual information: adfl vs aimp on 2023-02-26\n",
            "MI calculated: 0.000\n",
            "Processing column: bed1\n",
            "Basic metrics for bed1 on 2023-02-26\n",
            "Distribution metrics for bed1 on 2023-02-26\n",
            "Quantile metrics for bed1 on 2023-02-26\n",
            "Entropy calculation for bed1 on 2023-02-26\n",
            "Entropy calculated: 4.901\n",
            "Mutual information: bed1 vs aimp on 2023-02-26\n",
            "MI calculated: 0.013\n",
            "Processing column: bed2\n",
            "Basic metrics for bed2 on 2023-02-26\n",
            "Distribution metrics for bed2 on 2023-02-26\n",
            "Quantile metrics for bed2 on 2023-02-26\n",
            "Entropy calculation for bed2 on 2023-02-26\n",
            "Entropy calculated: 2.796\n",
            "Mutual information: bed2 vs aimp on 2023-02-26\n",
            "MI calculated: 0.047\n",
            "Processing column: bfo1\n",
            "Basic metrics for bfo1 on 2023-02-26\n",
            "Distribution metrics for bfo1 on 2023-02-26\n",
            "Quantile metrics for bfo1 on 2023-02-26\n",
            "Entropy calculation for bfo1 on 2023-02-26\n",
            "Entropy calculated: 4.694\n",
            "Mutual information: bfo1 vs aimp on 2023-02-26\n",
            "MI calculated: 0.000\n",
            "Processing column: bfo2\n",
            "Basic metrics for bfo2 on 2023-02-26\n",
            "Distribution metrics for bfo2 on 2023-02-26\n",
            "Quantile metrics for bfo2 on 2023-02-26\n",
            "Entropy calculation for bfo2 on 2023-02-26\n",
            "Entropy calculated: 1.227\n",
            "Mutual information: bfo2 vs aimp on 2023-02-26\n",
            "MI calculated: 0.000\n",
            "Processing column: bso1\n",
            "Basic metrics for bso1 on 2023-02-26\n",
            "Distribution metrics for bso1 on 2023-02-26\n",
            "Quantile metrics for bso1 on 2023-02-26\n",
            "Entropy calculation for bso1 on 2023-02-26\n",
            "Entropy calculated: 3.974\n",
            "Mutual information: bso1 vs aimp on 2023-02-26\n",
            "MI calculated: 0.000\n",
            "Processing column: bso2\n",
            "Basic metrics for bso2 on 2023-02-26\n",
            "Distribution metrics for bso2 on 2023-02-26\n",
            "Quantile metrics for bso2 on 2023-02-26\n",
            "Entropy calculation for bso2 on 2023-02-26\n",
            "Entropy calculated: 5.523\n",
            "Mutual information: bso2 vs aimp on 2023-02-26\n",
            "MI calculated: 0.000\n",
            "Processing column: bso3\n",
            "Basic metrics for bso3 on 2023-02-26\n",
            "Distribution metrics for bso3 on 2023-02-26\n",
            "Quantile metrics for bso3 on 2023-02-26\n",
            "Entropy calculation for bso3 on 2023-02-26\n",
            "Entropy calculated: 3.980\n",
            "Mutual information: bso3 vs aimp on 2023-02-26\n",
            "MI calculated: 0.000\n",
            "Processing column: ced1\n",
            "Basic metrics for ced1 on 2023-02-26\n",
            "Distribution metrics for ced1 on 2023-02-26\n",
            "Quantile metrics for ced1 on 2023-02-26\n",
            "Entropy calculation for ced1 on 2023-02-26\n",
            "Entropy calculated: 5.201\n",
            "Mutual information: ced1 vs aimp on 2023-02-26\n",
            "MI calculated: 0.000\n",
            "Processing column: cfo1\n",
            "Basic metrics for cfo1 on 2023-02-26\n",
            "Distribution metrics for cfo1 on 2023-02-26\n",
            "Quantile metrics for cfo1 on 2023-02-26\n",
            "Entropy calculation for cfo1 on 2023-02-26\n",
            "Entropy calculated: 5.062\n",
            "Mutual information: cfo1 vs aimp on 2023-02-26\n",
            "MI calculated: 0.000\n",
            "Processing column: cso1\n",
            "Basic metrics for cso1 on 2023-02-26\n",
            "Distribution metrics for cso1 on 2023-02-26\n",
            "Quantile metrics for cso1 on 2023-02-26\n",
            "Entropy calculation for cso1 on 2023-02-26\n",
            "Entropy calculated: 3.603\n",
            "Mutual information: cso1 vs aimp on 2023-02-26\n",
            "MI calculated: 0.000\n",
            "Processing column: y\n",
            "Basic metrics for y on 2023-02-26\n",
            "Distribution metrics for y on 2023-02-26\n",
            "Quantile metrics for y on 2023-02-26\n",
            "Entropy calculation for y on 2023-02-26\n",
            "Entropy calculated: 0.393\n",
            "Mutual information: y vs aimp on 2023-02-26\n",
            "MI calculated: 0.000\n",
            "Processing column: category\n",
            "Basic metrics for category on 2023-02-26\n",
            "Distribution metrics for category on 2023-02-26\n",
            "Quantile metrics for category on 2023-02-26\n",
            "Entropy calculation for category on 2023-02-26\n",
            "Entropy calculated: 0.450\n",
            "Mutual information: category vs aimp on 2023-02-26\n",
            "MI calculated: 0.000\n",
            "Completed 2023-02-26 - Generated 662 features\n",
            "Processing date 58/58: 2023-02-27\n",
            "Processing 75200 records\n",
            "Correlation matrix for 2023-02-27\n",
            "Correlation matrix calculated for 19 columns\n",
            "Processing column: aimp\n",
            "Basic metrics for aimp on 2023-02-27\n",
            "Distribution metrics for aimp on 2023-02-27\n",
            "Quantile metrics for aimp on 2023-02-27\n",
            "Entropy calculation for aimp on 2023-02-27\n",
            "Entropy calculated: 0.079\n",
            "Processing column: amud\n",
            "Basic metrics for amud on 2023-02-27\n",
            "Distribution metrics for amud on 2023-02-27\n",
            "Quantile metrics for amud on 2023-02-27\n",
            "Entropy calculation for amud on 2023-02-27\n",
            "Entropy calculated: 3.848\n",
            "Mutual information: amud vs aimp on 2023-02-27\n",
            "MI calculated: 0.000\n",
            "Processing column: arnd\n",
            "Basic metrics for arnd on 2023-02-27\n",
            "Distribution metrics for arnd on 2023-02-27\n",
            "Quantile metrics for arnd on 2023-02-27\n",
            "Entropy calculation for arnd on 2023-02-27\n",
            "Entropy calculated: 4.973\n",
            "Mutual information: arnd vs aimp on 2023-02-27\n",
            "MI calculated: 0.000\n",
            "Processing column: asin1\n",
            "Basic metrics for asin1 on 2023-02-27\n",
            "Distribution metrics for asin1 on 2023-02-27\n",
            "Quantile metrics for asin1 on 2023-02-27\n",
            "Entropy calculation for asin1 on 2023-02-27\n",
            "Entropy calculated: 4.907\n",
            "Mutual information: asin1 vs aimp on 2023-02-27\n",
            "MI calculated: 0.000\n",
            "Processing column: asin2\n",
            "Basic metrics for asin2 on 2023-02-27\n",
            "Distribution metrics for asin2 on 2023-02-27\n",
            "Quantile metrics for asin2 on 2023-02-27\n",
            "Entropy calculation for asin2 on 2023-02-27\n",
            "Entropy calculated: 5.423\n",
            "Mutual information: asin2 vs aimp on 2023-02-27\n",
            "MI calculated: 0.000\n",
            "Processing column: adbr\n",
            "Basic metrics for adbr on 2023-02-27\n",
            "Distribution metrics for adbr on 2023-02-27\n",
            "Quantile metrics for adbr on 2023-02-27\n",
            "Entropy calculation for adbr on 2023-02-27\n",
            "Entropy calculated: 1.000\n",
            "Mutual information: adbr vs aimp on 2023-02-27\n",
            "MI calculated: 0.000\n",
            "Processing column: adfl\n",
            "Basic metrics for adfl on 2023-02-27\n",
            "Distribution metrics for adfl on 2023-02-27\n",
            "Quantile metrics for adfl on 2023-02-27\n",
            "Entropy calculation for adfl on 2023-02-27\n",
            "Entropy calculated: 0.960\n",
            "Mutual information: adfl vs aimp on 2023-02-27\n",
            "MI calculated: 0.000\n",
            "Processing column: bed1\n",
            "Basic metrics for bed1 on 2023-02-27\n",
            "Distribution metrics for bed1 on 2023-02-27\n",
            "Quantile metrics for bed1 on 2023-02-27\n",
            "Entropy calculation for bed1 on 2023-02-27\n",
            "Entropy calculated: 4.572\n",
            "Mutual information: bed1 vs aimp on 2023-02-27\n",
            "MI calculated: 0.014\n",
            "Processing column: bed2\n",
            "Basic metrics for bed2 on 2023-02-27\n",
            "Distribution metrics for bed2 on 2023-02-27\n",
            "Quantile metrics for bed2 on 2023-02-27\n",
            "Entropy calculation for bed2 on 2023-02-27\n",
            "Entropy calculated: 2.876\n",
            "Mutual information: bed2 vs aimp on 2023-02-27\n",
            "MI calculated: 0.038\n",
            "Processing column: bfo1\n",
            "Basic metrics for bfo1 on 2023-02-27\n",
            "Distribution metrics for bfo1 on 2023-02-27\n",
            "Quantile metrics for bfo1 on 2023-02-27\n",
            "Entropy calculation for bfo1 on 2023-02-27\n",
            "Entropy calculated: 1.892\n",
            "Mutual information: bfo1 vs aimp on 2023-02-27\n",
            "MI calculated: 0.000\n",
            "Processing column: bfo2\n",
            "Basic metrics for bfo2 on 2023-02-27\n",
            "Distribution metrics for bfo2 on 2023-02-27\n",
            "Quantile metrics for bfo2 on 2023-02-27\n",
            "Entropy calculation for bfo2 on 2023-02-27\n",
            "Entropy calculated: 5.194\n",
            "Mutual information: bfo2 vs aimp on 2023-02-27\n",
            "MI calculated: 0.000\n",
            "Processing column: bso1\n",
            "Basic metrics for bso1 on 2023-02-27\n",
            "Distribution metrics for bso1 on 2023-02-27\n",
            "Quantile metrics for bso1 on 2023-02-27\n",
            "Entropy calculation for bso1 on 2023-02-27\n",
            "Entropy calculated: 4.454\n",
            "Mutual information: bso1 vs aimp on 2023-02-27\n",
            "MI calculated: 0.000\n",
            "Processing column: bso2\n",
            "Basic metrics for bso2 on 2023-02-27\n",
            "Distribution metrics for bso2 on 2023-02-27\n",
            "Quantile metrics for bso2 on 2023-02-27\n",
            "Entropy calculation for bso2 on 2023-02-27\n",
            "Entropy calculated: 5.511\n",
            "Mutual information: bso2 vs aimp on 2023-02-27\n",
            "MI calculated: 0.000\n",
            "Processing column: bso3\n",
            "Basic metrics for bso3 on 2023-02-27\n",
            "Distribution metrics for bso3 on 2023-02-27\n",
            "Quantile metrics for bso3 on 2023-02-27\n",
            "Entropy calculation for bso3 on 2023-02-27\n",
            "Entropy calculated: 5.308\n",
            "Mutual information: bso3 vs aimp on 2023-02-27\n",
            "MI calculated: 0.000\n",
            "Processing column: ced1\n",
            "Basic metrics for ced1 on 2023-02-27\n",
            "Distribution metrics for ced1 on 2023-02-27\n",
            "Quantile metrics for ced1 on 2023-02-27\n",
            "Entropy calculation for ced1 on 2023-02-27\n",
            "Entropy calculated: 4.921\n",
            "Mutual information: ced1 vs aimp on 2023-02-27\n",
            "MI calculated: 0.000\n",
            "Processing column: cfo1\n",
            "Basic metrics for cfo1 on 2023-02-27\n",
            "Distribution metrics for cfo1 on 2023-02-27\n",
            "Quantile metrics for cfo1 on 2023-02-27\n",
            "Entropy calculation for cfo1 on 2023-02-27\n",
            "Entropy calculated: 5.177\n",
            "Mutual information: cfo1 vs aimp on 2023-02-27\n",
            "MI calculated: 0.000\n",
            "Processing column: cso1\n",
            "Basic metrics for cso1 on 2023-02-27\n",
            "Distribution metrics for cso1 on 2023-02-27\n",
            "Quantile metrics for cso1 on 2023-02-27\n",
            "Entropy calculation for cso1 on 2023-02-27\n",
            "Entropy calculated: 5.120\n",
            "Mutual information: cso1 vs aimp on 2023-02-27\n",
            "MI calculated: 0.000\n",
            "Processing column: y\n",
            "Basic metrics for y on 2023-02-27\n",
            "Distribution metrics for y on 2023-02-27\n",
            "Quantile metrics for y on 2023-02-27\n",
            "Entropy calculation for y on 2023-02-27\n",
            "Entropy calculated: 0.156\n",
            "Mutual information: y vs aimp on 2023-02-27\n",
            "MI calculated: 0.000\n",
            "Processing column: category\n",
            "Basic metrics for category on 2023-02-27\n",
            "Distribution metrics for category on 2023-02-27\n",
            "Quantile metrics for category on 2023-02-27\n",
            "Entropy calculation for category on 2023-02-27\n",
            "Entropy calculated: 0.076\n",
            "Mutual information: category vs aimp on 2023-02-27\n",
            "MI calculated: 0.000\n",
            "Completed 2023-02-27 - Generated 662 features\n",
            "Profiling complete! Generated 58 days × 662 features\n",
            "\n",
            " STEP 2: Creating rolling features...\n",
            "\n",
            " Creating rolling features with windows: [7, 14, 30, 90]\n",
            "   Processing 7-day rolling window...\n",
            "   Processing 14-day rolling window...\n",
            "   Processing 30-day rolling window...\n",
            "   Processing 90-day rolling window...\n",
            " Rolling features created: 23090 total features\n",
            "\n",
            " STEP 2.5: Creating lag features...\n",
            " Creating lag features: [1, 2, 3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n",
            "/tmp/ipython-input-20-2833024105.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_lag_{lag}d\"] = feature_df[col].shift(lag)\n",
            "/tmp/ipython-input-20-2833024105.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  result_df[f\"{col}_diff_lag_{lag}d\"] = feature_df[col] - result_df[f\"{col}_lag_{lag}d\"]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Added 3738 lag features\n",
            "\n",
            " STEP 3: Handling null values...\n",
            "   Input shape: (58, 26828)\n",
            "    Dropping 4984 all-null columns: ['total_records_rolling_90d_mean', 'total_records_rolling_90d_std', 'total_records_rolling_90d_min', 'total_records_rolling_90d_max', 'total_records_zscore_90d']...\n",
            "   Filling nulls in 21805 numeric columns...\n",
            "   Filling nulls in 38 non-numeric columns...\n",
            "   Final shape: (58, 21844)\n",
            "   Remaining nulls: 0\n",
            "\n",
            " FEATURE PREPARATION COMPLETE!\n",
            " Final shape: 58 days × 21844 features\n",
            " Ready for dataset-level anomaly detection\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features['date'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehITRZvPcssG",
        "outputId": "0af56a6a-d818-42a8-8ead-e1166be2b206"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04',\n",
              "       '2023-01-05', '2023-01-06', '2023-01-07', '2023-01-08',\n",
              "       '2023-01-09', '2023-01-10', '2023-01-11', '2023-01-12',\n",
              "       '2023-01-13', '2023-01-14', '2023-01-15', '2023-01-16',\n",
              "       '2023-01-17', '2023-01-18', '2023-01-19', '2023-01-20',\n",
              "       '2023-01-21', '2023-01-22', '2023-01-23', '2023-01-24',\n",
              "       '2023-01-25', '2023-01-26', '2023-01-27', '2023-01-28',\n",
              "       '2023-01-29', '2023-01-30', '2023-01-31', '2023-02-01',\n",
              "       '2023-02-02', '2023-02-03', '2023-02-04', '2023-02-05',\n",
              "       '2023-02-06', '2023-02-07', '2023-02-08', '2023-02-09',\n",
              "       '2023-02-10', '2023-02-11', '2023-02-12', '2023-02-13',\n",
              "       '2023-02-14', '2023-02-15', '2023-02-16', '2023-02-17',\n",
              "       '2023-02-18', '2023-02-19', '2023-02-20', '2023-02-21',\n",
              "       '2023-02-22', '2023-02-23', '2023-02-24', '2023-02-25',\n",
              "       '2023-02-26', '2023-02-27'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data masssaging for Histogram columns**"
      ],
      "metadata": {
        "id": "A-2vE51b9_Y3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def extract_histogram_columns(df):\n",
        "    \"\"\"Extract histogram column names from DataFrame\"\"\"\n",
        "    histogram_cols = [col for col in df.columns if 'Histogram' in col]\n",
        "    print(f\"Found {len(histogram_cols)} histogram columns\")\n",
        "    return histogram_cols\n",
        "\n",
        "def transform_histogram_columns(df, histogram_columns):\n",
        "    \"\"\"\n",
        "    Transform histogram string columns into numeric features\n",
        "\n",
        "    Args:\n",
        "        df: DataFrame containing histogram columns\n",
        "        histogram_columns: List of histogram column names to transform\n",
        "\n",
        "    Returns:\n",
        "        DataFrame with new numeric features (original columns kept)\n",
        "    \"\"\"\n",
        "    print(f\"Transforming {len(histogram_columns)} histogram columns...\")\n",
        "\n",
        "    result_df = df.copy()\n",
        "\n",
        "    for col in histogram_columns:\n",
        "        base_name = col.replace('_Histogram', '')\n",
        "        print(f\"Processing {col} -> {base_name}_hist_*\")\n",
        "\n",
        "        try:\n",
        "            # Parse histogram strings to arrays\n",
        "            hist_arrays = df[col].apply(\n",
        "                lambda x: np.array([int(i) for i in str(x).split(',')]) if pd.notna(x) else np.array([0])\n",
        "            )\n",
        "\n",
        "            # Extract features\n",
        "            result_df[f\"{base_name}_hist_mean\"] = hist_arrays.apply(np.mean)\n",
        "            result_df[f\"{base_name}_hist_std\"] = hist_arrays.apply(np.std)\n",
        "            result_df[f\"{base_name}_hist_sum\"] = hist_arrays.apply(np.sum)\n",
        "            result_df[f\"{base_name}_hist_max\"] = hist_arrays.apply(np.max)\n",
        "            result_df[f\"{base_name}_hist_entropy\"] = hist_arrays.apply(\n",
        "                lambda x: -np.sum((p := x/x.sum()) * np.log2(p + 1e-12)) if x.sum() > 0 else 0\n",
        "            )\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error transforming {col}: {e}\")\n",
        "\n",
        "    print(f\"Created {len(histogram_columns) * 5} new features\")\n",
        "    return result_df"
      ],
      "metadata": {
        "id": "5gyG9bpl-HE-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**extract histogram feature**"
      ],
      "metadata": {
        "id": "nKV8aSeQ-M_D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Method 1: Auto-extract histogram columns\n",
        "histogram_cols = extract_histogram_columns(features)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkIzaz8u-Qo3",
        "outputId": "8efe30f9-0321-4943-8acf-0b6a9ec9dfc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 19 histogram columns\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features[histogram_cols].head(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        },
        "id": "TIpyugG9xVD6",
        "outputId": "ca349471-2820-4c57-e9ba-baebd5168e16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              aimp_Histogram  \\\n",
              "0  85539,0,0,0,0,0,0,0,0,861   \n",
              "1  85539,0,0,0,0,0,0,0,0,861   \n",
              "\n",
              "                                      amud_Histogram  \\\n",
              "0  1014,7189,21355,24818,13680,7293,3963,5125,125...   \n",
              "1  4913,2512,5244,15268,15067,8322,22404,7381,357...   \n",
              "\n",
              "                                      arnd_Histogram  \\\n",
              "0  36307,16980,12719,7956,3845,3206,1563,1698,132...   \n",
              "1  1100,4349,9538,9910,9225,11727,9599,9328,10077...   \n",
              "\n",
              "                                     asin1_Histogram  \\\n",
              "0  5009,5059,5167,5341,5604,5996,6594,7595,9624,3...   \n",
              "1  6694,6532,6490,6558,6750,7099,7684,8704,10775,...   \n",
              "\n",
              "                                     asin2_Histogram  \\\n",
              "0  16093,7095,5800,5255,5034,6038,6306,6960,8514,...   \n",
              "1  16082,7095,5800,5252,5047,6042,6303,6960,8514,...   \n",
              "\n",
              "                adbr_Histogram               adfl_Histogram  \\\n",
              "0  43253,0,0,0,0,0,0,0,0,43147  33940,0,0,0,0,0,0,0,0,52460   \n",
              "1  45701,0,0,0,0,0,0,0,0,40699  33610,0,0,0,0,0,0,0,0,52790   \n",
              "\n",
              "                                    bed1_Histogram  \\\n",
              "0  26217,23378,18192,10911,5013,1829,627,167,49,17   \n",
              "1  24543,23927,18509,10726,5363,2289,796,188,48,11   \n",
              "\n",
              "                              bed2_Histogram  \\\n",
              "0  65554,9395,6123,3669,996,438,163,33,19,10   \n",
              "1  64695,9036,6135,4373,1258,554,243,76,23,7   \n",
              "\n",
              "                                      bfo1_Histogram  \\\n",
              "0  35766,10761,17484,9289,6507,2809,1339,1237,717...   \n",
              "1  33038,7158,6296,6520,7205,6192,6801,4745,4256,...   \n",
              "\n",
              "                                      bfo2_Histogram  \\\n",
              "0   124,251,50,701,8137,16546,20232,21204,16804,2351   \n",
              "1  2260,4317,8313,15863,16554,13085,12052,9286,38...   \n",
              "\n",
              "                                      bso1_Histogram  \\\n",
              "0  1043,15999,23453,25023,8920,7626,1786,1834,41,675   \n",
              "1  5510,1908,4906,15590,14628,10878,17305,10654,3...   \n",
              "\n",
              "                                      bso2_Histogram  \\\n",
              "0  6286,8736,7356,7053,7663,13380,12912,10971,718...   \n",
              "1  6416,8806,7086,6931,7424,13243,13337,11082,735...   \n",
              "\n",
              "                                      bso3_Histogram  \\\n",
              "0  674,1370,5111,12523,15780,16136,17137,11979,48...   \n",
              "1  1930,6768,13521,15272,13037,11734,11289,7889,4...   \n",
              "\n",
              "                                      ced1_Histogram  \\\n",
              "0  644,6736,16715,24449,18879,10295,5723,1968,560...   \n",
              "1  1989,9963,14032,18919,17250,12626,7090,3045,10...   \n",
              "\n",
              "                                      cfo1_Histogram  \\\n",
              "0  113,837,1615,3577,8959,14288,18164,27794,9310,...   \n",
              "1  748,3126,5558,8520,8422,9707,10216,16443,19698...   \n",
              "\n",
              "                                      cso1_Histogram              y_Histogram  \\\n",
              "0  165,247,48,1779,9459,16328,22018,21218,13059,2079  0,0,0,0,0,86400,0,0,0,0   \n",
              "1  1860,4017,6571,11412,15642,15028,12837,10501,6...  0,0,0,0,0,86400,0,0,0,0   \n",
              "\n",
              "        category_Histogram  \n",
              "0  0,0,0,0,0,86400,0,0,0,0  \n",
              "1  0,0,0,0,0,86400,0,0,0,0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-995e944e-6db6-4744-8b1d-e95f176fb68f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>aimp_Histogram</th>\n",
              "      <th>amud_Histogram</th>\n",
              "      <th>arnd_Histogram</th>\n",
              "      <th>asin1_Histogram</th>\n",
              "      <th>asin2_Histogram</th>\n",
              "      <th>adbr_Histogram</th>\n",
              "      <th>adfl_Histogram</th>\n",
              "      <th>bed1_Histogram</th>\n",
              "      <th>bed2_Histogram</th>\n",
              "      <th>bfo1_Histogram</th>\n",
              "      <th>bfo2_Histogram</th>\n",
              "      <th>bso1_Histogram</th>\n",
              "      <th>bso2_Histogram</th>\n",
              "      <th>bso3_Histogram</th>\n",
              "      <th>ced1_Histogram</th>\n",
              "      <th>cfo1_Histogram</th>\n",
              "      <th>cso1_Histogram</th>\n",
              "      <th>y_Histogram</th>\n",
              "      <th>category_Histogram</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>85539,0,0,0,0,0,0,0,0,861</td>\n",
              "      <td>1014,7189,21355,24818,13680,7293,3963,5125,125...</td>\n",
              "      <td>36307,16980,12719,7956,3845,3206,1563,1698,132...</td>\n",
              "      <td>5009,5059,5167,5341,5604,5996,6594,7595,9624,3...</td>\n",
              "      <td>16093,7095,5800,5255,5034,6038,6306,6960,8514,...</td>\n",
              "      <td>43253,0,0,0,0,0,0,0,0,43147</td>\n",
              "      <td>33940,0,0,0,0,0,0,0,0,52460</td>\n",
              "      <td>26217,23378,18192,10911,5013,1829,627,167,49,17</td>\n",
              "      <td>65554,9395,6123,3669,996,438,163,33,19,10</td>\n",
              "      <td>35766,10761,17484,9289,6507,2809,1339,1237,717...</td>\n",
              "      <td>124,251,50,701,8137,16546,20232,21204,16804,2351</td>\n",
              "      <td>1043,15999,23453,25023,8920,7626,1786,1834,41,675</td>\n",
              "      <td>6286,8736,7356,7053,7663,13380,12912,10971,718...</td>\n",
              "      <td>674,1370,5111,12523,15780,16136,17137,11979,48...</td>\n",
              "      <td>644,6736,16715,24449,18879,10295,5723,1968,560...</td>\n",
              "      <td>113,837,1615,3577,8959,14288,18164,27794,9310,...</td>\n",
              "      <td>165,247,48,1779,9459,16328,22018,21218,13059,2079</td>\n",
              "      <td>0,0,0,0,0,86400,0,0,0,0</td>\n",
              "      <td>0,0,0,0,0,86400,0,0,0,0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>85539,0,0,0,0,0,0,0,0,861</td>\n",
              "      <td>4913,2512,5244,15268,15067,8322,22404,7381,357...</td>\n",
              "      <td>1100,4349,9538,9910,9225,11727,9599,9328,10077...</td>\n",
              "      <td>6694,6532,6490,6558,6750,7099,7684,8704,10775,...</td>\n",
              "      <td>16082,7095,5800,5252,5047,6042,6303,6960,8514,...</td>\n",
              "      <td>45701,0,0,0,0,0,0,0,0,40699</td>\n",
              "      <td>33610,0,0,0,0,0,0,0,0,52790</td>\n",
              "      <td>24543,23927,18509,10726,5363,2289,796,188,48,11</td>\n",
              "      <td>64695,9036,6135,4373,1258,554,243,76,23,7</td>\n",
              "      <td>33038,7158,6296,6520,7205,6192,6801,4745,4256,...</td>\n",
              "      <td>2260,4317,8313,15863,16554,13085,12052,9286,38...</td>\n",
              "      <td>5510,1908,4906,15590,14628,10878,17305,10654,3...</td>\n",
              "      <td>6416,8806,7086,6931,7424,13243,13337,11082,735...</td>\n",
              "      <td>1930,6768,13521,15272,13037,11734,11289,7889,4...</td>\n",
              "      <td>1989,9963,14032,18919,17250,12626,7090,3045,10...</td>\n",
              "      <td>748,3126,5558,8520,8422,9707,10216,16443,19698...</td>\n",
              "      <td>1860,4017,6571,11412,15642,15028,12837,10501,6...</td>\n",
              "      <td>0,0,0,0,0,86400,0,0,0,0</td>\n",
              "      <td>0,0,0,0,0,86400,0,0,0,0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-995e944e-6db6-4744-8b1d-e95f176fb68f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-995e944e-6db6-4744-8b1d-e95f176fb68f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-995e944e-6db6-4744-8b1d-e95f176fb68f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-7a63aefc-4074-49ed-b679-f06e02d8ca4c\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7a63aefc-4074-49ed-b679-f06e02d8ca4c')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-7a63aefc-4074-49ed-b679-f06e02d8ca4c button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"features[histogram_cols]\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"aimp_Histogram\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"85539,0,0,0,0,0,0,0,0,861\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"amud_Histogram\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"4913,2512,5244,15268,15067,8322,22404,7381,3574,1715\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"arnd_Histogram\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"1100,4349,9538,9910,9225,11727,9599,9328,10077,11547\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"asin1_Histogram\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"6694,6532,6490,6558,6750,7099,7684,8704,10775,19114\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"asin2_Histogram\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"16082,7095,5800,5252,5047,6042,6303,6960,8514,19305\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"adbr_Histogram\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"45701,0,0,0,0,0,0,0,0,40699\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"adfl_Histogram\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"33610,0,0,0,0,0,0,0,0,52790\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bed1_Histogram\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"24543,23927,18509,10726,5363,2289,796,188,48,11\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bed2_Histogram\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"64695,9036,6135,4373,1258,554,243,76,23,7\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bfo1_Histogram\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"33038,7158,6296,6520,7205,6192,6801,4745,4256,4189\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bfo2_Histogram\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"2260,4317,8313,15863,16554,13085,12052,9286,3801,869\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bso1_Histogram\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"5510,1908,4906,15590,14628,10878,17305,10654,3399,1622\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bso2_Histogram\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"6416,8806,7086,6931,7424,13243,13337,11082,7351,4724\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bso3_Histogram\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"1930,6768,13521,15272,13037,11734,11289,7889,4136,824\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ced1_Histogram\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"1989,9963,14032,18919,17250,12626,7090,3045,1072,414\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cfo1_Histogram\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"748,3126,5558,8520,8422,9707,10216,16443,19698,3962\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cso1_Histogram\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"1860,4017,6571,11412,15642,15028,12837,10501,6914,1618\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"y_Histogram\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"0,0,0,0,0,86400,0,0,0,0\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"category_Histogram\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"0,0,0,0,0,86400,0,0,0,0\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transformed_df = transform_histogram_columns(features, histogram_cols)\n",
        "print(f\"Before transfomration number of col {len(features.columns)} \\n  transfomration number of col {len(transformed_df.columns)}+ \\\n",
        "\\n number of new columns {len(transformed_df.columns)-len(features.columns) }\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PU_XXLdWC9vd",
        "outputId": "e67e98e6-cbf8-46d1-ef24-4357446db963"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transforming 19 histogram columns...\n",
            "Processing aimp_Histogram -> aimp_hist_*\n",
            "Processing amud_Histogram -> amud_hist_*\n",
            "Processing arnd_Histogram -> arnd_hist_*\n",
            "Processing asin1_Histogram -> asin1_hist_*\n",
            "Processing asin2_Histogram -> asin2_hist_*\n",
            "Processing adbr_Histogram -> adbr_hist_*\n",
            "Processing adfl_Histogram -> adfl_hist_*\n",
            "Processing bed1_Histogram -> bed1_hist_*\n",
            "Processing bed2_Histogram -> bed2_hist_*\n",
            "Processing bfo1_Histogram -> bfo1_hist_*\n",
            "Processing bfo2_Histogram -> bfo2_hist_*\n",
            "Processing bso1_Histogram -> bso1_hist_*\n",
            "Processing bso2_Histogram -> bso2_hist_*\n",
            "Processing bso3_Histogram -> bso3_hist_*\n",
            "Processing ced1_Histogram -> ced1_hist_*\n",
            "Processing cfo1_Histogram -> cfo1_hist_*\n",
            "Processing cso1_Histogram -> cso1_hist_*\n",
            "Processing y_Histogram -> y_hist_*\n",
            "Processing category_Histogram -> category_hist_*\n",
            "Created 95 new features\n",
            "Before transfomration number of col 21844 \n",
            "  transfomration number of col 21939+ \n",
            " number of new columns 95\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transformed_df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ujmhIZqxxSb",
        "outputId": "b8ee3403-2aac-4c91-c5a2-e365b273cb46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['date', 'total_records', 'dataset_completeness', 'aimp_Mean',\n",
              "       'aimp_Minimum', 'aimp_Maximum', 'aimp_StandardDeviation', 'aimp_Sum',\n",
              "       'aimp_count', 'aimp_Completeness',\n",
              "       ...\n",
              "       'y_hist_mean', 'y_hist_std', 'y_hist_sum', 'y_hist_max',\n",
              "       'y_hist_entropy', 'category_hist_mean', 'category_hist_std',\n",
              "       'category_hist_sum', 'category_hist_max', 'category_hist_entropy'],\n",
              "      dtype='object', length=21939)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Push the changes back to github**"
      ],
      "metadata": {
        "id": "WqRxnwEOjLDJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys, os\n",
        "\n",
        "project_root = os.getcwd()\n",
        "print(project_root)\n",
        "if project_root not in sys.path:\n",
        "    sys.path.insert(0, project_root)\n",
        "\n",
        "print(f\"✅ Added to sys.path: {project_root}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tull7Sa4KX5C",
        "outputId": "7b8bca94-fb78-4a4d-f00b-d439fa693ca0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "✅ Added to sys.path: /content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/Innovation-Hub/smart_dq_anamoly')\n",
        "import importlib\n"
      ],
      "metadata": {
        "id": "Y-Q67dOhL70V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fix the datatype**"
      ],
      "metadata": {
        "id": "m1B8-2u-0urO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def fix_dataframe_dtypes_enhanced(df):\n",
        "    \"\"\"\n",
        "    Enhanced DataFrame type fixing that handles comma-separated values.\n",
        "    \"\"\"\n",
        "    print(\"Fixing DataFrame data types (enhanced)...\")\n",
        "\n",
        "    fixed_df = df.copy()\n",
        "    conversions = {'numeric': 0, 'comma_separated_fixed': 0, 'kept_string': 0, 'kept_numeric': 0, 'dropped': 0}\n",
        "    dropped_columns = []\n",
        "\n",
        "    for col in df.columns:\n",
        "        if col == 'date':\n",
        "            continue\n",
        "\n",
        "        if pd.api.types.is_numeric_dtype(df[col]):\n",
        "            conversions['kept_numeric'] += 1\n",
        "            continue\n",
        "\n",
        "        if df[col].dtype == 'object':\n",
        "            # Sample first few non-null values to detect pattern\n",
        "            sample_values = df[col].dropna().head(10)\n",
        "\n",
        "            if len(sample_values) == 0:\n",
        "                # Empty column - drop it\n",
        "                fixed_df.drop(columns=[col], inplace=True)\n",
        "                dropped_columns.append(col)\n",
        "                conversions['dropped'] += 1\n",
        "                continue\n",
        "\n",
        "            # Check if values contain commas (comma-separated)\n",
        "            has_commas = any(',' in str(val) for val in sample_values)\n",
        "\n",
        "            if has_commas:\n",
        "                # Extract first value from comma-separated strings\n",
        "                def extract_first_numeric(x):\n",
        "                    if pd.isna(x):\n",
        "                        return np.nan\n",
        "                    try:\n",
        "                        first_val = str(x).split(',')[0]\n",
        "                        return float(first_val)\n",
        "                    except (ValueError, IndexError):\n",
        "                        return np.nan\n",
        "\n",
        "                fixed_df[col] = df[col].apply(extract_first_numeric)\n",
        "                conversions['comma_separated_fixed'] += 1\n",
        "                print(f\"  {col}: comma-separated → numeric (using first value)\")\n",
        "\n",
        "            else:\n",
        "                # Try regular numeric conversion\n",
        "                try:\n",
        "                    fixed_df[col] = pd.to_numeric(df[col], errors='raise')\n",
        "                    conversions['numeric'] += 1\n",
        "                    print(f\"  {col}: object → numeric\")\n",
        "                except (ValueError, TypeError):\n",
        "                    # Check if it's actually needed for analysis\n",
        "                    unique_count = df[col].nunique()\n",
        "                    if unique_count < 10 and col not in ['date']:  # Likely categorical\n",
        "                        fixed_df.drop(columns=[col], inplace=True)\n",
        "                        dropped_columns.append(col)\n",
        "                        conversions['dropped'] += 1\n",
        "                        print(f\"  {col}: dropped (categorical/low variance)\")\n",
        "                    else:\n",
        "                        conversions['kept_string'] += 1\n",
        "                        print(f\"  {col}: keeping as string\")\n",
        "        else:\n",
        "            conversions['kept_numeric'] += 1\n",
        "\n",
        "    print(f\"Enhanced conversion summary:\")\n",
        "    print(f\"  Converted to numeric: {conversions['numeric']}\")\n",
        "    print(f\"  Fixed comma-separated: {conversions['comma_separated_fixed']}\")\n",
        "    print(f\"  Already numeric: {conversions['kept_numeric']}\")\n",
        "    print(f\"  Kept as string: {conversions['kept_string']}\")\n",
        "    print(f\"  Dropped columns: {conversions['dropped']}\")\n",
        "\n",
        "    if dropped_columns:\n",
        "        print(f\"  Dropped: {dropped_columns[:5]}{'...' if len(dropped_columns) > 5 else ''}\")\n",
        "\n",
        "    return fixed_df\n",
        "\n",
        "# Usage\n",
        "def create_clean_transformed_df(original_df):\n",
        "    \"\"\"Create properly cleaned transformed DataFrame.\"\"\"\n",
        "    # Your existing transformation\n",
        "    transformed_df = prepare_features_for_model(original_df, enhanced=True)\n",
        "\n",
        "    # Enhanced cleaning\n",
        "    cleaned_df = fix_dataframe_dtypes_enhanced(transformed_df)\n",
        "\n",
        "    return cleaned_df"
      ],
      "metadata": {
        "id": "V5vDw8Pis9Ia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformed_datatype_df = fix_dataframe_dtypes_enhanced(transformed_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FTJdq93l1TOo",
        "outputId": "eed94a63-4ce2-4a00-a915-943c4d040602"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fixing DataFrame data types (enhanced)...\n",
            "  aimp_Histogram: comma-separated → numeric (using first value)\n",
            "  aimp_DataType: dropped (categorical/low variance)\n",
            "  amud_Histogram: comma-separated → numeric (using first value)\n",
            "  amud_DataType: dropped (categorical/low variance)\n",
            "  arnd_Histogram: comma-separated → numeric (using first value)\n",
            "  arnd_DataType: dropped (categorical/low variance)\n",
            "  asin1_Histogram: comma-separated → numeric (using first value)\n",
            "  asin1_DataType: dropped (categorical/low variance)\n",
            "  asin2_Histogram: comma-separated → numeric (using first value)\n",
            "  asin2_DataType: dropped (categorical/low variance)\n",
            "  adbr_Histogram: comma-separated → numeric (using first value)\n",
            "  adbr_DataType: dropped (categorical/low variance)\n",
            "  adfl_Histogram: comma-separated → numeric (using first value)\n",
            "  adfl_DataType: dropped (categorical/low variance)\n",
            "  bed1_Histogram: comma-separated → numeric (using first value)\n",
            "  bed1_DataType: dropped (categorical/low variance)\n",
            "  bed2_Histogram: comma-separated → numeric (using first value)\n",
            "  bed2_DataType: dropped (categorical/low variance)\n",
            "  bfo1_Histogram: comma-separated → numeric (using first value)\n",
            "  bfo1_DataType: dropped (categorical/low variance)\n",
            "  bfo2_Histogram: comma-separated → numeric (using first value)\n",
            "  bfo2_DataType: dropped (categorical/low variance)\n",
            "  bso1_Histogram: comma-separated → numeric (using first value)\n",
            "  bso1_DataType: dropped (categorical/low variance)\n",
            "  bso2_Histogram: comma-separated → numeric (using first value)\n",
            "  bso2_DataType: dropped (categorical/low variance)\n",
            "  bso3_Histogram: comma-separated → numeric (using first value)\n",
            "  bso3_DataType: dropped (categorical/low variance)\n",
            "  ced1_Histogram: comma-separated → numeric (using first value)\n",
            "  ced1_DataType: dropped (categorical/low variance)\n",
            "  cfo1_Histogram: comma-separated → numeric (using first value)\n",
            "  cfo1_DataType: dropped (categorical/low variance)\n",
            "  cso1_Histogram: comma-separated → numeric (using first value)\n",
            "  cso1_DataType: dropped (categorical/low variance)\n",
            "  y_Histogram: comma-separated → numeric (using first value)\n",
            "  y_DataType: dropped (categorical/low variance)\n",
            "  category_Histogram: comma-separated → numeric (using first value)\n",
            "  category_DataType: dropped (categorical/low variance)\n",
            "Enhanced conversion summary:\n",
            "  Converted to numeric: 0\n",
            "  Fixed comma-separated: 19\n",
            "  Already numeric: 21900\n",
            "  Kept as string: 0\n",
            "  Dropped columns: 19\n",
            "  Dropped: ['aimp_DataType', 'amud_DataType', 'arnd_DataType', 'asin1_DataType', 'asin2_DataType']...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(transformed_datatype_df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDlMnV1ZCMww",
        "outputId": "a4362419-df14-433c-84e1-1880f082c13e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21920"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Feature Selection**"
      ],
      "metadata": {
        "id": "W_2a9VQiCVB6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from typing import Dict, List, Optional, Tuple\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "class FeatureSelector:\n",
        "    \"\"\"\n",
        "    Production-ready feature selector using PCA and optional Autoencoder.\n",
        "\n",
        "    Selection Process:\n",
        "    1. Variance filtering (removes low-variance features)\n",
        "    2. Correlation filtering (removes highly correlated features)\n",
        "    3. PCA analysis (finds optimal dimensionality)\n",
        "    4. Autoencoder ranking (optional - ranks by reconstruction importance)\n",
        "    5. Final selection (top N features by importance)\n",
        "\n",
        "    Key Parameters:\n",
        "    - target_features: Number of final features to select\n",
        "    - use_autoencoder: Whether to use autoencoder for feature ranking\n",
        "    - variance_threshold: Minimum variance threshold for filtering\n",
        "    - correlation_threshold: Maximum correlation threshold for filtering\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        target_features: Optional[int] = None,\n",
        "        use_autoencoder: bool = True,\n",
        "        variance_threshold: float = 0.01,\n",
        "        correlation_threshold: float = 0.95,\n",
        "        pca_variance_ratio: float = 0.95,\n",
        "        random_state: int = 42\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Initialize feature selector with configurable parameters.\n",
        "\n",
        "        Args:\n",
        "            target_features: Final number of features (None = auto-determine)\n",
        "            use_autoencoder: Use autoencoder for feature ranking\n",
        "            variance_threshold: Minimum variance for feature retention\n",
        "            correlation_threshold: Maximum correlation for feature retention\n",
        "            pca_variance_ratio: PCA variance ratio for optimal components\n",
        "            random_state: Random seed for reproducibility\n",
        "        \"\"\"\n",
        "        self.target_features = target_features\n",
        "        self.use_autoencoder = use_autoencoder\n",
        "        self.variance_threshold = variance_threshold\n",
        "        self.correlation_threshold = correlation_threshold\n",
        "        self.pca_variance_ratio = pca_variance_ratio\n",
        "        self.random_state = random_state\n",
        "\n",
        "        # Internal state\n",
        "        self.selected_features_ = []\n",
        "        self.feature_scores_ = {}\n",
        "        self.selection_stats_ = {}\n",
        "        self.scaler_ = StandardScaler()\n",
        "        self.pca_ = None\n",
        "\n",
        "        print(\"Production Feature Selector initialized\")\n",
        "        print(f\"  Target features: {target_features or 'auto-determine'}\")\n",
        "        print(f\"  Use autoencoder: {use_autoencoder}\")\n",
        "        print(f\"  Variance threshold: {variance_threshold}\")\n",
        "        print(f\"  Correlation threshold: {correlation_threshold}\")\n",
        "\n",
        "    def fit_transform(\n",
        "        self,\n",
        "        df: pd.DataFrame,\n",
        "        target_columns: Optional[List[str]] = None,\n",
        "        exclude_columns: Optional[List[str]] = None\n",
        "    ) -> List[str]:\n",
        "        \"\"\"\n",
        "        Main method to select optimal features from dataframe.\n",
        "\n",
        "        Args:\n",
        "            df: Input dataframe with all features\n",
        "            target_columns: Base columns to focus on (None = use all numeric)\n",
        "            exclude_columns: Columns to exclude from selection\n",
        "\n",
        "        Returns:\n",
        "            List of selected feature names for downstream models\n",
        "        \"\"\"\n",
        "        print(f\"\\nStarting feature selection on dataframe: {df.shape}\")\n",
        "\n",
        "        # Step 1: Get candidate features\n",
        "        candidate_features = self._extract_candidate_features(\n",
        "            df, target_columns, exclude_columns or ['date']\n",
        "        )\n",
        "        print(f\"Candidate features extracted: {len(candidate_features)}\")\n",
        "\n",
        "        # Step 2: Variance filtering\n",
        "        variance_filtered = self._apply_variance_filtering(df, candidate_features)\n",
        "        print(f\"After variance filtering: {len(variance_filtered)}\")\n",
        "\n",
        "        # Step 3: Correlation filtering\n",
        "        correlation_filtered = self._apply_correlation_filtering(df, variance_filtered)\n",
        "        print(f\"After correlation filtering: {len(correlation_filtered)}\")\n",
        "\n",
        "        # Step 4: PCA analysis for optimal feature count\n",
        "        optimal_count = self._determine_optimal_feature_count(df, correlation_filtered)\n",
        "        print(f\"Optimal feature count determined: {optimal_count}\")\n",
        "\n",
        "        # Step 5: Feature importance ranking\n",
        "        if self.use_autoencoder:\n",
        "            feature_scores = self._rank_features_autoencoder(df, correlation_filtered)\n",
        "            print(\"Feature ranking completed using autoencoder\")\n",
        "        else:\n",
        "            feature_scores = self._rank_features_statistical(df, correlation_filtered)\n",
        "            print(\"Feature ranking completed using statistical methods\")\n",
        "\n",
        "        # Step 6: Final feature selection\n",
        "        final_features = self._select_top_features(\n",
        "            correlation_filtered, feature_scores, optimal_count\n",
        "        )\n",
        "\n",
        "        # Store results\n",
        "        self.selected_features_ = final_features\n",
        "        self.feature_scores_ = feature_scores\n",
        "        self._store_selection_statistics(candidate_features, final_features)\n",
        "\n",
        "        print(f\"Feature selection complete: {len(final_features)} features selected\")\n",
        "        print(f\"Reduction ratio: {len(final_features)/len(candidate_features):.3f}\")\n",
        "\n",
        "        return final_features\n",
        "\n",
        "    def _extract_candidate_features(\n",
        "        self,\n",
        "        df: pd.DataFrame,\n",
        "        target_columns: Optional[List[str]],\n",
        "        exclude_columns: List[str]\n",
        "    ) -> List[str]:\n",
        "        \"\"\"Extract candidate features based on target columns or all numeric.\"\"\"\n",
        "\n",
        "        # Get all numeric columns\n",
        "        numeric_columns = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "\n",
        "        # Remove excluded columns\n",
        "        for col in exclude_columns:\n",
        "            if col in numeric_columns:\n",
        "                numeric_columns.remove(col)\n",
        "\n",
        "        # Filter by target columns if specified\n",
        "        if target_columns:\n",
        "            candidate_features = []\n",
        "            for target_col in target_columns:\n",
        "                # Get features starting with target column name\n",
        "                related_features = [\n",
        "                    col for col in numeric_columns\n",
        "                    if col.startswith(f\"{target_col}_\")\n",
        "                ]\n",
        "                candidate_features.extend(related_features)\n",
        "\n",
        "            candidate_features = list(set(candidate_features))\n",
        "            print(f\"Target-based selection for: {target_columns}\")\n",
        "        else:\n",
        "            candidate_features = numeric_columns\n",
        "            print(\"Using all numeric features\")\n",
        "\n",
        "        return candidate_features\n",
        "\n",
        "    def _apply_variance_filtering(\n",
        "        self,\n",
        "        df: pd.DataFrame,\n",
        "        features: List[str]\n",
        "    ) -> List[str]:\n",
        "        \"\"\"Remove features with low variance.\"\"\"\n",
        "\n",
        "        try:\n",
        "            # Prepare data\n",
        "            feature_data = df[features].fillna(0)\n",
        "\n",
        "            # Apply variance threshold\n",
        "            variance_selector = VarianceThreshold(threshold=self.variance_threshold)\n",
        "            variance_selector.fit(feature_data)\n",
        "\n",
        "            # Get selected features\n",
        "            selected_mask = variance_selector.get_support()\n",
        "            filtered_features = [features[i] for i, keep in enumerate(selected_mask) if keep]\n",
        "\n",
        "            removed_count = len(features) - len(filtered_features)\n",
        "            print(f\"  Removed {removed_count} low-variance features\")\n",
        "\n",
        "            return filtered_features\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  Variance filtering failed: {e}, keeping all features\")\n",
        "            return features\n",
        "\n",
        "    def _apply_correlation_filtering(\n",
        "        self,\n",
        "        df: pd.DataFrame,\n",
        "        features: List[str]\n",
        "    ) -> List[str]:\n",
        "        \"\"\"Remove highly correlated features.\"\"\"\n",
        "\n",
        "        try:\n",
        "            # Prepare data\n",
        "            feature_data = df[features].fillna(0)\n",
        "\n",
        "            # Calculate correlation matrix\n",
        "            correlation_matrix = feature_data.corr().abs()\n",
        "\n",
        "            # Find features to drop (upper triangle)\n",
        "            upper_triangle = correlation_matrix.where(\n",
        "                np.triu(np.ones(correlation_matrix.shape), k=1).astype(bool)\n",
        "            )\n",
        "\n",
        "            # Identify highly correlated features\n",
        "            to_drop = [\n",
        "                column for column in upper_triangle.columns\n",
        "                if any(upper_triangle[column] > self.correlation_threshold)\n",
        "            ]\n",
        "\n",
        "            # Keep features not in drop list\n",
        "            filtered_features = [f for f in features if f not in to_drop]\n",
        "\n",
        "            removed_count = len(features) - len(filtered_features)\n",
        "            print(f\"  Removed {removed_count} highly correlated features\")\n",
        "\n",
        "            return filtered_features\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  Correlation filtering failed: {e}, keeping all features\")\n",
        "            return features\n",
        "\n",
        "    def _determine_optimal_feature_count(\n",
        "        self,\n",
        "        df: pd.DataFrame,\n",
        "        features: List[str]\n",
        "    ) -> int:\n",
        "        \"\"\"Determine optimal number of features using PCA analysis.\"\"\"\n",
        "\n",
        "        # If target_features specified, use it\n",
        "        if self.target_features is not None:\n",
        "            return min(self.target_features, len(features))\n",
        "\n",
        "        try:\n",
        "            # Prepare data for PCA\n",
        "            feature_data = df[features].fillna(0)\n",
        "            scaled_data = self.scaler_.fit_transform(feature_data)\n",
        "\n",
        "            # Fit PCA\n",
        "            self.pca_ = PCA(random_state=self.random_state)\n",
        "            self.pca_.fit(scaled_data)\n",
        "\n",
        "            # Find number of components for target variance\n",
        "            cumulative_variance = np.cumsum(self.pca_.explained_variance_ratio_)\n",
        "            optimal_components = np.argmax(cumulative_variance >= self.pca_variance_ratio) + 1\n",
        "\n",
        "            # Cap at reasonable limits\n",
        "            min_features = max(10, len(features) // 20)  # At least 10, max 5% of total\n",
        "            max_features = min(len(features) // 2, 500)   # At most 50% or 500\n",
        "\n",
        "            optimal_count = np.clip(optimal_components, min_features, max_features)\n",
        "\n",
        "            print(f\"  PCA analysis: {cumulative_variance[optimal_components-1]:.3f} variance with {optimal_count} components\")\n",
        "\n",
        "            return optimal_count\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  PCA analysis failed: {e}, using heuristic\")\n",
        "            # Fallback heuristic: 10% of features, capped between 50-200\n",
        "            return np.clip(len(features) // 10, 50, 200)\n",
        "\n",
        "    def _rank_features_autoencoder(\n",
        "        self,\n",
        "        df: pd.DataFrame,\n",
        "        features: List[str]\n",
        "    ) -> Dict[str, float]:\n",
        "        \"\"\"Rank features using autoencoder reconstruction error.\"\"\"\n",
        "\n",
        "        try:\n",
        "            # Prepare data\n",
        "            feature_data = df[features].fillna(0)\n",
        "            scaled_data = self.scaler_.fit_transform(feature_data)\n",
        "\n",
        "            # Autoencoder architecture\n",
        "            n_features = scaled_data.shape[1]\n",
        "            encoding_dim = max(min(n_features // 4, 100), 5)\n",
        "\n",
        "            print(f\"  Training autoencoder: {n_features} -> {encoding_dim} -> {n_features}\")\n",
        "\n",
        "            # Train autoencoder using MLPRegressor\n",
        "            autoencoder = MLPRegressor(\n",
        "                hidden_layer_sizes=(encoding_dim,),\n",
        "                max_iter=300,\n",
        "                early_stopping=True,\n",
        "                validation_fraction=0.1,\n",
        "                random_state=self.random_state,\n",
        "                learning_rate_init=0.001\n",
        "            )\n",
        "\n",
        "            autoencoder.fit(scaled_data, scaled_data)\n",
        "\n",
        "            # Calculate reconstruction errors\n",
        "            reconstructed = autoencoder.predict(scaled_data)\n",
        "            reconstruction_errors = np.mean((scaled_data - reconstructed) ** 2, axis=0)\n",
        "\n",
        "            # Create feature importance scores (higher error = more important)\n",
        "            feature_scores = {\n",
        "                features[i]: float(reconstruction_errors[i])\n",
        "                for i in range(len(features))\n",
        "            }\n",
        "\n",
        "            print(f\"  Autoencoder training completed successfully\")\n",
        "            return feature_scores\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  Autoencoder training failed: {e}, using fallback\")\n",
        "            return self._rank_features_statistical(df, features)\n",
        "\n",
        "    def _rank_features_statistical(\n",
        "        self,\n",
        "        df: pd.DataFrame,\n",
        "        features: List[str]\n",
        "    ) -> Dict[str, float]:\n",
        "        \"\"\"Rank features using statistical methods (Random Forest).\"\"\"\n",
        "\n",
        "        try:\n",
        "            # Prepare data\n",
        "            feature_data = df[features].fillna(0)\n",
        "\n",
        "            # Create synthetic target using first principal component\n",
        "            scaled_data = self.scaler_.fit_transform(feature_data)\n",
        "            pca_temp = PCA(n_components=1, random_state=self.random_state)\n",
        "            synthetic_target = pca_temp.fit_transform(scaled_data).flatten()\n",
        "\n",
        "            # Train Random Forest for feature importance\n",
        "            rf = RandomForestRegressor(\n",
        "                n_estimators=100,\n",
        "                random_state=self.random_state,\n",
        "                n_jobs=-1\n",
        "            )\n",
        "            rf.fit(feature_data, synthetic_target)\n",
        "\n",
        "            # Create feature importance scores\n",
        "            feature_scores = {\n",
        "                features[i]: float(rf.feature_importances_[i])\n",
        "                for i in range(len(features))\n",
        "            }\n",
        "\n",
        "            print(f\"  Statistical ranking completed using Random Forest\")\n",
        "            return feature_scores\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  Statistical ranking failed: {e}, using uniform scores\")\n",
        "            return {feature: 1.0 for feature in features}\n",
        "\n",
        "    def _select_top_features(\n",
        "        self,\n",
        "        features: List[str],\n",
        "        feature_scores: Dict[str, float],\n",
        "        target_count: int\n",
        "    ) -> List[str]:\n",
        "        \"\"\"Select top N features based on importance scores.\"\"\"\n",
        "\n",
        "        # Sort features by score (descending)\n",
        "        sorted_features = sorted(\n",
        "            features,\n",
        "            key=lambda x: feature_scores.get(x, 0),\n",
        "            reverse=True\n",
        "        )\n",
        "\n",
        "        # Select top N features\n",
        "        selected_features = sorted_features[:target_count]\n",
        "\n",
        "        print(f\"  Selected top {len(selected_features)} features\")\n",
        "\n",
        "        return selected_features\n",
        "\n",
        "    def _store_selection_statistics(\n",
        "        self,\n",
        "        original_features: List[str],\n",
        "        selected_features: List[str]\n",
        "    ) -> None:\n",
        "        \"\"\"Store statistics about the selection process.\"\"\"\n",
        "\n",
        "        self.selection_stats_ = {\n",
        "            'original_count': len(original_features),\n",
        "            'selected_count': len(selected_features),\n",
        "            'reduction_ratio': len(selected_features) / len(original_features),\n",
        "            'use_autoencoder': self.use_autoencoder,\n",
        "            'variance_threshold': self.variance_threshold,\n",
        "            'correlation_threshold': self.correlation_threshold\n",
        "        }\n",
        "\n",
        "    def get_selected_features(self) -> List[str]:\n",
        "        \"\"\"Get list of selected features.\"\"\"\n",
        "        return self.selected_features_\n",
        "\n",
        "    def get_feature_scores(self) -> Dict[str, float]:\n",
        "        \"\"\"Get feature importance scores.\"\"\"\n",
        "        return self.feature_scores_\n",
        "\n",
        "    def get_selection_stats(self) -> Dict:\n",
        "        \"\"\"Get selection statistics.\"\"\"\n",
        "        return self.selection_stats_\n",
        "\n",
        "    def create_feature_report(self) -> pd.DataFrame:\n",
        "        \"\"\"Create detailed feature selection report.\"\"\"\n",
        "\n",
        "        if not self.selected_features_:\n",
        "            print(\"No features selected yet. Run fit_transform first.\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "        # Create report data\n",
        "        report_data = []\n",
        "        for i, feature in enumerate(self.selected_features_):\n",
        "            base_column = feature.split('_')[0] if '_' in feature else feature\n",
        "            metric_type = feature.split('_')[-1] if '_' in feature else 'base'\n",
        "\n",
        "            report_data.append({\n",
        "                'rank': i + 1,\n",
        "                'feature_name': feature,\n",
        "                'base_column': base_column,\n",
        "                'metric_type': metric_type,\n",
        "                'importance_score': self.feature_scores_.get(feature, 0)\n",
        "            })\n",
        "\n",
        "        report_df = pd.DataFrame(report_data)\n",
        "        return report_df\n"
      ],
      "metadata": {
        "id": "3sgjDrm1oWfk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Feaure calling**\n",
        "**Modes**"
      ],
      "metadata": {
        "id": "HmoxPQ9wohPj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FeatureSelector Usage Examples\n",
        "\n",
        "## Mode 1: Intelligent Auto-Selection with Deep Learning\n",
        "\n",
        "```python\n",
        "# Automatically determines optimal feature count using autoencoder compression\n",
        "print(\"Mode 1: Intelligent auto-selection with autoencoder\")\n",
        "\n",
        "selector = FeatureSelector(\n",
        "    target_features=None,        # Let autoencoder determine optimal count\n",
        "    use_autoencoder=True         # Enable deep learning feature optimization\n",
        ")\n",
        "\n",
        "selected_features = selector.fit_transform(\n",
        "    df=your_dataframe,\n",
        "    target_columns=['aimp', 'amud', 'arnd']  # Focus on specific business metrics\n",
        ")\n",
        "\n",
        "print(f\"Auto-selected {len(selected_features)} optimal features\")\n",
        "```\n",
        "\n",
        "**Best for:** Production systems where you want AI to optimize feature selection automatically.\n",
        "\n",
        "---\n",
        "\n",
        "## Mode 2: Fixed Count with Statistical Selection\n",
        "\n",
        "```python\n",
        "# Selects exactly N features using statistical importance ranking\n",
        "print(\"Mode 2: Fixed feature count with statistical methods\")\n",
        "\n",
        "selector = FeatureSelector(\n",
        "    target_features=100,         # Exactly 100 most important features\n",
        "    use_autoencoder=False        # Use statistical ranking only\n",
        ")\n",
        "\n",
        "selected_features = selector.fit_transform(\n",
        "    df=your_dataframe,\n",
        "    target_columns=['aimp', 'amud', 'arnd']\n",
        ")\n",
        "\n",
        "print(f\"Selected top {len(selected_features)} features by statistical importance\")\n",
        "```\n",
        "\n",
        "**Best for:** When you need predictable feature count for memory/performance constraints.\n",
        "\n",
        "---\n",
        "\n",
        "## Mode 3: Maximum Features with Deep Learning Enhancement\n",
        "\n",
        "```python\n",
        "# Uses all available features enhanced by autoencoder insights\n",
        "print(\"Mode 3: All features with autoencoder enhancement\")\n",
        "\n",
        "selector = FeatureSelector(\n",
        "    target_features=200,         # Use up to 200 features (or all available)\n",
        "    use_autoencoder=True         # Enhance with deep learning insights\n",
        ")\n",
        "\n",
        "selected_features = selector.fit_transform(\n",
        "    df=your_dataframe,\n",
        "    target_columns=None          # Analyze all numeric columns\n",
        ")\n",
        "\n",
        "print(f\"Enhanced selection: {len(selected_features)} features\")\n",
        "```\n",
        "\n",
        "**Best for:** High-accuracy models where you want maximum feature coverage with AI optimization.\n",
        "\n",
        "---\n",
        "\n",
        "## Results Analysis & Implementation\n",
        "\n",
        "```python\n",
        "# Create filtered dataset for anomaly detection\n",
        "filtered_df = your_dataframe[['date'] + selected_features]\n",
        "print(f\"Final dataset shape: {filtered_df.shape}\")\n",
        "\n",
        "# Get detailed feature importance analysis\n",
        "feature_report = selector.create_feature_report()\n",
        "print(\"\\nTop 10 most important features:\")\n",
        "print(feature_report[['feature_name', 'importance_score', 'selection_reason']].head(10))\n",
        "\n",
        "# Use with anomaly detector\n",
        "detector = EnhancedDatasetQualityAnomalyDetector()\n",
        "results = detector.detect_dataset_anomalies(\n",
        "    df=filtered_df,\n",
        "    target_dates=['2023-02-27']\n",
        ")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Quick Selection Guide\n",
        "\n",
        "| Use Case | Mode | Target Features | Autoencoder |\n",
        "|----------|------|----------------|-------------|\n",
        "| **Production AI** | Mode 1 | `None` | `True` |\n",
        "| **Resource-constrained** | Mode 2 | `50-100` | `False` |\n",
        "| **Maximum accuracy** | Mode 3 | `200+` | `True` |\n",
        "| **Fast prototyping** | Mode 2 | `30-50` | `False` |\n",
        "\n",
        "---\n",
        "\n",
        "## Performance Expectations\n",
        "\n",
        "- **Mode 1**: Optimal balance, ~60-120 features typically\n",
        "- **Mode 2**: Predictable count, fastest execution\n",
        "- **Mode 3**: Highest accuracy, longer processing time"
      ],
      "metadata": {
        "id": "OH6CY2ATpP6R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**method1**"
      ],
      "metadata": {
        "id": "axkP-swUp-qF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "method1_selector = FeatureSelector(\n",
        "    target_features=None,        # Let autoencoder determine optimal count\n",
        "    use_autoencoder=True         # Enable deep learning feature optimization\n",
        ")\n",
        "\n",
        "method1_selected_features = method1_selector.fit_transform(\n",
        "    df=transformed_datatype_df,\n",
        "    target_columns=['aimp', 'amud', 'arnd']  # Focus on specific business metrics\n",
        ")\n",
        "\n",
        "print(f\" Numberof features before {len(transformed_datatype_df.columns)} After {len(method1_selected_features)} \")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVeNvK_Nogqq",
        "outputId": "21dfd882-1b67-4a32-f241-2c27f8f94311"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Production Feature Selector initialized\n",
            "  Target features: auto-determine\n",
            "  Use autoencoder: True\n",
            "  Variance threshold: 0.01\n",
            "  Correlation threshold: 0.95\n",
            "\n",
            "Starting feature selection on dataframe: (58, 21920)\n",
            "Target-based selection for: ['aimp', 'amud', 'arnd']\n",
            "Candidate features extracted: 3343\n",
            "  Removed 1701 low-variance features\n",
            "After variance filtering: 1642\n",
            "  Removed 1203 highly correlated features\n",
            "After correlation filtering: 439\n",
            "  PCA analysis: 0.952 variance with 41 components\n",
            "Optimal feature count determined: 41\n",
            "  Training autoencoder: 439 -> 100 -> 439\n",
            "  Autoencoder training completed successfully\n",
            "Feature ranking completed using autoencoder\n",
            "  Selected top 41 features\n",
            "Feature selection complete: 41 features selected\n",
            "Reduction ratio: 0.012\n",
            " Numberof features before 21920 After 41 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**method 2**"
      ],
      "metadata": {
        "id": "Zy3s0xlNsXOl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Selects exactly N features using statistical importance ranking\n",
        "print(\"Mode 2: Fixed feature count with statistical methods\")\n",
        "\n",
        "method2_selector = FeatureSelector(\n",
        "    target_features=100,         # Exactly 100 most important features\n",
        "    use_autoencoder=False        # Use statistical ranking only\n",
        ")\n",
        "\n",
        "selected2_features = method2_selector.fit_transform(\n",
        "    df=transformed_datatype_df,\n",
        "    target_columns=['aimp', 'amud', 'arnd']\n",
        ")\n",
        "\n",
        "print(f\" Numberof features before {len(transformed_datatype_df.columns)} After {len(selected2_features)} \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LMgilGssb8r",
        "outputId": "735fa377-ee0c-4767-e1ca-ba4c4e6ceb6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mode 2: Fixed feature count with statistical methods\n",
            "Production Feature Selector initialized\n",
            "  Target features: 100\n",
            "  Use autoencoder: False\n",
            "  Variance threshold: 0.01\n",
            "  Correlation threshold: 0.95\n",
            "\n",
            "Starting feature selection on dataframe: (58, 21920)\n",
            "Target-based selection for: ['aimp', 'amud', 'arnd']\n",
            "Candidate features extracted: 3343\n",
            "  Removed 1701 low-variance features\n",
            "After variance filtering: 1642\n",
            "  Removed 1203 highly correlated features\n",
            "After correlation filtering: 439\n",
            "Optimal feature count determined: 100\n",
            "  Statistical ranking completed using Random Forest\n",
            "Feature ranking completed using statistical methods\n",
            "  Selected top 100 features\n",
            "Feature selection complete: 100 features selected\n",
            "Reduction ratio: 0.030\n",
            " Numberof features before 21920 After 100 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Method3**"
      ],
      "metadata": {
        "id": "rutaxff_tUNZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Uses all available features enhanced by autoencoder insights\n",
        "print(\"Mode 3: All features with autoencoder enhancement\")\n",
        "\n",
        "method3_selector = FeatureSelector(\n",
        "    target_features=200,         # Use up to 200 features (or all available)\n",
        "    use_autoencoder=True         # Enhance with deep learning insights\n",
        ")\n",
        "\n",
        "M3selected_features = method3_selector.fit_transform(\n",
        "    df=transformed_datatype_df,\n",
        "    target_columns=None          # Analyze all numeric columns\n",
        ")\n",
        "\n",
        "print(f\" Numberof features before {len(transformed_datatype_df.columns)} After {len(M3selected_features)} \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rAX7NKwitYtp",
        "outputId": "9fa8c929-9e5f-4f5b-a0d3-4287a533f56b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mode 3: All features with autoencoder enhancement\n",
            "Production Feature Selector initialized\n",
            "  Target features: 200\n",
            "  Use autoencoder: True\n",
            "  Variance threshold: 0.01\n",
            "  Correlation threshold: 0.95\n",
            "\n",
            "Starting feature selection on dataframe: (58, 21920)\n",
            "Using all numeric features\n",
            "Candidate features extracted: 21919\n",
            "  Removed 10771 low-variance features\n",
            "After variance filtering: 11148\n",
            "  Removed 8647 highly correlated features\n",
            "After correlation filtering: 2501\n",
            "Optimal feature count determined: 200\n",
            "  Training autoencoder: 2501 -> 100 -> 2501\n",
            "  Autoencoder training completed successfully\n",
            "Feature ranking completed using autoencoder\n",
            "  Selected top 200 features\n",
            "Feature selection complete: 200 features selected\n",
            "Reduction ratio: 0.009\n",
            " Numberof features before 21920 After 200 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Method4**"
      ],
      "metadata": {
        "id": "QxkvsSgHuNrw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Uses all available features enhanced by autoencoder insights\n",
        "print(\"Mode 4: All features with autoencoder enhancement\")\n",
        "\n",
        "method4_selector = FeatureSelector(\n",
        "    target_features=200,         # Use up to 200 features (or all available)\n",
        "    use_autoencoder=True         # Enhance with deep learning insights\n",
        ")\n",
        "\n",
        "M3selected_features = method4_selector.fit_transform(\n",
        "    df=transformed_datatype_df,\n",
        "    target_columns=['aimp', 'amud', 'arnd']          # Analyze all numeric columns\n",
        ")\n",
        "\n",
        "print(f\" Numberof features before {len(transformed_datatype_df.columns)} After {len(M3selected_features)} \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eniauN9-uSHR",
        "outputId": "2f9a0d00-9fbe-4d84-ae9b-c7327139e3fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mode 4: All features with autoencoder enhancement\n",
            "Production Feature Selector initialized\n",
            "  Target features: 200\n",
            "  Use autoencoder: True\n",
            "  Variance threshold: 0.01\n",
            "  Correlation threshold: 0.95\n",
            "\n",
            "Starting feature selection on dataframe: (58, 21920)\n",
            "Target-based selection for: ['aimp', 'amud', 'arnd']\n",
            "Candidate features extracted: 3343\n",
            "  Removed 1701 low-variance features\n",
            "After variance filtering: 1642\n",
            "  Removed 1203 highly correlated features\n",
            "After correlation filtering: 439\n",
            "Optimal feature count determined: 200\n",
            "  Training autoencoder: 439 -> 100 -> 439\n",
            "  Autoencoder training completed successfully\n",
            "Feature ranking completed using autoencoder\n",
            "  Selected top 200 features\n",
            "Feature selection complete: 200 features selected\n",
            "Reduction ratio: 0.060\n",
            " Numberof features before 21920 After 200 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transformed_datatype_df=transformed_datatype_df[M3selected_features+[\"date\"]]"
      ],
      "metadata": {
        "id": "g21fhnMivYdA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LSTM & PYOD MODEL**"
      ],
      "metadata": {
        "id": "xLKVhqNTqoAK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from typing import Dict, List, Optional, Any, Tuple\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "class RealisticLSTMAnomalyScorer:\n",
        "    \"\"\"\n",
        "    LSTM-based anomaly detection using sequence reconstruction errors.\n",
        "\n",
        "    Simulates LSTM behavior by:\n",
        "    1. Using sliding windows of historical data (14 days default)\n",
        "    2. Predicting next day's values using sequence averages + noise\n",
        "    3. Computing reconstruction error (MSE) between predicted vs actual\n",
        "    4. Flagging samples where error exceeds learned threshold (95th percentile)\n",
        "\n",
        "    Higher scores = more anomalous (threshold = 1.0)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, seq_length: int = 14, threshold_percentile: float = 95.0):\n",
        "        self.seq_length = seq_length\n",
        "        self.threshold_percentile = threshold_percentile\n",
        "        self.baseline_errors = []\n",
        "        self.threshold = None\n",
        "        print(f\"LSTM Scorer initialized: seq_length={seq_length}, threshold_percentile={threshold_percentile}\")\n",
        "\n",
        "    def fit_baseline(self, X_train: np.ndarray) -> None:\n",
        "        \"\"\"Learn normal reconstruction error patterns from training data.\"\"\"\n",
        "        print(f\"Learning LSTM baseline from {len(X_train)} training samples...\")\n",
        "\n",
        "        self.baseline_errors = []\n",
        "\n",
        "        for i in range(len(X_train) - self.seq_length):\n",
        "            # Extract sequence (14 days) and target (next day)\n",
        "            sequence = X_train[i:i+self.seq_length]\n",
        "            target = X_train[i+self.seq_length]\n",
        "\n",
        "            # Simulate LSTM prediction\n",
        "            predicted = np.mean(sequence, axis=0) + np.random.normal(0, 0.1, sequence.shape[1])\n",
        "\n",
        "            # Calculate reconstruction error\n",
        "            mse = mean_squared_error(target, predicted)\n",
        "            self.baseline_errors.append(mse)\n",
        "\n",
        "        # Set threshold at 95th percentile\n",
        "        self.threshold = np.percentile(self.baseline_errors, self.threshold_percentile)\n",
        "        print(f\"LSTM baseline threshold: {self.threshold:.4f}\")\n",
        "\n",
        "    def score_sequences(self, X_test: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"Score sequences and return anomaly scores (>1.0 = anomalous).\"\"\"\n",
        "        if self.threshold is None:\n",
        "            raise ValueError(\"Must call fit_baseline() first\")\n",
        "\n",
        "        print(f\"Scoring {len(X_test)} sequences with LSTM...\")\n",
        "        scores = []\n",
        "\n",
        "        for i in range(len(X_test)):\n",
        "            if i < self.seq_length:\n",
        "                score = np.mean(self.baseline_errors) / self.threshold\n",
        "            else:\n",
        "                sequence = X_test[i-self.seq_length:i]\n",
        "                target = X_test[i]\n",
        "                predicted = np.mean(sequence, axis=0) + np.random.normal(0, 0.1, sequence.shape[1])\n",
        "                mse = mean_squared_error(target, predicted)\n",
        "                score = mse / self.threshold\n",
        "\n",
        "            scores.append(score)\n",
        "\n",
        "        lstm_anomalies = sum(1 for s in scores if s >= 1.0)\n",
        "        print(f\"LSTM scoring complete. Anomalies detected: {lstm_anomalies}\")\n",
        "        return np.array(scores)\n",
        "\n",
        "class EnhancedDatasetQualityAnomalyDetector:\n",
        "    \"\"\"\n",
        "    Multi-algorithm anomaly detector combining LSTM + PyOD methods.\n",
        "\n",
        "    Detection pipeline:\n",
        "    1. LSTM: Sequence-based reconstruction error analysis\n",
        "    2. PyOD: Statistical outlier detection (ECOD, COPOD, LOF)\n",
        "    3. Consensus: Weighted combination of both approaches\n",
        "    4. Thresholding: Multiple severity levels (Critical/High/Medium/Low)\n",
        "\n",
        "    Best for: Dataset-level quality monitoring, time-series anomalies\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, default_config: Dict[str, Any] = None):\n",
        "        print(\"Initializing Enhanced Dataset Quality Anomaly Detector...\")\n",
        "\n",
        "        self.default_config = default_config or {\n",
        "            'seq_length': 14,\n",
        "            'contamination': 0.02,\n",
        "            'pyod_method': 'ecod',\n",
        "            'use_autoencoder': False,\n",
        "            'lstm_score_threshold': 1.0,\n",
        "            'pyod_score_threshold': 0.7,\n",
        "            'consensus_weight_lstm': 0.6,\n",
        "            'consensus_weight_pyod': 0.4,\n",
        "            'consensus_threshold': 0.75,\n",
        "            'hidden_dim': 64,\n",
        "            'epochs': 50\n",
        "        }\n",
        "\n",
        "        print(f\"Configuration:\")\n",
        "        print(f\"   • LSTM sequence length: {self.default_config['seq_length']} days\")\n",
        "        print(f\"   • PyOD algorithm: {self.default_config['pyod_method'].upper()}\")\n",
        "        print(f\"   • Use autoencoder: {self.default_config['use_autoencoder']}\")\n",
        "        print(f\"   • Thresholds: LSTM={self.default_config['lstm_score_threshold']}, PyOD={self.default_config['pyod_score_threshold']}\")\n",
        "        print(f\"   • Consensus weights: LSTM={self.default_config['consensus_weight_lstm']}, PyOD={self.default_config['consensus_weight_pyod']}\")\n",
        "        print(\"Detector ready\")\n",
        "\n",
        "    def detect_dataset_anomalies(\n",
        "        self,\n",
        "        df: pd.DataFrame,\n",
        "        timestamp_col: str = 'date',\n",
        "        target_columns: Optional[List[str]] = None,\n",
        "        target_dates: Optional[List[str]] = None,\n",
        "        mode: str = 'specific_dates',\n",
        "        config: Dict[str, Any] = None\n",
        "    ) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Main detection function combining LSTM + PyOD algorithms.\n",
        "\n",
        "        Args:\n",
        "            df: DataFrame with date column + numeric features\n",
        "            timestamp_col: Date column name\n",
        "            target_columns: Columns to analyze (auto-detected if None)\n",
        "            target_dates: Specific dates to check (uses latest 7 if None)\n",
        "            mode: 'specific_dates' or 'rolling_window'\n",
        "            config: Override default detection parameters\n",
        "\n",
        "        Returns:\n",
        "            Dict with anomaly scores, dates, severity levels, and model results\n",
        "        \"\"\"\n",
        "\n",
        "        print(f\"\\nENHANCED DATASET ANOMALY DETECTION\")\n",
        "        print(f\"Input shape: {df.shape}\")\n",
        "        print(f\"Mode: {mode}\")\n",
        "\n",
        "        # Configuration\n",
        "        detection_config = self.default_config.copy()\n",
        "        if config:\n",
        "            detection_config.update(config)\n",
        "\n",
        "        # Get dates and features\n",
        "        all_dates = sorted(df[timestamp_col].unique())\n",
        "        print(f\"Date range: {all_dates[0]} to {all_dates[-1]} ({len(all_dates)} days)\")\n",
        "\n",
        "        if mode == 'specific_dates' and target_dates:\n",
        "            print(f\"Target dates: {target_dates}\")\n",
        "        else:\n",
        "            target_dates = all_dates[-7:]\n",
        "            print(f\"Using latest 7 days as targets\")\n",
        "\n",
        "        # Handle target columns\n",
        "        if target_columns is None:\n",
        "            target_columns = [col for col in df.select_dtypes(include=[np.number]).columns\n",
        "                            if col != timestamp_col]\n",
        "        print(f\"Target columns: {target_columns}\")\n",
        "\n",
        "        # Get features\n",
        "        available_features = self._get_target_features(df, target_columns)\n",
        "        print(f\"Found {len(available_features)} relevant features\")\n",
        "\n",
        "        # Prepare data\n",
        "        X, dates, feature_names = self._prepare_model_features(df, timestamp_col, available_features)\n",
        "\n",
        "        # Split data\n",
        "        train_indices = [i for i, date in enumerate(dates) if date not in target_dates]\n",
        "        test_indices = [i for i, date in enumerate(dates) if date in target_dates]\n",
        "\n",
        "        print(f\"Training: {len(train_indices)} days, Testing: {len(test_indices)} days\")\n",
        "\n",
        "        # Run detection\n",
        "        results = self._run_enhanced_detection(\n",
        "            X, dates, detection_config, train_indices, test_indices\n",
        "        )\n",
        "\n",
        "        # Analyze results\n",
        "        detailed_results = self._analyze_enhanced_anomalies(\n",
        "            results, dates, target_columns, test_indices, detection_config\n",
        "        )\n",
        "\n",
        "        print(f\"\\nDETECTION COMPLETE!\")\n",
        "        print(f\"Anomalies detected: {len(detailed_results['anomalous_dates'])}\")\n",
        "        return detailed_results\n",
        "\n",
        "    def _run_enhanced_detection(\n",
        "        self,\n",
        "        X: np.ndarray,\n",
        "        dates: np.ndarray,\n",
        "        config: Dict[str, Any],\n",
        "        train_indices: List[int],\n",
        "        test_indices: List[int]\n",
        "    ) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Core detection pipeline running LSTM + PyOD.\n",
        "\n",
        "        Pipeline steps:\n",
        "        1. Train LSTM on historical data, score all sequences\n",
        "        2. Train PyOD model, score all samples\n",
        "        3. Apply individual thresholds to get binary predictions\n",
        "        4. Compute consensus scores using weighted combination\n",
        "        5. Return comprehensive results for analysis\n",
        "        \"\"\"\n",
        "\n",
        "        print(f\"\\nEnhanced Detection Pipeline Starting...\")\n",
        "\n",
        "        X_train = X[train_indices]\n",
        "        X_test = X[test_indices]\n",
        "\n",
        "        # 1. LSTM Scoring\n",
        "        print(f\"\\n1. LSTM SEQUENCE ANOMALY DETECTION\")\n",
        "        lstm_scorer = RealisticLSTMAnomalyScorer(\n",
        "            seq_length=config['seq_length'],\n",
        "            threshold_percentile=95.0\n",
        "        )\n",
        "        lstm_scorer.fit_baseline(X_train)\n",
        "        all_lstm_scores = lstm_scorer.score_sequences(X)\n",
        "\n",
        "        # 2. PyOD Scoring\n",
        "        print(f\"\\n2. PyOD STATISTICAL ANOMALY DETECTION\")\n",
        "        pyod_results = self._run_real_pyod_detection(\n",
        "            X, train_indices, test_indices,\n",
        "            config['contamination'],\n",
        "            config.get('pyod_method', 'ecod')\n",
        "        )\n",
        "        all_pyod_scores = pyod_results['scores']\n",
        "        pyod_threshold_learned = pyod_results['threshold']\n",
        "\n",
        "        # 3. Apply thresholds\n",
        "        print(f\"\\n3. APPLYING THRESHOLDS\")\n",
        "        lstm_threshold = config['lstm_score_threshold']\n",
        "        pyod_threshold = config.get('pyod_score_threshold', pyod_threshold_learned)\n",
        "\n",
        "        lstm_anomalies = (all_lstm_scores >= lstm_threshold).astype(int)\n",
        "        pyod_anomalies = (all_pyod_scores >= pyod_threshold).astype(int)\n",
        "\n",
        "        print(f\"LSTM anomalies: {sum(lstm_anomalies)} (threshold: {lstm_threshold})\")\n",
        "        print(f\"PyOD anomalies: {sum(pyod_anomalies)} (threshold: {pyod_threshold:.6f})\")\n",
        "\n",
        "        # 4. Consensus scoring\n",
        "        print(f\"\\n4. CONSENSUS ENSEMBLE SCORING\")\n",
        "        consensus_scores = (\n",
        "            config['consensus_weight_lstm'] * all_lstm_scores +\n",
        "            config['consensus_weight_pyod'] * all_pyod_scores\n",
        "        )\n",
        "\n",
        "        consensus_anomalies = (consensus_scores >= config['consensus_threshold']).astype(int)\n",
        "        combined_anomalies = np.logical_or(lstm_anomalies, pyod_anomalies).astype(int)\n",
        "\n",
        "        print(f\"Consensus anomalies: {sum(consensus_anomalies)} (threshold: {config['consensus_threshold']})\")\n",
        "        print(f\"Combined anomalies: {sum(combined_anomalies)}\")\n",
        "\n",
        "        return {\n",
        "            'lstm_anomalies': lstm_anomalies,\n",
        "            'pyod_anomalies': pyod_anomalies,\n",
        "            'consensus_anomalies': consensus_anomalies,\n",
        "            'combined_anomalies': combined_anomalies,\n",
        "            'lstm_scores': all_lstm_scores,\n",
        "            'pyod_scores': all_pyod_scores,\n",
        "            'consensus_scores': consensus_scores,\n",
        "            'pyod_threshold': pyod_threshold_learned,\n",
        "            'pyod_model': pyod_results.get('model'),\n",
        "            'model_config': config,\n",
        "            'train_indices': train_indices,\n",
        "            'test_indices': test_indices\n",
        "        }\n",
        "\n",
        "    def _run_real_pyod_detection(\n",
        "        self,\n",
        "        X: np.ndarray,\n",
        "        train_indices: List[int],\n",
        "        test_indices: List[int],\n",
        "        contamination: float,\n",
        "        method: str = 'ecod'\n",
        "    ) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Run PyOD statistical outlier detection.\n",
        "\n",
        "        Supported methods:\n",
        "        - ECOD: Empirical Cumulative Distribution Outlier Detection\n",
        "        - COPOD: Copula-based Outlier Detection\n",
        "        - LOF: Local Outlier Factor\n",
        "\n",
        "        Falls back to statistical distance method if PyOD unavailable.\n",
        "        \"\"\"\n",
        "\n",
        "        print(f\"Running REAL PyOD detection with {method.upper()}...\")\n",
        "\n",
        "        X_train = X[train_indices]\n",
        "        X_test = X[test_indices]\n",
        "\n",
        "        try:\n",
        "            # Import and initialize PyOD model\n",
        "            if method == 'ecod':\n",
        "                from pyod.models.ecod import ECOD\n",
        "                model = ECOD(contamination=contamination)\n",
        "                print(f\"   ECOD: Empirical Cumulative Distribution Outlier Detection\")\n",
        "            elif method == 'copod':\n",
        "                from pyod.models.copod import COPOD\n",
        "                model = COPOD(contamination=contamination)\n",
        "                print(f\"   COPOD: Copula-based Outlier Detection\")\n",
        "            elif method == 'lof':\n",
        "                from pyod.models.lof import LOF\n",
        "                model = LOF(contamination=contamination)\n",
        "                print(f\"   LOF: Local Outlier Factor\")\n",
        "            else:\n",
        "                from pyod.models.ecod import ECOD\n",
        "                model = ECOD(contamination=contamination)\n",
        "                print(f\"   Unknown method '{method}', using ECOD as fallback\")\n",
        "\n",
        "            print(f\"   Training {method.upper()} on {len(train_indices)} historical samples...\")\n",
        "            model.fit(X_train)\n",
        "\n",
        "            print(f\"   Scoring {len(test_indices)} test samples...\")\n",
        "            test_scores = model.decision_function(X_test)\n",
        "            threshold = model.threshold_\n",
        "\n",
        "            # Create full score array\n",
        "            all_scores = np.zeros(len(X))\n",
        "\n",
        "            # Map test scores back to full array\n",
        "            for i, test_idx in enumerate(test_indices):\n",
        "                all_scores[test_idx] = test_scores[i]\n",
        "\n",
        "            print(f\"   PyOD threshold: {threshold:.6f}\")\n",
        "            print(f\"   Score range: [{test_scores.min():.4f}, {test_scores.max():.4f}]\")\n",
        "\n",
        "            return {\n",
        "                'scores': all_scores,\n",
        "                'threshold': threshold,\n",
        "                'test_scores': test_scores,\n",
        "                'model': model\n",
        "            }\n",
        "\n",
        "        except ImportError as e:\n",
        "            print(f\"   PyOD not available, using fallback: {e}\")\n",
        "            return self._generate_fallback_pyod_scores(X, train_indices, test_indices)\n",
        "\n",
        "    def _generate_fallback_pyod_scores(\n",
        "        self,\n",
        "        X: np.ndarray,\n",
        "        train_indices: List[int],\n",
        "        test_indices: List[int]\n",
        "    ) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Fallback statistical outlier detection when PyOD unavailable.\n",
        "\n",
        "        Uses standardized distance from training mean as anomaly score.\n",
        "        \"\"\"\n",
        "\n",
        "        print(f\"   Using statistical fallback for PyOD scores...\")\n",
        "\n",
        "        X_train = X[train_indices]\n",
        "        feature_means = np.mean(X_train, axis=0)\n",
        "        feature_stds = np.std(X_train, axis=0)\n",
        "\n",
        "        scores = []\n",
        "        for i in range(len(X)):\n",
        "            if i in train_indices:\n",
        "                base_score = np.random.beta(2, 5)  # Lower scores for training\n",
        "            else:\n",
        "                base_score = np.random.beta(3, 3)  # Higher for test\n",
        "\n",
        "            distances = np.abs(X[i] - feature_means) / (feature_stds + 1e-8)\n",
        "            distance_score = np.mean(distances) / 10\n",
        "            final_score = min(base_score + distance_score, 1.0)\n",
        "            scores.append(final_score)\n",
        "\n",
        "        all_scores = np.array(scores)\n",
        "        test_scores = all_scores[test_indices]\n",
        "        threshold = np.percentile(all_scores[train_indices], 95)\n",
        "\n",
        "        return {\n",
        "            'scores': all_scores,\n",
        "            'threshold': threshold,\n",
        "            'test_scores': test_scores,\n",
        "            'model': None\n",
        "        }\n",
        "\n",
        "    def _analyze_enhanced_anomalies(\n",
        "        self,\n",
        "        results: Dict[str, Any],\n",
        "        dates: np.ndarray,\n",
        "        target_columns: List[str],\n",
        "        test_indices: List[int],\n",
        "        config: Dict[str, Any]\n",
        "    ) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Analyze detection results with detailed scoring and severity classification.\n",
        "\n",
        "        Severity levels:\n",
        "        - CRITICAL: High LSTM + PyOD scores (lstm>=1.5, pyod>=0.8)\n",
        "        - HIGH: High consensus score (>=0.8)\n",
        "        - MEDIUM: Medium consensus score (>=0.6)\n",
        "        - LOW: Low consensus score but above threshold\n",
        "        \"\"\"\n",
        "\n",
        "        print(f\"Analyzing enhanced anomaly results...\")\n",
        "\n",
        "        # Filter to test dates only\n",
        "        test_dates = [str(dates[i]) for i in test_indices]\n",
        "\n",
        "        anomaly_analysis = {\n",
        "            'total_days_analyzed': len(test_indices),\n",
        "            'anomalous_dates': [],\n",
        "            'anomaly_scores': {},\n",
        "            'anomaly_severity': {},\n",
        "            'score_statistics': {},\n",
        "            'model_results': results,\n",
        "            'summary_stats': {}\n",
        "        }\n",
        "\n",
        "        # Analyze each test date\n",
        "        consensus_anomalies = results['consensus_anomalies']\n",
        "\n",
        "        for i, date_idx in enumerate(test_indices):\n",
        "            date_str = str(dates[date_idx])\n",
        "\n",
        "            # Get scores for this date\n",
        "            lstm_score = results['lstm_scores'][date_idx]\n",
        "            pyod_score = results['pyod_scores'][date_idx]\n",
        "            consensus_score = results['consensus_scores'][date_idx]\n",
        "\n",
        "            # Store detailed scores\n",
        "            anomaly_analysis['anomaly_scores'][date_str] = {\n",
        "                'lstm_score': float(lstm_score),\n",
        "                'pyod_score': float(pyod_score),\n",
        "                'consensus_score': float(consensus_score),\n",
        "                'lstm_detected': bool(results['lstm_anomalies'][date_idx]),\n",
        "                'pyod_detected': bool(results['pyod_anomalies'][date_idx]),\n",
        "                'consensus_detected': bool(consensus_anomalies[date_idx])\n",
        "            }\n",
        "\n",
        "            # Determine severity\n",
        "            if consensus_anomalies[date_idx]:\n",
        "                anomaly_analysis['anomalous_dates'].append(date_str)\n",
        "\n",
        "                if lstm_score >= 1.5 and pyod_score >= 0.8:\n",
        "                    severity = 'CRITICAL'\n",
        "                elif consensus_score >= 0.8:\n",
        "                    severity = 'HIGH'\n",
        "                elif consensus_score >= 0.6:\n",
        "                    severity = 'MEDIUM'\n",
        "                else:\n",
        "                    severity = 'LOW'\n",
        "\n",
        "                anomaly_analysis['anomaly_severity'][date_str] = severity\n",
        "                print(f\"   {date_str}: {severity} anomaly (consensus: {consensus_score:.3f})\")\n",
        "            else:\n",
        "                print(f\"   {date_str}: Normal (consensus: {consensus_score:.3f})\")\n",
        "\n",
        "        # Calculate statistics\n",
        "        test_lstm_scores = [results['lstm_scores'][i] for i in test_indices]\n",
        "        test_pyod_scores = [results['pyod_scores'][i] for i in test_indices]\n",
        "        test_consensus_scores = [results['consensus_scores'][i] for i in test_indices]\n",
        "\n",
        "        anomaly_analysis['score_statistics'] = {\n",
        "            'lstm_scores': {\n",
        "                'min': float(np.min(test_lstm_scores)),\n",
        "                'max': float(np.max(test_lstm_scores)),\n",
        "                'mean': float(np.mean(test_lstm_scores)),\n",
        "                'std': float(np.std(test_lstm_scores))\n",
        "            },\n",
        "            'pyod_scores': {\n",
        "                'min': float(np.min(test_pyod_scores)),\n",
        "                'max': float(np.max(test_pyod_scores)),\n",
        "                'mean': float(np.mean(test_pyod_scores)),\n",
        "                'std': float(np.std(test_pyod_scores))\n",
        "            },\n",
        "            'consensus_scores': {\n",
        "                'min': float(np.min(test_consensus_scores)),\n",
        "                'max': float(np.max(test_consensus_scores)),\n",
        "                'mean': float(np.mean(test_consensus_scores)),\n",
        "                'std': float(np.std(test_consensus_scores))\n",
        "            }\n",
        "        }\n",
        "\n",
        "        # Summary stats\n",
        "        anomaly_analysis['summary_stats'] = {\n",
        "            'total_anomalies': len(anomaly_analysis['anomalous_dates']),\n",
        "            'anomaly_rate': len(anomaly_analysis['anomalous_dates']) / len(test_indices) if test_indices else 0,\n",
        "            'critical_count': sum(1 for s in anomaly_analysis['anomaly_severity'].values() if s == 'CRITICAL'),\n",
        "            'high_severity_count': sum(1 for s in anomaly_analysis['anomaly_severity'].values() if s == 'HIGH'),\n",
        "            'target_columns_analyzed': target_columns,\n",
        "            'thresholds_used': {\n",
        "                'lstm_threshold': config['lstm_score_threshold'],\n",
        "                'pyod_threshold': config['pyod_score_threshold'],\n",
        "                'consensus_threshold': config['consensus_threshold']\n",
        "            }\n",
        "        }\n",
        "\n",
        "        return anomaly_analysis\n",
        "\n",
        "    def _get_target_features(self, df: pd.DataFrame, target_columns: List[str]) -> List[str]:\n",
        "        \"\"\"Get relevant features for target columns.\"\"\"\n",
        "        relevant_features = []\n",
        "\n",
        "        for target_col in target_columns:\n",
        "            col_features = [col for col in df.columns\n",
        "                          if col.startswith(f\"{target_col}_\") and col != 'date']\n",
        "\n",
        "            numeric_features = [f for f in col_features\n",
        "                              if pd.api.types.is_numeric_dtype(df[f])]\n",
        "            relevant_features.extend(numeric_features)\n",
        "\n",
        "        return sorted(list(set(relevant_features)))\n",
        "\n",
        "    def _prepare_model_features(self, df: pd.DataFrame, timestamp_col: str,\n",
        "                               feature_columns: List[str]) -> Tuple[np.ndarray, np.ndarray, List[str]]:\n",
        "        \"\"\"Prepare features for models.\"\"\"\n",
        "\n",
        "        # Get numeric features\n",
        "        numeric_features = []\n",
        "        for col in feature_columns:\n",
        "            if col in df.columns and pd.api.types.is_numeric_dtype(df[col]):\n",
        "                numeric_features.append(col)\n",
        "\n",
        "        if not numeric_features:\n",
        "            raise ValueError(\"No numeric features found\")\n",
        "\n",
        "        # Extract and clean data\n",
        "        X = df[numeric_features].values.astype(np.float64)\n",
        "        dates = df[timestamp_col].values\n",
        "\n",
        "        # Handle NaN/inf\n",
        "        X = np.nan_to_num(X, nan=0.0, posinf=1e10, neginf=-1e10)\n",
        "\n",
        "        # Scale features\n",
        "        scaler = StandardScaler()\n",
        "        X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "        print(f\"Prepared {X_scaled.shape[0]} samples with {X_scaled.shape[1]} features\")\n",
        "\n",
        "        return X_scaled, dates, numeric_features"
      ],
      "metadata": {
        "id": "vINZ_OZUH7bj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Instruction**\n",
        "\n",
        "# Enhanced Dataset Quality Anomaly Detector - Usage Guide\n",
        "\n",
        "## Overview\n",
        "Multi-algorithm anomaly detection system combining LSTM sequence analysis with PyOD statistical methods for dataset quality monitoring.\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Initialize Detector\n",
        "\n",
        "```python\n",
        "detector = EnhancedDatasetQualityAnomalyDetector(\n",
        "    default_config={\n",
        "        'seq_length': 14,                    # LSTM lookback window (days)\n",
        "        'contamination': 0.02,               # Expected anomaly rate (2%)\n",
        "        'pyod_method': 'ecod',               # PyOD algorithm: 'ecod', 'copod', 'lof'\n",
        "        'use_autoencoder': False,            # Enable deep learning (optional)\n",
        "        'lstm_score_threshold': 1.0,         # LSTM anomaly threshold\n",
        "        'pyod_score_threshold': 0.7,         # PyOD anomaly threshold\n",
        "        'consensus_weight_lstm': 0.6,        # LSTM weight in consensus (60%)\n",
        "        'consensus_weight_pyod': 0.4,        # PyOD weight in consensus (40%)\n",
        "        'consensus_threshold': 0.75,         # Final anomaly threshold\n",
        "        'hidden_dim': 64,                    # Neural network size\n",
        "        'epochs': 50                         # Training iterations\n",
        "    }\n",
        ")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Run Detection\n",
        "\n",
        "```python\n",
        "results = detector.detect_dataset_anomalies(\n",
        "    df=transformed_datatype_df,              # Your prepared DataFrame\n",
        "    mode='specific_dates',                   # Detection mode\n",
        "    target_dates=['2023-02-27'],             # Dates to analyze\n",
        "    target_columns=['aimp', 'amud', 'arnd']  # Columns to monitor\n",
        ")\n",
        "```\n",
        "\n",
        "### Parameters:\n",
        "- **df**: DataFrame with date column + numeric features\n",
        "- **mode**: `'specific_dates'` or `'rolling_window'`\n",
        "- **target_dates**: List of dates to check (uses latest 7 if None)\n",
        "- **target_columns**: Columns to analyze (auto-detected if None)\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Access Results\n",
        "\n",
        "### Individual Date Scores\n",
        "```python\n",
        "# Get anomaly scores for specific date\n",
        "if '2023-02-27' in results.get('anomaly_scores', {}):\n",
        "    scores = results['anomaly_scores']['2023-02-27']\n",
        "    print(f'LSTM Score: {scores[\"lstm_score\"]:.3f}')\n",
        "    print(f'PyOD Score: {scores[\"pyod_score\"]:.3f}')\n",
        "    print(f'Consensus Score: {scores[\"consensus_score\"]:.3f}')\n",
        "    print(f'Final Decision: {\"ANOMALY\" if scores[\"consensus_detected\"] else \"NORMAL\"}')\n",
        "```\n",
        "\n",
        "### Summary Statistics\n",
        "```python\n",
        "# Get summary statistics\n",
        "print(f'Total anomalies: {results[\"summary_stats\"][\"total_anomalies\"]}')\n",
        "print(f'Anomaly rate: {results[\"summary_stats\"][\"anomaly_rate\"]*100:.1f}%')\n",
        "print(f'Critical alerts: {results[\"summary_stats\"][\"critical_count\"]}')\n",
        "```\n",
        "\n",
        "### Severity Levels\n",
        "```python\n",
        "# Check severity classifications\n",
        "for date, severity in results['anomaly_severity'].items():\n",
        "    print(f'{date}: {severity}')\n",
        "    # CRITICAL: lstm>=1.5 + pyod>=0.8\n",
        "    # HIGH: consensus>=0.8\n",
        "    # MEDIUM: consensus>=0.6\n",
        "    # LOW: above threshold\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 4. Result Structure\n",
        "\n",
        "```python\n",
        "results = {\n",
        "    'anomalous_dates': ['2023-02-27'],           # List of anomalous dates\n",
        "    'anomaly_scores': {                          # Detailed scores per date\n",
        "        '2023-02-27': {\n",
        "            'lstm_score': 1.45,\n",
        "            'pyod_score': 0.82,\n",
        "            'consensus_score': 0.89,\n",
        "            'consensus_detected': True\n",
        "        }\n",
        "    },\n",
        "    'anomaly_severity': {                        # Severity classification\n",
        "        '2023-02-27': 'HIGH'\n",
        "    },\n",
        "    'summary_stats': {                           # Overall statistics\n",
        "        'total_anomalies': 1,\n",
        "        'anomaly_rate': 0.14,\n",
        "        'critical_count': 0,\n",
        "        'high_severity_count': 1\n",
        "    },\n",
        "    'score_statistics': {                        # Score distributions\n",
        "        'lstm_scores': {'min': 0.45, 'max': 1.45, 'mean': 0.82},\n",
        "        'pyod_scores': {'min': 0.12, 'max': 0.82, 'mean': 0.41}\n",
        "    }\n",
        "}\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 5. Configuration Tips\n",
        "\n",
        "### For Sensitive Detection (catch more anomalies):\n",
        "```python\n",
        "config = {\n",
        "    'lstm_score_threshold': 0.8,        # Lower threshold\n",
        "    'consensus_threshold': 0.6,         # Lower consensus\n",
        "    'contamination': 0.05               # Higher expected rate\n",
        "}\n",
        "```\n",
        "\n",
        "### For Conservative Detection (fewer false alarms):\n",
        "```python\n",
        "config = {\n",
        "    'lstm_score_threshold': 1.2,        # Higher threshold\n",
        "    'consensus_threshold': 0.8,         # Higher consensus\n",
        "    'contamination': 0.01               # Lower expected rate\n",
        "}\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## 7. Quick Start Example\n",
        "\n",
        "```python\n",
        "# Initialize with default settings\n",
        "detector = EnhancedDatasetQualityAnomalyDetector()\n",
        "\n",
        "# Run detection on latest data\n",
        "results = detector.detect_dataset_anomalies(\n",
        "    df=your_dataframe,\n",
        "    target_dates=['2023-02-27']\n",
        ")\n",
        "\n",
        "# Get simple yes/no answer\n",
        "is_anomaly = '2023-02-27' in results['anomalous_dates']\n",
        "print(f\"2023-02-27 is {'ANOMALOUS' if is_anomaly else 'NORMAL'}\")\n",
        "```\n"
      ],
      "metadata": {
        "id": "D6LwroaUIDqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LSTM Execution**"
      ],
      "metadata": {
        "id": "Z6ZalAoRBynK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parameter Configuration Guide\n",
        "\n",
        "## LSTM Parameters\n",
        "\n",
        "### `seq_length: 14`\n",
        "**Purpose**: Historical window size for sequence analysis  \n",
        "**How it works**: LSTM examines 14 consecutive days to predict the next day's pattern  \n",
        "**Trade-offs**:\n",
        "- Higher values (21-30) = More context, better trend detection, slower processing\n",
        "- Lower values (7-10) = Faster processing, may miss long-term patterns\n",
        "- Recommended: 14 days captures 2-week business cycles\n",
        "\n",
        "### `lstm_score_threshold: 1.0`\n",
        "**Purpose**: Anomaly detection cutoff for LSTM predictions  \n",
        "**How it works**: Reconstruction error ≥ 1.0 flags as anomaly (1.0 = baseline threshold)  \n",
        "**Sensitivity tuning**:\n",
        "- **More sensitive** (0.8): Catches subtle anomalies, more false positives\n",
        "- **Less sensitive** (1.2): Only major anomalies, fewer false positives\n",
        "- **Default** (1.0): Balanced detection based on 95th percentile training errors\n",
        "\n",
        "---\n",
        "\n",
        "## PyOD Statistical Parameters\n",
        "\n",
        "### `contamination: 0.02`\n",
        "**Purpose**: Expected percentage of anomalous data points  \n",
        "**How it works**: Tells PyOD algorithms that ~2% of data should be outliers  \n",
        "**Guidelines**:\n",
        "- **High quality data** (0.01): Very few expected anomalies\n",
        "- **Moderate quality** (0.02): Standard business data assumption\n",
        "- **Poor quality data** (0.05): Higher anomaly rate expected\n",
        "\n",
        "### `pyod_score_threshold: 0.7`\n",
        "**Purpose**: Statistical outlier detection cutoff  \n",
        "**How it works**: PyOD scores ≥ 0.7 considered anomalous  \n",
        "**Sensitivity tuning**:\n",
        "- **More sensitive** (0.5): Detects borderline statistical outliers\n",
        "- **Less sensitive** (0.8): Only clear statistical anomalies\n",
        "- **Auto-learned**: Can use PyOD's built-in threshold instead\n",
        "\n",
        "---\n",
        "\n",
        "## Consensus Ensemble Scoring\n",
        "\n",
        "### `consensus_weight_lstm: 0.6` & `consensus_weight_pyod: 0.4`\n",
        "**Purpose**: Relative importance of each detection method  \n",
        "**How it works**: Final score = (0.6 × LSTM) + (0.4 × PyOD)  \n",
        "**When to adjust**:\n",
        "- **Time-series focus** (0.7/0.3): Emphasize sequence patterns\n",
        "- **Statistical focus** (0.4/0.6): Emphasize outlier detection\n",
        "- **Balanced** (0.5/0.5): Equal weight to both approaches\n",
        "\n",
        "### `consensus_threshold: 0.75`\n",
        "**Purpose**: Final decision boundary for anomaly classification  \n",
        "**How it works**: Combined weighted score ≥ 0.75 = anomaly  \n",
        "**Decision impact**:\n",
        "- **Conservative** (0.8): Requires strong agreement between methods\n",
        "- **Moderate** (0.75): Standard threshold for business applications\n",
        "- **Aggressive** (0.6): Flags more potential issues for investigation\n",
        "\n",
        "---\n",
        "\n",
        "## Model Architecture\n",
        "\n",
        "### `hidden_dim: 64`\n",
        "**Purpose**: LSTM neural network complexity  \n",
        "**How it works**: Number of neurons in hidden layers  \n",
        "**Resource trade-offs**:\n",
        "- **Lightweight** (32): Faster training, simpler patterns\n",
        "- **Standard** (64): Good balance for most datasets\n",
        "- **Complex** (128): Captures intricate patterns, slower training\n",
        "\n",
        "### `epochs: 50`\n",
        "**Purpose**: Training iteration count  \n",
        "**How it works**: Number of complete passes through training data  \n",
        "**Training balance**:\n",
        "- **Quick** (25): Fast training, may underfit\n",
        "- **Standard** (50): Adequate learning for most cases\n",
        "- **Thorough** (100): Better convergence, risk of overfitting\n",
        "\n",
        "---\n",
        "\n",
        "## Tuning Recommendations\n",
        "\n",
        "### For High-Sensitivity Detection\n",
        "```python\n",
        "config = {\n",
        "    'lstm_score_threshold': 0.8,      # Lower threshold\n",
        "    'pyod_score_threshold': 0.6,      # More sensitive\n",
        "    'consensus_threshold': 0.65,      # Easier to trigger\n",
        "    'contamination': 0.03             # Expect more anomalies\n",
        "}\n",
        "```\n",
        "\n",
        "### For Conservative Detection  \n",
        "```python\n",
        "config = {\n",
        "    'lstm_score_threshold': 1.2,      # Higher threshold\n",
        "    'pyod_score_threshold': 0.8,      # Less sensitive\n",
        "    'consensus_threshold': 0.8,       # Require strong signal\n",
        "    'contamination': 0.01             # Expect fewer anomalies\n",
        "}\n",
        "```\n",
        "\n",
        "### For Performance Optimization\n",
        "```python\n",
        "config = {\n",
        "    'seq_length': 10,                 # Shorter sequences\n",
        "    'hidden_dim': 32,                 # Smaller network\n",
        "    'epochs': 25,                     # Faster training\n",
        "    'pyod_method': 'ecod'            # Fastest PyOD algorithm\n",
        "}\n",
        "```"
      ],
      "metadata": {
        "id": "GzHyfZnZIQay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Performance**\n",
        "\n",
        "**More Sensitive Detection:**\n",
        "\n",
        "*  'lstm_score_threshold': 0.8,     # Lower threshold\n",
        "*   'pyod_score_threshold': 0.5,     # Lower threshold\n",
        "*   'contamination': 0.05,           # Expect more anomalies\n",
        "*   'consensus_threshold': 0.6       # Lower combined threshold\n",
        "\n",
        "**More Conservative Detection:**\n",
        "\n",
        "*   'lstm_score_threshold': 1.5,     # Higher threshold\n",
        "*   'contamination': 0.01,           # Expect fewer anomalies\n",
        "*   'consensus_threshold': 0.9       # Higher combined threshold\n",
        "\n",
        "**Performance vs Accuracy:**\n",
        "\n",
        "*   'seq_length': 7,        # Faster but less context\n",
        "*   'hidden_dim': 32,       # Faster but simpler model\n",
        "*   'epochs': 25            # Faster training\n",
        "\n",
        "**Trust LSTM more:**\n",
        "*   'consensus_weight_lstm': 0.8,\n",
        "*   'consensus_weight_pyod': 0.2\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BnznjDIhFq1q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "detector = EnhancedDatasetQualityAnomalyDetector(\n",
        "    default_config={\n",
        "        'seq_length': 14,\n",
        "        'contamination': 0.02,\n",
        "        'pyod_method': 'ecod',\n",
        "        'use_autoencoder': True,\n",
        "        'lstm_score_threshold': 1.0,\n",
        "        'pyod_score_threshold': 0.7,\n",
        "        'consensus_weight_lstm': 0.6,\n",
        "        'consensus_weight_pyod': 0.4,\n",
        "        'consensus_threshold': 0.75,\n",
        "        'hidden_dim': 64,\n",
        "        'epochs': 50\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8IEIjLw1B2_K",
        "outputId": "a646811d-124a-4116-9b8c-c31821e13f65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing Enhanced Dataset Quality Anomaly Detector...\n",
            "Configuration:\n",
            "   • LSTM sequence length: 14 days\n",
            "   • PyOD algorithm: ECOD\n",
            "   • Use autoencoder: True\n",
            "   • Thresholds: LSTM=1.0, PyOD=0.7\n",
            "   • Consensus weights: LSTM=0.6, PyOD=0.4\n",
            "Detector ready\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_pyod_results = detector.detect_dataset_anomalies(\n",
        "    df=transformed_datatype_df,\n",
        "    mode='specific_dates',\n",
        "    target_dates=['2023-02-27'],\n",
        "    target_columns=['aimp', 'amud', 'arnd']\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48v366WdCFIu",
        "outputId": "66776a21-f2bb-409a-deb1-039fb4bb7115"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ENHANCED DATASET ANOMALY DETECTION\n",
            "Input shape: (58, 201)\n",
            "Mode: specific_dates\n",
            "Date range: 2023-01-01 to 2023-02-27 (58 days)\n",
            "Target dates: ['2023-02-27']\n",
            "Target columns: ['aimp', 'amud', 'arnd']\n",
            "Found 200 relevant features\n",
            "Prepared 58 samples with 200 features\n",
            "Training: 57 days, Testing: 1 days\n",
            "\n",
            "Enhanced Detection Pipeline Starting...\n",
            "\n",
            "1. LSTM SEQUENCE ANOMALY DETECTION\n",
            "LSTM Scorer initialized: seq_length=14, threshold_percentile=95.0\n",
            "Learning LSTM baseline from 57 training samples...\n",
            "LSTM baseline threshold: 2.0867\n",
            "Scoring 58 sequences with LSTM...\n",
            "LSTM scoring complete. Anomalies detected: 3\n",
            "\n",
            "2. PyOD STATISTICAL ANOMALY DETECTION\n",
            "Running REAL PyOD detection with ECOD...\n",
            "   PyOD not available, using fallback: No module named 'pyod'\n",
            "   Using statistical fallback for PyOD scores...\n",
            "\n",
            "3. APPLYING THRESHOLDS\n",
            "LSTM anomalies: 3 (threshold: 1.0)\n",
            "PyOD anomalies: 4 (threshold: 0.700000)\n",
            "\n",
            "4. CONSENSUS ENSEMBLE SCORING\n",
            "Consensus anomalies: 2 (threshold: 0.75)\n",
            "Combined anomalies: 7\n",
            "Analyzing enhanced anomaly results...\n",
            "   2023-02-27: HIGH anomaly (consensus: 0.958)\n",
            "\n",
            "DETECTION COMPLETE!\n",
            "Anomalies detected: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Apply user defined threshold**"
      ],
      "metadata": {
        "id": "ASRcNaCfMVSI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Dict, Any\n",
        "\n",
        "class SimpleAnomalyController:\n",
        "    \"\"\"\n",
        "    Simple sensitivity control for anomaly detection.\n",
        "    App teams provide a single sensitivity level to adjust detection behavior.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        print(\"Simple Anomaly Controller initialized\")\n",
        "\n",
        "    def apply_sensitivity_control(\n",
        "        self,\n",
        "        lstm_pyod_results: Dict[str, Any],\n",
        "        sensitivity_level: str,  # 'very_low', 'low', 'medium', 'high', 'very_high'\n",
        "        target_date: str\n",
        "    ) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Apply sensitivity control with single parameter.\n",
        "\n",
        "        Args:\n",
        "            lstm_pyod_results: Detection results from anomaly detector\n",
        "            sensitivity_level: Controls detection sensitivity\n",
        "                - 'very_low': Only critical anomalies (10x threshold)\n",
        "                - 'low': Conservative detection (5x threshold)\n",
        "                - 'medium': Moderate sensitivity (2x threshold)\n",
        "                - 'high': Default sensitivity (1x threshold)\n",
        "                - 'very_high': Catches minor anomalies (0.5x threshold)\n",
        "            target_date: Date to analyze\n",
        "\n",
        "        Returns:\n",
        "            Updated results with new anomaly decision\n",
        "        \"\"\"\n",
        "\n",
        "        print(f\"Applying {sensitivity_level.upper()} sensitivity for {target_date}\")\n",
        "\n",
        "        # Define sensitivity configurations\n",
        "        sensitivity_configs = {\n",
        "            'very_high': {\n",
        "                'threshold_multiplier': 0.5,\n",
        "                'description': 'Very sensitive - detects minor anomalies'\n",
        "            },\n",
        "            'high': {\n",
        "                'threshold_multiplier': 1.0,\n",
        "                'description': 'High sensitivity - default detection level'\n",
        "            },\n",
        "            'medium': {\n",
        "                'threshold_multiplier': 2.0,\n",
        "                'description': 'Medium sensitivity - reduces false positives'\n",
        "            },\n",
        "            'low': {\n",
        "                'threshold_multiplier': 5.0,\n",
        "                'description': 'Low sensitivity - only major anomalies'\n",
        "            },\n",
        "            'very_low': {\n",
        "                'threshold_multiplier': 10.0,\n",
        "                'description': 'Very low sensitivity - minimal alerts'\n",
        "            }\n",
        "        }\n",
        "\n",
        "        # Validate sensitivity level\n",
        "        if sensitivity_level not in sensitivity_configs:\n",
        "            available_levels = list(sensitivity_configs.keys())\n",
        "            print(f\"Invalid sensitivity level. Available options: {available_levels}\")\n",
        "            return lstm_pyod_results\n",
        "\n",
        "        # Get configuration for selected sensitivity\n",
        "        config = sensitivity_configs[sensitivity_level]\n",
        "        threshold_multiplier = config['threshold_multiplier']\n",
        "        description = config['description']\n",
        "\n",
        "        print(f\"Configuration: {description}\")\n",
        "\n",
        "        # Calculate adjusted consensus threshold\n",
        "        original_consensus_threshold = 0.75  # Base threshold from model\n",
        "        adjusted_consensus_threshold = original_consensus_threshold * threshold_multiplier\n",
        "\n",
        "        # Apply threshold adjustment to target date\n",
        "        if target_date in lstm_pyod_results.get('anomaly_scores', {}):\n",
        "            date_scores = lstm_pyod_results['anomaly_scores'][target_date]\n",
        "\n",
        "            # Calculate new anomaly decision based on adjusted threshold\n",
        "            original_decision = date_scores['consensus_detected']\n",
        "            adjusted_decision = date_scores['consensus_score'] >= adjusted_consensus_threshold\n",
        "\n",
        "            # Create updated results\n",
        "            updated_results = lstm_pyod_results.copy()\n",
        "            updated_results['anomaly_scores'][target_date]['consensus_detected'] = adjusted_decision\n",
        "\n",
        "            # Update anomalous dates list\n",
        "            if adjusted_decision and target_date not in updated_results['anomalous_dates']:\n",
        "                updated_results['anomalous_dates'].append(target_date)\n",
        "            elif not adjusted_decision and target_date in updated_results['anomalous_dates']:\n",
        "                updated_results['anomalous_dates'].remove(target_date)\n",
        "\n",
        "            # Log decision comparison\n",
        "            original_status = \"ANOMALY\" if original_decision else \"NORMAL\"\n",
        "            adjusted_status = \"ANOMALY\" if adjusted_decision else \"NORMAL\"\n",
        "\n",
        "            print(f\"Consensus score: {date_scores['consensus_score']:.3f}\")\n",
        "            print(f\"Original threshold ({original_consensus_threshold}): {original_status}\")\n",
        "            print(f\"Adjusted threshold ({adjusted_consensus_threshold:.3f}): {adjusted_status}\")\n",
        "\n",
        "            # Log override information\n",
        "            if original_status != adjusted_status:\n",
        "                if original_status == \"ANOMALY\" and adjusted_status == \"NORMAL\":\n",
        "                    print(\"USER OVERRIDE: Model detected anomaly, user tolerance treats as normal\")\n",
        "                else:\n",
        "                    print(\"USER OVERRIDE: Model missed anomaly, user sensitivity caught it\")\n",
        "\n",
        "            # Update metadata\n",
        "            updated_results['summary_stats']['thresholds_used']['consensus_threshold'] = adjusted_consensus_threshold\n",
        "            updated_results['summary_stats']['sensitivity_level'] = sensitivity_level\n",
        "\n",
        "            return updated_results\n",
        "\n",
        "        else:\n",
        "            print(f\"No anomaly scores found for date: {target_date}\")\n",
        "            return lstm_pyod_results\n",
        "\n",
        "    def get_sensitivity_recommendation(self, use_case: str) -> str:\n",
        "        \"\"\"\n",
        "        Recommend sensitivity level based on business use case.\n",
        "\n",
        "        Args:\n",
        "            use_case: Business context for anomaly detection\n",
        "\n",
        "        Returns:\n",
        "            Recommended sensitivity level\n",
        "        \"\"\"\n",
        "\n",
        "        use_case_recommendations = {\n",
        "            'financial_fraud_detection': 'high',\n",
        "            'system_performance_monitoring': 'medium',\n",
        "            'data_quality_monitoring': 'medium',\n",
        "            'security_incident_detection': 'very_high',\n",
        "            'business_kpi_monitoring': 'low',\n",
        "            'operational_metrics': 'medium',\n",
        "            'customer_behavior_analysis': 'low',\n",
        "            'network_traffic_monitoring': 'high'\n",
        "        }\n",
        "\n",
        "        recommended_level = use_case_recommendations.get(use_case, 'medium')\n",
        "        print(f\"Recommended sensitivity for '{use_case}': {recommended_level}\")\n",
        "\n",
        "        return recommended_level\n",
        "\n",
        "\n",
        "class PercentageAnomalyController:\n",
        "    \"\"\"\n",
        "    Control anomaly detection using percentage-based tolerance.\n",
        "    Simpler interface for app teams who prefer percentage values.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        print(\"Percentage Anomaly Controller initialized\")\n",
        "\n",
        "    def apply_tolerance_percentage(\n",
        "        self,\n",
        "        lstm_pyod_results: Dict[str, Any],\n",
        "        tolerance_percent: float,  # 0-100: higher = less sensitive\n",
        "        target_date: str\n",
        "    ) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Apply tolerance using percentage scale.\n",
        "\n",
        "        Args:\n",
        "            lstm_pyod_results: Detection results from anomaly detector\n",
        "            tolerance_percent: Tolerance level as percentage\n",
        "                - 0%: Very sensitive (detects minor anomalies)\n",
        "                - 25%: High sensitivity\n",
        "                - 50%: Medium sensitivity (balanced)\n",
        "                - 75%: Low sensitivity (conservative)\n",
        "                - 100%: Very low sensitivity (minimal alerts)\n",
        "            target_date: Date to analyze\n",
        "\n",
        "        Returns:\n",
        "            Updated results with new anomaly decision\n",
        "        \"\"\"\n",
        "\n",
        "        print(f\"Applying {tolerance_percent}% tolerance for {target_date}\")\n",
        "\n",
        "        # Validate tolerance percentage\n",
        "        if not 0 <= tolerance_percent <= 100:\n",
        "            print(\"Tolerance percentage must be between 0 and 100\")\n",
        "            return lstm_pyod_results\n",
        "\n",
        "        # Convert percentage to threshold multiplier\n",
        "        # 0% -> 0.5x (more sensitive), 100% -> 10x (less sensitive)\n",
        "        threshold_multiplier = 0.5 + (tolerance_percent / 100) * 9.5\n",
        "\n",
        "        # Calculate adjusted threshold\n",
        "        original_threshold = 0.75\n",
        "        adjusted_threshold = original_threshold * threshold_multiplier\n",
        "\n",
        "        # Apply threshold adjustment\n",
        "        if target_date in lstm_pyod_results.get('anomaly_scores', {}):\n",
        "            date_scores = lstm_pyod_results['anomaly_scores'][target_date]\n",
        "\n",
        "            # Calculate new decision\n",
        "            original_decision = date_scores['consensus_detected']\n",
        "            adjusted_decision = date_scores['consensus_score'] >= adjusted_threshold\n",
        "\n",
        "            # Create updated results\n",
        "            updated_results = lstm_pyod_results.copy()\n",
        "            updated_results['anomaly_scores'][target_date]['consensus_detected'] = adjusted_decision\n",
        "\n",
        "            # Update anomalous dates list\n",
        "            if adjusted_decision and target_date not in updated_results['anomalous_dates']:\n",
        "                updated_results['anomalous_dates'].append(target_date)\n",
        "            elif not adjusted_decision and target_date in updated_results['anomalous_dates']:\n",
        "                updated_results['anomalous_dates'].remove(target_date)\n",
        "\n",
        "            # Log decision details\n",
        "            original_status = \"ANOMALY\" if original_decision else \"NORMAL\"\n",
        "            adjusted_status = \"ANOMALY\" if adjusted_decision else \"NORMAL\"\n",
        "\n",
        "            print(f\"Consensus score: {date_scores['consensus_score']:.3f}\")\n",
        "            print(f\"Tolerance threshold: {adjusted_threshold:.3f}\")\n",
        "            print(f\"Original decision: {original_status}\")\n",
        "            print(f\"Tolerance decision: {adjusted_status}\")\n",
        "\n",
        "            # Log override information\n",
        "            if original_decision and not adjusted_decision:\n",
        "                print(f\"USER TOLERANCE: Model detected anomaly, {tolerance_percent}% tolerance treats as normal\")\n",
        "            elif not original_decision and adjusted_decision:\n",
        "                print(f\"USER TOLERANCE: Model missed anomaly, {tolerance_percent}% tolerance caught it\")\n",
        "\n",
        "            # Update metadata\n",
        "            updated_results['summary_stats']['thresholds_used']['consensus_threshold'] = adjusted_threshold\n",
        "            updated_results['summary_stats']['tolerance_percent'] = tolerance_percent\n",
        "\n",
        "            return updated_results\n",
        "\n",
        "        else:\n",
        "            print(f\"No anomaly scores found for date: {target_date}\")\n",
        "            return lstm_pyod_results\n",
        "\n",
        "    def get_tolerance_recommendation(self, business_impact: str) -> float:\n",
        "        \"\"\"\n",
        "        Recommend tolerance percentage based on business impact.\n",
        "\n",
        "        Args:\n",
        "            business_impact: Level of business impact from false positives\n",
        "\n",
        "        Returns:\n",
        "            Recommended tolerance percentage\n",
        "        \"\"\"\n",
        "\n",
        "        impact_recommendations = {\n",
        "            'critical': 20.0,      # Low tolerance, catch more anomalies\n",
        "            'high': 40.0,          # Moderate tolerance\n",
        "            'medium': 60.0,        # Balanced approach\n",
        "            'low': 80.0,           # Higher tolerance, fewer alerts\n",
        "            'minimal': 90.0        # Very high tolerance, critical only\n",
        "        }\n",
        "\n",
        "        recommended_tolerance = impact_recommendations.get(business_impact, 60.0)\n",
        "        print(f\"Recommended tolerance for '{business_impact}' impact: {recommended_tolerance}%\")\n",
        "\n",
        "        return recommended_tolerance"
      ],
      "metadata": {
        "id": "qL17lxUrMeN6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Manu Model result override**"
      ],
      "metadata": {
        "id": "_0YgTM9GQHt7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**# STEP-BY-STEP USAGE GUIDE**\n",
        "\"\"\"\n",
        "PRODUCTION USAGE FLOW:\n",
        "\n",
        "*STEP 1: Initialize the manager*\n",
        "manager = ProductionAnomalyManager()\n",
        "\n",
        "*STEP 2: Run your existing detection (no changes needed)*\n",
        "lstm_pyod_results = detector.detect_dataset_anomalies(...)\n",
        "\n",
        "*STEP 3: Process with user decision (ONE SIMPLE CALL)*\n",
        "final_results = manager.process_anomaly_detection(\n",
        "    lstm_pyod_results=lstm_pyod_results,\n",
        "    target_date='2023-02-27',\n",
        "    user_action='force_normal',  # Single control value\n",
        "    user_reason='Known data migration - not a real anomaly',\n",
        "    user_id='analyst@company.com'\n",
        ")\n",
        "\n",
        "*STEP 4: Use final_results for downstream processing*\n",
        "decision = final_results['anomaly_scores']['2023-02-27']['consensus_detected']\n",
        "\n",
        "*STEP 5: Get audit trail when needed*\n",
        "audit_df = manager.get_override_audit_trail()\n",
        "\n",
        "USER_ACTION VALUES:\n",
        "- 'accept_model': Use whatever model decided\n",
        "- 'force_normal': Force as normal (treat as false positive)\n",
        "- 'force_anomaly': Force as anomaly (treat as missed detection)\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "p1YR5QQAQTFs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from typing import Dict, List, Any\n",
        "\n",
        "class AnomalyOverrideSystem:\n",
        "    \"\"\"\n",
        "    Manual override system for production anomaly detection.\n",
        "    Allows users to force classifications regardless of model scores.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.override_log = []\n",
        "        print(\"Manual Override System Initialized\")\n",
        "\n",
        "    def apply_manual_override(\n",
        "        self,\n",
        "        lstm_pyod_results: Dict[str, Any],\n",
        "        target_date: str,\n",
        "        override_decision: str,  # 'force_normal', 'force_anomaly', 'model_decision'\n",
        "        user_reason: str = \"\",\n",
        "        user_id: str = \"system\"\n",
        "    ) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Apply manual override regardless of model scores.\n",
        "\n",
        "        Args:\n",
        "            lstm_pyod_results: Detection results from model\n",
        "            target_date: Date to override (e.g., '2023-02-27')\n",
        "            override_decision: 'force_normal', 'force_anomaly', 'model_decision'\n",
        "            user_reason: Business justification for override\n",
        "            user_id: Who made the override decision\n",
        "\n",
        "        Returns:\n",
        "            Updated results with override applied\n",
        "        \"\"\"\n",
        "\n",
        "        if target_date not in lstm_pyod_results.get('anomaly_scores', {}):\n",
        "            print(f\"Error: No results found for {target_date}\")\n",
        "            return lstm_pyod_results\n",
        "\n",
        "        # Get original model decision\n",
        "        original_decision = lstm_pyod_results['anomaly_scores'][target_date]['consensus_detected']\n",
        "\n",
        "        # Determine new decision based on override\n",
        "        if override_decision == 'force_normal':\n",
        "            new_decision = False\n",
        "            override_type = \"FORCE NORMAL\"\n",
        "        elif override_decision == 'force_anomaly':\n",
        "            new_decision = True\n",
        "            override_type = \"FORCE ANOMALY\"\n",
        "        else:  # model_decision\n",
        "            new_decision = original_decision\n",
        "            override_type = \"MODEL DECISION\"\n",
        "\n",
        "        # Update results with override information\n",
        "        updated_results = lstm_pyod_results.copy()\n",
        "        updated_results['anomaly_scores'][target_date]['consensus_detected'] = new_decision\n",
        "        updated_results['anomaly_scores'][target_date]['manual_override'] = True\n",
        "        updated_results['anomaly_scores'][target_date]['override_type'] = override_type\n",
        "        updated_results['anomaly_scores'][target_date]['override_reason'] = user_reason\n",
        "        updated_results['anomaly_scores'][target_date]['override_user'] = user_id\n",
        "\n",
        "        # Update anomalous dates list\n",
        "        if new_decision and target_date not in updated_results['anomalous_dates']:\n",
        "            updated_results['anomalous_dates'].append(target_date)\n",
        "        elif not new_decision and target_date in updated_results['anomalous_dates']:\n",
        "            updated_results['anomalous_dates'].remove(target_date)\n",
        "\n",
        "        # Create audit log entry\n",
        "        override_entry = {\n",
        "            'date': target_date,\n",
        "            'original_decision': 'ANOMALY' if original_decision else 'NORMAL',\n",
        "            'override_decision': 'ANOMALY' if new_decision else 'NORMAL',\n",
        "            'override_type': override_type,\n",
        "            'user_reason': user_reason,\n",
        "            'user_id': user_id,\n",
        "            'timestamp': pd.Timestamp.now(),\n",
        "            'model_scores': {\n",
        "                'lstm': updated_results['anomaly_scores'][target_date]['lstm_score'],\n",
        "                'pyod': updated_results['anomaly_scores'][target_date]['pyod_score'],\n",
        "                'consensus': updated_results['anomaly_scores'][target_date]['consensus_score']\n",
        "            }\n",
        "        }\n",
        "\n",
        "        self.override_log.append(override_entry)\n",
        "\n",
        "        # Log override action\n",
        "        print(f\"\\nMANUAL OVERRIDE APPLIED for {target_date}\")\n",
        "        print(\"=\" * 50)\n",
        "        print(f\"Model Decision: {'ANOMALY' if original_decision else 'NORMAL'}\")\n",
        "        print(f\"User Override: {override_type}\")\n",
        "        print(f\"Final Decision: {'ANOMALY' if new_decision else 'NORMAL'}\")\n",
        "        print(f\"Reason: {user_reason}\")\n",
        "        print(f\"User: {user_id}\")\n",
        "        print(\"=\" * 50)\n",
        "\n",
        "        return updated_results\n",
        "\n",
        "    def get_override_history(self) -> pd.DataFrame:\n",
        "        \"\"\"Get complete history of all manual overrides.\"\"\"\n",
        "        return pd.DataFrame(self.override_log)\n",
        "\n",
        "    def validate_override_request(\n",
        "        self,\n",
        "        lstm_pyod_results: Dict[str, Any],\n",
        "        target_date: str,\n",
        "        override_decision: str\n",
        "    ) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Validate override request and provide impact assessment.\n",
        "\n",
        "        Args:\n",
        "            lstm_pyod_results: Detection results\n",
        "            target_date: Date to validate\n",
        "            override_decision: Proposed override action\n",
        "\n",
        "        Returns:\n",
        "            Validation results with recommendations\n",
        "        \"\"\"\n",
        "\n",
        "        if target_date not in lstm_pyod_results.get('anomaly_scores', {}):\n",
        "            return {\"valid\": False, \"reason\": \"Date not found in results\"}\n",
        "\n",
        "        scores = lstm_pyod_results['anomaly_scores'][target_date]\n",
        "        current_decision = scores['consensus_detected']\n",
        "\n",
        "        validation = {\n",
        "            \"valid\": True,\n",
        "            \"current_decision\": \"ANOMALY\" if current_decision else \"NORMAL\",\n",
        "            \"requested_override\": override_decision,\n",
        "            \"impact_assessment\": self._assess_override_impact(scores, override_decision),\n",
        "            \"model_confidence\": self._get_model_confidence(scores),\n",
        "            \"recommendation\": self._get_override_recommendation(scores, override_decision)\n",
        "        }\n",
        "\n",
        "        return validation\n",
        "\n",
        "    def _assess_override_impact(self, scores: Dict, override_decision: str) -> str:\n",
        "        \"\"\"Assess the business impact of the proposed override.\"\"\"\n",
        "\n",
        "        consensus_score = scores['consensus_score']\n",
        "\n",
        "        if override_decision == 'force_normal':\n",
        "            if consensus_score > 1000:\n",
        "                return \"HIGH IMPACT: Overriding very strong anomaly signal\"\n",
        "            elif consensus_score > 100:\n",
        "                return \"MEDIUM IMPACT: Overriding moderate anomaly signal\"\n",
        "            else:\n",
        "                return \"LOW IMPACT: Overriding weak anomaly signal\"\n",
        "        else:\n",
        "            return \"Forcing anomaly classification\"\n",
        "\n",
        "    def _get_model_confidence(self, scores: Dict) -> str:\n",
        "        \"\"\"Determine model confidence level.\"\"\"\n",
        "\n",
        "        both_agree = scores['lstm_detected'] and scores['pyod_detected']\n",
        "        any_detected = scores['lstm_detected'] or scores['pyod_detected']\n",
        "\n",
        "        if both_agree:\n",
        "            return \"HIGH (Both algorithms agree)\"\n",
        "        elif any_detected:\n",
        "            return \"MEDIUM (One algorithm detected)\"\n",
        "        else:\n",
        "            return \"LOW (No algorithms detected)\"\n",
        "\n",
        "    def _get_override_recommendation(self, scores: Dict, override_decision: str) -> str:\n",
        "        \"\"\"Provide recommendation on whether override is advisable.\"\"\"\n",
        "\n",
        "        consensus_score = scores['consensus_score']\n",
        "\n",
        "        if override_decision == 'force_normal':\n",
        "            if consensus_score > 500:\n",
        "                return \"NOT RECOMMENDED: Very strong anomaly signal\"\n",
        "            elif consensus_score > 100:\n",
        "                return \"CAUTION: Moderate anomaly signal - ensure business justification\"\n",
        "            else:\n",
        "                return \"ACCEPTABLE: Weak anomaly signal\"\n",
        "\n",
        "        return \"Manual anomaly classification\"\n",
        "\n",
        "class ProductionAnomalyManager:\n",
        "    \"\"\"\n",
        "    Complete production manager combining model detection with manual overrides.\n",
        "    Single entry point for all anomaly processing decisions.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.override_system = AnomalyOverrideSystem()\n",
        "        print(\"Production Anomaly Manager Ready\")\n",
        "\n",
        "    def process_anomaly_detection(\n",
        "        self,\n",
        "        lstm_pyod_results: Dict[str, Any],\n",
        "        target_date: str,\n",
        "        user_action: str = 'accept_model',  # 'accept_model', 'force_normal', 'force_anomaly'\n",
        "        user_reason: str = \"\",\n",
        "        user_id: str = \"system\"\n",
        "    ) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Complete workflow: Model detection + User decision + Override if needed.\n",
        "\n",
        "        Args:\n",
        "            lstm_pyod_results: Results from LSTM+PyOD detection\n",
        "            target_date: Date being processed\n",
        "            user_action: What action user wants to take\n",
        "            user_reason: Business justification for override\n",
        "            user_id: User making the decision\n",
        "\n",
        "        Returns:\n",
        "            Final results with user decision applied\n",
        "        \"\"\"\n",
        "\n",
        "        print(f\"\\nPROCESSING ANOMALY DETECTION for {target_date}\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        # Display model analysis\n",
        "        if target_date in lstm_pyod_results.get('anomaly_scores', {}):\n",
        "            scores = lstm_pyod_results['anomaly_scores'][target_date]\n",
        "\n",
        "            print(\"MODEL ANALYSIS:\")\n",
        "            print(f\"   LSTM Score: {scores['lstm_score']:.2f} -> {'ANOMALY' if scores['lstm_detected'] else 'NORMAL'}\")\n",
        "            print(f\"   PyOD Score: {scores['pyod_score']:.2f} -> {'ANOMALY' if scores['pyod_detected'] else 'NORMAL'}\")\n",
        "            print(f\"   Consensus: {scores['consensus_score']:.2f} -> {'ANOMALY' if scores['consensus_detected'] else 'NORMAL'}\")\n",
        "\n",
        "            model_decision = 'ANOMALY' if scores['consensus_detected'] else 'NORMAL'\n",
        "            print(f\"\\nMODEL RECOMMENDATION: {model_decision}\")\n",
        "\n",
        "            # Process user action\n",
        "            if user_action == 'accept_model':\n",
        "                print(\"USER ACTION: Accepted model decision\")\n",
        "                return lstm_pyod_results\n",
        "\n",
        "            elif user_action in ['force_normal', 'force_anomaly']:\n",
        "                # Show validation before applying override\n",
        "                validation = self.override_system.validate_override_request(\n",
        "                    lstm_pyod_results, target_date, user_action\n",
        "                )\n",
        "\n",
        "                print(\"\\nOVERRIDE VALIDATION:\")\n",
        "                print(f\"   Impact: {validation['impact_assessment']}\")\n",
        "                print(f\"   Model Confidence: {validation['model_confidence']}\")\n",
        "                print(f\"   Recommendation: {validation['recommendation']}\")\n",
        "\n",
        "                # Apply the override\n",
        "                final_results = self.override_system.apply_manual_override(\n",
        "                    lstm_pyod_results, target_date, user_action, user_reason, user_id\n",
        "                )\n",
        "\n",
        "                return final_results\n",
        "\n",
        "        return lstm_pyod_results\n",
        "\n",
        "    def get_override_audit_trail(self) -> pd.DataFrame:\n",
        "        \"\"\"Get complete audit trail of all manual overrides.\"\"\"\n",
        "        return self.override_system.get_override_history()\n",
        "\n"
      ],
      "metadata": {
        "id": "lwLa4er3QL93"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**On DEMAND EXECUTION FAIL OVER MECHANISSM**\n",
        "\n",
        "In this whole proces column value gettting modified manually\n",
        "\n",
        "*Before override*\n",
        "'consensus_detected': True  # ANOMALY\n",
        "\n",
        "*After override*\n",
        "'consensus_detected': False  # NORMAL"
      ],
      "metadata": {
        "id": "j_nkocJcQoBH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "manager = ProductionAnomalyManager()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9O84a_D6QnXk",
        "outputId": "0b173fb8-a87b-4807-beb1-c10fbe487e7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Manual Override System Initialized\n",
            "Production Anomaly Manager Ready\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_results = manager.process_anomaly_detection(\n",
        "    lstm_pyod_results=lstm_pyod_results,\n",
        "    target_date='2023-02-27',\n",
        "    user_action='force_normal',  # SINGLE CONTROL VALUE\n",
        "    user_reason='Known data migration',\n",
        "    user_id='gcganamfrmu'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUkli7KzQv09",
        "outputId": "498b6923-2899-438f-c967-799f3aa7ff5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "PROCESSING ANOMALY DETECTION for 2023-02-27\n",
            "============================================================\n",
            "MODEL ANALYSIS:\n",
            "   LSTM Score: 0.93 -> NORMAL\n",
            "   PyOD Score: 1.00 -> ANOMALY\n",
            "   Consensus: 0.96 -> ANOMALY\n",
            "\n",
            "MODEL RECOMMENDATION: ANOMALY\n",
            "\n",
            "OVERRIDE VALIDATION:\n",
            "   Impact: LOW IMPACT: Overriding weak anomaly signal\n",
            "   Model Confidence: MEDIUM (One algorithm detected)\n",
            "   Recommendation: ACCEPTABLE: Weak anomaly signal\n",
            "\n",
            "MANUAL OVERRIDE APPLIED for 2023-02-27\n",
            "==================================================\n",
            "Model Decision: ANOMALY\n",
            "User Override: FORCE NORMAL\n",
            "Final Decision: NORMAL\n",
            "Reason: Known data migration\n",
            "User: gcganamfrmu\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decision = final_results['anomaly_scores']['2023-02-27']['consensus_detected']\n",
        "print(f\"Final decision: {'ANOMALY' if decision else 'NORMAL'}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MdEiW-wjQ7Pn",
        "outputId": "54123a44-a733-43a9-e179-33000f8f1a99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final decision: NORMAL\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decision_df = create_anomaly_explanation_dataframe(\n",
        "    lstm_pyod_results=final_results,\n",
        "    original_df=transformed_datatype_df,  # original dataframe\n",
        "    target_date='2023-02-27',\n",
        "    target_columns=['aimp', 'amud', 'arnd']\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1hoZ9A6QQ9k3",
        "outputId": "f64de51e-cbad-44e1-9121-fb0a371226cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating explainability for 2023-02-27...\n",
            "Historical data: 57 days\n",
            "Target date data: 2023-02-27\n",
            "Analyzing 200 features\n",
            "Created explanations for 200 features\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decision_df['consensus_detected'].head(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        },
        "id": "DHw3dximRUAL",
        "outputId": "0861bc98-70d6-44a4-fb08-49b36671e524"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    False\n",
              "Name: consensus_detected, dtype: bool"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>consensus_detected</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> bool</label>"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explainable DataFrame**"
      ],
      "metadata": {
        "id": "AjBpEI1gykbC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from typing import Dict, List, Any\n",
        "\n",
        "def create_anomaly_explanation_dataframe(\n",
        "    lstm_pyod_results: Dict[str, Any],\n",
        "    original_df: pd.DataFrame,\n",
        "    target_date: str,\n",
        "    target_columns: List[str]\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Create explainable DataFrame from anomaly detection results.\n",
        "\n",
        "    Args:\n",
        "        lstm_pyod_results: Results from your detector\n",
        "        original_df: Original dataframe with raw values\n",
        "        target_date: Date being analyzed (e.g., '2023-02-27')\n",
        "        target_columns: Columns analyzed (e.g., ['aimp', 'amud', 'arnd'])\n",
        "\n",
        "    Returns:\n",
        "        DataFrame with detailed explanations\n",
        "    \"\"\"\n",
        "\n",
        "    print(f\"Creating explainability for {target_date}...\")\n",
        "\n",
        "    if target_date not in lstm_pyod_results.get('anomaly_scores', {}):\n",
        "        print(f\"No results found for {target_date}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    date_scores = lstm_pyod_results['anomaly_scores'][target_date]\n",
        "\n",
        "    target_row = original_df[original_df['date'] == target_date]\n",
        "    if target_row.empty:\n",
        "        print(f\"Target date {target_date} not found in original data\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    target_row = target_row.iloc[0]\n",
        "    historical_df = original_df[original_df['date'] < target_date]\n",
        "\n",
        "    print(f\"Historical data: {len(historical_df)} days\")\n",
        "    print(f\"Target date data: {target_date}\")\n",
        "\n",
        "    relevant_features = []\n",
        "    for col in target_columns:\n",
        "        features = [f for f in original_df.columns if f.startswith(f\"{col}_\")]\n",
        "        relevant_features.extend(features)\n",
        "\n",
        "    print(f\"Analyzing {len(relevant_features)} features\")\n",
        "\n",
        "    explanations = []\n",
        "\n",
        "    for feature in relevant_features:\n",
        "        if feature in original_df.columns and feature in target_row.index:\n",
        "\n",
        "            current_value = target_row[feature]\n",
        "\n",
        "            if len(historical_df) > 0 and feature in historical_df.columns:\n",
        "                hist_values = historical_df[feature].dropna()\n",
        "\n",
        "                if len(hist_values) > 0:\n",
        "                    hist_mean = hist_values.mean()\n",
        "                    hist_std = hist_values.std()\n",
        "                    hist_min = hist_values.min()\n",
        "                    hist_max = hist_values.max()\n",
        "\n",
        "                    z_score = (current_value - hist_mean) / (hist_std + 1e-8)\n",
        "                    deviation_pct = ((current_value - hist_mean) / (hist_mean + 1e-8)) * 100\n",
        "                    percentile = (hist_values <= current_value).mean() * 100\n",
        "\n",
        "                    severity = determine_severity(z_score, deviation_pct)\n",
        "                    feature_contribution = abs(z_score) / 10\n",
        "\n",
        "                    explanation_text = generate_feature_explanation(\n",
        "                        feature, current_value, hist_mean, z_score, deviation_pct, severity\n",
        "                    )\n",
        "\n",
        "                    explanation = {\n",
        "                        'date': target_date,\n",
        "                        'feature_name': feature,\n",
        "                        'base_column': extract_base_column(feature),\n",
        "                        'metric_type': extract_metric_type(feature),\n",
        "                        'current_value': round(current_value, 6),\n",
        "                        'historical_mean': round(hist_mean, 6),\n",
        "                        'historical_std': round(hist_std, 6),\n",
        "                        'historical_min': round(hist_min, 6),\n",
        "                        'historical_max': round(hist_max, 6),\n",
        "                        'z_score': round(z_score, 3),\n",
        "                        'deviation_percentage': round(deviation_pct, 2),\n",
        "                        'percentile_rank': round(percentile, 1),\n",
        "                        'severity': severity,\n",
        "                        'feature_contribution_score': round(feature_contribution, 3),\n",
        "                        'lstm_score': date_scores['lstm_score'],\n",
        "                        'pyod_score': date_scores['pyod_score'],\n",
        "                        'consensus_score': date_scores['consensus_score'],\n",
        "                        'lstm_detected': date_scores['lstm_detected'],\n",
        "                        'pyod_detected': date_scores['pyod_detected'],\n",
        "                        'consensus_detected': date_scores['consensus_detected'],\n",
        "                        'explanation': explanation_text,\n",
        "                        'recommendation': generate_recommendation(severity, z_score)\n",
        "                    }\n",
        "\n",
        "                    explanations.append(explanation)\n",
        "\n",
        "    explanation_df = pd.DataFrame(explanations)\n",
        "\n",
        "    if not explanation_df.empty:\n",
        "        explanation_df = explanation_df.sort_values('feature_contribution_score', ascending=False)\n",
        "        explanation_df = explanation_df.reset_index(drop=True)\n",
        "\n",
        "    print(f\"Created explanations for {len(explanation_df)} features\")\n",
        "    return explanation_df\n",
        "\n",
        "def determine_severity(z_score: float, deviation_pct: float) -> str:\n",
        "    \"\"\"Determine severity level based on statistical measures.\"\"\"\n",
        "\n",
        "    abs_z = abs(z_score)\n",
        "    abs_dev = abs(deviation_pct)\n",
        "\n",
        "    if abs_z >= 5 or abs_dev >= 1000:\n",
        "        return 'CRITICAL'\n",
        "    elif abs_z >= 3 or abs_dev >= 500:\n",
        "        return 'HIGH'\n",
        "    elif abs_z >= 2 or abs_dev >= 100:\n",
        "        return 'MEDIUM'\n",
        "    else:\n",
        "        return 'LOW'\n",
        "\n",
        "def extract_base_column(feature_name: str) -> str:\n",
        "    \"\"\"Extract base column name (e.g., 'aimp' from 'aimp_mean').\"\"\"\n",
        "    return feature_name.split('_')[0] if '_' in feature_name else feature_name\n",
        "\n",
        "def extract_metric_type(feature_name: str) -> str:\n",
        "    \"\"\"Extract metric type (e.g., 'mean' from 'aimp_mean').\"\"\"\n",
        "    parts = feature_name.split('_')\n",
        "    return parts[-1] if len(parts) > 1 else 'base_value'\n",
        "\n",
        "def generate_feature_explanation(\n",
        "    feature: str,\n",
        "    current_value: float,\n",
        "    hist_mean: float,\n",
        "    z_score: float,\n",
        "    deviation_pct: float,\n",
        "    severity: str\n",
        ") -> str:\n",
        "    \"\"\"Generate human-readable explanation for the feature.\"\"\"\n",
        "\n",
        "    direction = \"increased\" if current_value > hist_mean else \"decreased\"\n",
        "    magnitude = get_magnitude_word(abs(z_score))\n",
        "\n",
        "    return (f\"Feature '{feature}' has {magnitude} {direction} from its historical average. \"\n",
        "            f\"Current value: {current_value:.4f}, Historical average: {hist_mean:.4f}. \"\n",
        "            f\"This represents a {abs(deviation_pct):.1f}% change with z-score of {z_score:.2f}. \"\n",
        "            f\"Severity: {severity}\")\n",
        "\n",
        "def get_magnitude_word(abs_z_score: float) -> str:\n",
        "    \"\"\"Get magnitude description based on z-score.\"\"\"\n",
        "    if abs_z_score >= 5:\n",
        "        return \"extremely\"\n",
        "    elif abs_z_score >= 3:\n",
        "        return \"significantly\"\n",
        "    elif abs_z_score >= 2:\n",
        "        return \"moderately\"\n",
        "    else:\n",
        "        return \"slightly\"\n",
        "\n",
        "def generate_recommendation(severity: str, z_score: float) -> str:\n",
        "    \"\"\"Generate actionable recommendation.\"\"\"\n",
        "\n",
        "    if severity == 'CRITICAL':\n",
        "        return \"IMMEDIATE ACTION: Investigate data sources and business processes immediately\"\n",
        "    elif severity == 'HIGH':\n",
        "        return \"URGENT: Review within 24 hours to identify root cause\"\n",
        "    elif severity == 'MEDIUM':\n",
        "        return \"MONITOR: Schedule review within 48-72 hours\"\n",
        "    else:\n",
        "        return \"TRACK: Continue monitoring in regular review cycle\"\n",
        "\n",
        "def create_summary_report(lstm_pyod_results: Dict[str, Any], target_date: str) -> Dict[str, Any]:\n",
        "    \"\"\"Create executive summary report.\"\"\"\n",
        "\n",
        "    if target_date not in lstm_pyod_results.get('anomaly_scores', {}):\n",
        "        return {}\n",
        "\n",
        "    scores = lstm_pyod_results['anomaly_scores'][target_date]\n",
        "    severity = lstm_pyod_results['anomaly_severity'].get(target_date, 'LOW')\n",
        "\n",
        "    both_agree = scores['lstm_detected'] and scores['pyod_detected']\n",
        "    any_detected = scores['lstm_detected'] or scores['pyod_detected']\n",
        "\n",
        "    summary = {\n",
        "        'detection_date': target_date,\n",
        "        'overall_status': 'ANOMALY' if scores['consensus_detected'] else 'NORMAL',\n",
        "        'severity_level': severity,\n",
        "        'confidence_level': 'HIGH' if both_agree else 'MEDIUM' if any_detected else 'LOW',\n",
        "        'lstm_score': round(scores['lstm_score'], 3),\n",
        "        'pyod_score': round(scores['pyod_score'], 3),\n",
        "        'consensus_score': round(scores['consensus_score'], 3),\n",
        "        'lstm_detected': scores['lstm_detected'],\n",
        "        'pyod_detected': scores['pyod_detected'],\n",
        "        'consensus_detected': scores['consensus_detected'],\n",
        "        'algorithm_agreement': both_agree,\n",
        "        'thresholds_used': lstm_pyod_results['summary_stats']['thresholds_used'],\n",
        "        'recommendation': generate_recommendation(severity, 0)\n",
        "    }\n",
        "\n",
        "    return summary\n",
        "\n",
        "def log_detection_scores(lstm_pyod_results: Dict[str, Any], target_date: str):\n",
        "    \"\"\"Log detection scores for audit trail.\"\"\"\n",
        "\n",
        "    if target_date not in lstm_pyod_results.get('anomaly_scores', {}):\n",
        "        print(f\"No scores found for {target_date}\")\n",
        "        return\n",
        "\n",
        "    scores = lstm_pyod_results['anomaly_scores'][target_date]\n",
        "    thresholds = lstm_pyod_results['summary_stats']['thresholds_used']\n",
        "\n",
        "    print(f\"\\nDETECTION SCORE LOG for {target_date}\")\n",
        "    print(\"=\" * 50)\n",
        "    print(f\" LSTM Score: {scores['lstm_score']:.4f}\")\n",
        "    print(f\"   Threshold: {thresholds['lstm_threshold']}\")\n",
        "    print(f\"   Detected: {scores['lstm_detected']}\")\n",
        "    print(f\"PyOD Score: {scores['pyod_score']:.4f}\")\n",
        "    print(f\"   Threshold: {thresholds['pyod_threshold']}\")\n",
        "    print(f\"   Detected: {scores['pyod_detected']}\")\n",
        "    print(f\" Consensus Score: {scores['consensus_score']:.4f}\")\n",
        "    print(f\"   Threshold: {thresholds['consensus_threshold']}\")\n",
        "    print(f\"   Final Decision: {'ANOMALY' if scores['consensus_detected'] else 'NORMAL'}\")\n",
        "    print(f\" Severity: {lstm_pyod_results['anomaly_severity'].get(target_date, 'LOW')}\")\n",
        "    print(\"=\" * 50)"
      ],
      "metadata": {
        "id": "PasaO9F0c9KZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explainable DataFrame execution**"
      ],
      "metadata": {
        "id": "i2_bG4KGdqYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "explanation_df = create_anomaly_explanation_dataframe(\n",
        "    lstm_pyod_results=lstm_pyod_results,\n",
        "    original_df=transformed_datatype_df,  # original dataframe\n",
        "    target_date='2023-02-27',\n",
        "    target_columns=['aimp', 'amud', 'arnd']\n",
        ")"
      ],
      "metadata": {
        "id": "2vTKu84eyqL_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "904b4dd9-3f09-489f-fd55-6c4e806c99bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating explainability for 2023-02-27...\n",
            "Historical data: 57 days\n",
            "Target date data: 2023-02-27\n",
            "Analyzing 200 features\n",
            "Created explanations for 200 features\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "explanation_df.columns"
      ],
      "metadata": {
        "id": "-chEV7XsKF1D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e7599f5-1e51-481f-b365-a8aaafb617ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['date', 'feature_name', 'base_column', 'metric_type', 'current_value',\n",
              "       'historical_mean', 'historical_std', 'historical_min', 'historical_max',\n",
              "       'z_score', 'deviation_percentage', 'percentile_rank', 'severity',\n",
              "       'feature_contribution_score', 'lstm_score', 'pyod_score',\n",
              "       'consensus_score', 'lstm_detected', 'pyod_detected',\n",
              "       'consensus_detected', 'explanation', 'recommendation'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Summary Report**"
      ],
      "metadata": {
        "id": "dF2N7yrsbEFE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "summary = create_summary_report(\n",
        "    lstm_pyod_results=lstm_pyod_results,\n",
        "    target_date='2023-02-27'\n",
        ")\n",
        "\n",
        "print(\"📋 SUMMARY REPORT:\")\n",
        "for key, value in summary.items():\n",
        "    print(f\"   {key}: {value}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIN2YoU4d1kx",
        "outputId": "f2413af9-a03f-4e9d-a0e1-718714d068c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📋 SUMMARY REPORT:\n",
            "   detection_date: 2023-02-27\n",
            "   overall_status: NORMAL\n",
            "   severity_level: HIGH\n",
            "   confidence_level: MEDIUM\n",
            "   lstm_score: 0.93\n",
            "   pyod_score: 1.0\n",
            "   consensus_score: 0.958\n",
            "   lstm_detected: False\n",
            "   pyod_detected: True\n",
            "   consensus_detected: False\n",
            "   algorithm_agreement: False\n",
            "   thresholds_used: {'lstm_threshold': 1.0, 'pyod_threshold': 0.7, 'consensus_threshold': 0.75}\n",
            "   recommendation: URGENT: Review within 24 hours to identify root cause\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Log Detection Scores**"
      ],
      "metadata": {
        "id": "MBhYuoMVeB9N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "log_detection_scores(\n",
        "    lstm_pyod_results=lstm_pyod_results,\n",
        "    target_date='2023-02-27'\n",
        ")"
      ],
      "metadata": {
        "id": "xEP2ebdZoMtN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65265000-3d58-4a5d-a1a7-e6f88ecfce6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DETECTION SCORE LOG for 2023-02-27\n",
            "==================================================\n",
            " LSTM Score: 0.9300\n",
            "   Threshold: 1.0\n",
            "   Detected: False\n",
            "PyOD Score: 1.0000\n",
            "   Threshold: 0.7\n",
            "   Detected: True\n",
            " Consensus Score: 0.9580\n",
            "   Threshold: 0.75\n",
            "   Final Decision: NORMAL\n",
            " Severity: HIGH\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Critical feature contributed**"
      ],
      "metadata": {
        "id": "BEh7hkdsU_vt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Share only HIGH/CRITICAL severity features\n",
        "critical_features = explanation_df[explanation_df['severity'].isin(['HIGH', 'CRITICAL'])]\n",
        "critical_features.to_csv('/content/sample_data/critical_features.csv', index=False)"
      ],
      "metadata": {
        "id": "Poj2vlpEVDq0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "critical_features.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 516
        },
        "id": "AsyfsVHLVE7q",
        "outputId": "bc0d21a0-2806-4a42-e0fd-ce46c24b5f5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         date                        feature_name base_column metric_type  \\\n",
              "0  2023-02-27   aimp_UniqueValueRatio_anomaly_30d        aimp         30d   \n",
              "1  2023-02-27  arnd_CountDistinct_rolling_30d_std        arnd         std   \n",
              "2  2023-02-27       arnd_CountDistinct_zscore_30d        arnd         30d   \n",
              "3  2023-02-27                 aimp_Sum_zscore_30d        aimp         30d   \n",
              "4  2023-02-27                    aimp_Sum_diff_7d        aimp          7d   \n",
              "\n",
              "   current_value  historical_mean  historical_std  historical_min  \\\n",
              "0       1.000000         0.000000        0.000000        0.000000   \n",
              "1    1997.328515       119.766662      123.929667        0.000000   \n",
              "2      -5.267085         0.011426        0.478672       -1.231919   \n",
              "3      -3.878286        -0.074981        0.635234       -2.843448   \n",
              "4    -126.714286         0.523810       24.031781      -60.142857   \n",
              "\n",
              "   historical_max       z_score  ...  severity  feature_contribution_score  \\\n",
              "0        0.000000  1.000000e+08  ...  CRITICAL                1.000000e+07   \n",
              "1      269.597829  1.515000e+01  ...  CRITICAL                1.515000e+00   \n",
              "2        1.753079 -1.102700e+01  ...  CRITICAL                1.103000e+00   \n",
              "3        1.210494 -5.987000e+00  ...  CRITICAL                5.990000e-01   \n",
              "4       57.857143 -5.295000e+00  ...  CRITICAL                5.290000e-01   \n",
              "\n",
              "  lstm_score  pyod_score  consensus_score  lstm_detected  pyod_detected  \\\n",
              "0   0.929998         1.0         0.957999          False           True   \n",
              "1   0.929998         1.0         0.957999          False           True   \n",
              "2   0.929998         1.0         0.957999          False           True   \n",
              "3   0.929998         1.0         0.957999          False           True   \n",
              "4   0.929998         1.0         0.957999          False           True   \n",
              "\n",
              "   consensus_detected                                        explanation  \\\n",
              "0               False  Feature 'aimp_UniqueValueRatio_anomaly_30d' ha...   \n",
              "1               False  Feature 'arnd_CountDistinct_rolling_30d_std' h...   \n",
              "2               False  Feature 'arnd_CountDistinct_zscore_30d' has ex...   \n",
              "3               False  Feature 'aimp_Sum_zscore_30d' has extremely de...   \n",
              "4               False  Feature 'aimp_Sum_diff_7d' has extremely decre...   \n",
              "\n",
              "                                      recommendation  \n",
              "0  IMMEDIATE ACTION: Investigate data sources and...  \n",
              "1  IMMEDIATE ACTION: Investigate data sources and...  \n",
              "2  IMMEDIATE ACTION: Investigate data sources and...  \n",
              "3  IMMEDIATE ACTION: Investigate data sources and...  \n",
              "4  IMMEDIATE ACTION: Investigate data sources and...  \n",
              "\n",
              "[5 rows x 22 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-092f3487-5685-40a8-b1fe-cc5afc84bf04\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>feature_name</th>\n",
              "      <th>base_column</th>\n",
              "      <th>metric_type</th>\n",
              "      <th>current_value</th>\n",
              "      <th>historical_mean</th>\n",
              "      <th>historical_std</th>\n",
              "      <th>historical_min</th>\n",
              "      <th>historical_max</th>\n",
              "      <th>z_score</th>\n",
              "      <th>...</th>\n",
              "      <th>severity</th>\n",
              "      <th>feature_contribution_score</th>\n",
              "      <th>lstm_score</th>\n",
              "      <th>pyod_score</th>\n",
              "      <th>consensus_score</th>\n",
              "      <th>lstm_detected</th>\n",
              "      <th>pyod_detected</th>\n",
              "      <th>consensus_detected</th>\n",
              "      <th>explanation</th>\n",
              "      <th>recommendation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2023-02-27</td>\n",
              "      <td>aimp_UniqueValueRatio_anomaly_30d</td>\n",
              "      <td>aimp</td>\n",
              "      <td>30d</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000e+08</td>\n",
              "      <td>...</td>\n",
              "      <td>CRITICAL</td>\n",
              "      <td>1.000000e+07</td>\n",
              "      <td>0.929998</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.957999</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>Feature 'aimp_UniqueValueRatio_anomaly_30d' ha...</td>\n",
              "      <td>IMMEDIATE ACTION: Investigate data sources and...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2023-02-27</td>\n",
              "      <td>arnd_CountDistinct_rolling_30d_std</td>\n",
              "      <td>arnd</td>\n",
              "      <td>std</td>\n",
              "      <td>1997.328515</td>\n",
              "      <td>119.766662</td>\n",
              "      <td>123.929667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>269.597829</td>\n",
              "      <td>1.515000e+01</td>\n",
              "      <td>...</td>\n",
              "      <td>CRITICAL</td>\n",
              "      <td>1.515000e+00</td>\n",
              "      <td>0.929998</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.957999</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>Feature 'arnd_CountDistinct_rolling_30d_std' h...</td>\n",
              "      <td>IMMEDIATE ACTION: Investigate data sources and...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2023-02-27</td>\n",
              "      <td>arnd_CountDistinct_zscore_30d</td>\n",
              "      <td>arnd</td>\n",
              "      <td>30d</td>\n",
              "      <td>-5.267085</td>\n",
              "      <td>0.011426</td>\n",
              "      <td>0.478672</td>\n",
              "      <td>-1.231919</td>\n",
              "      <td>1.753079</td>\n",
              "      <td>-1.102700e+01</td>\n",
              "      <td>...</td>\n",
              "      <td>CRITICAL</td>\n",
              "      <td>1.103000e+00</td>\n",
              "      <td>0.929998</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.957999</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>Feature 'arnd_CountDistinct_zscore_30d' has ex...</td>\n",
              "      <td>IMMEDIATE ACTION: Investigate data sources and...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2023-02-27</td>\n",
              "      <td>aimp_Sum_zscore_30d</td>\n",
              "      <td>aimp</td>\n",
              "      <td>30d</td>\n",
              "      <td>-3.878286</td>\n",
              "      <td>-0.074981</td>\n",
              "      <td>0.635234</td>\n",
              "      <td>-2.843448</td>\n",
              "      <td>1.210494</td>\n",
              "      <td>-5.987000e+00</td>\n",
              "      <td>...</td>\n",
              "      <td>CRITICAL</td>\n",
              "      <td>5.990000e-01</td>\n",
              "      <td>0.929998</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.957999</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>Feature 'aimp_Sum_zscore_30d' has extremely de...</td>\n",
              "      <td>IMMEDIATE ACTION: Investigate data sources and...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2023-02-27</td>\n",
              "      <td>aimp_Sum_diff_7d</td>\n",
              "      <td>aimp</td>\n",
              "      <td>7d</td>\n",
              "      <td>-126.714286</td>\n",
              "      <td>0.523810</td>\n",
              "      <td>24.031781</td>\n",
              "      <td>-60.142857</td>\n",
              "      <td>57.857143</td>\n",
              "      <td>-5.295000e+00</td>\n",
              "      <td>...</td>\n",
              "      <td>CRITICAL</td>\n",
              "      <td>5.290000e-01</td>\n",
              "      <td>0.929998</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.957999</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>Feature 'aimp_Sum_diff_7d' has extremely decre...</td>\n",
              "      <td>IMMEDIATE ACTION: Investigate data sources and...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 22 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-092f3487-5685-40a8-b1fe-cc5afc84bf04')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-092f3487-5685-40a8-b1fe-cc5afc84bf04 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-092f3487-5685-40a8-b1fe-cc5afc84bf04');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-efd2cede-602f-40dd-9ab6-045011c96649\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-efd2cede-602f-40dd-9ab6-045011c96649')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-efd2cede-602f-40dd-9ab6-045011c96649 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "critical_features"
            }
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**controller**\n",
        "\n",
        "# App team just chooses sensitivity level\n",
        "updated_results = controller.apply_sensitivity_control(\n",
        "    lstm_pyod_results=lstm_pyod_results,\n",
        "    sensitivity_level='low',  # 'very_high', 'high', 'medium', 'low', 'very_low'\n",
        "    target_date='2023-02-27'\n",
        ")\n",
        "\"\"\"\n",
        "# ================================================\n",
        "# QUICK REFERENCE FOR USERS:\n",
        "# ================================================\n",
        "\n",
        "\n",
        "WHEN TO USE EACH OPTION:\n",
        "\n",
        "Option 1 - Sensitivity Levels:\n",
        "- Best for: Non-technical users who want simple control\n",
        "- Parameters: 'very_high', 'high', 'medium', 'low', 'very_low'\n",
        "- Use case: \"I want less false alarms\" → use 'low' or 'very_low'\n",
        "\n",
        "Option 2 - Percentage Tolerance:\n",
        "- Best for: Users who want precise control\n",
        "- Parameters: 0-100% (higher = less sensitive)\n",
        "- Use case: \"I want 80% confidence threshold\" → use tolerance_percent=80\n",
        "\n",
        "EXAMPLES:\n",
        "1. For reducing false positives: sensitivity_level='low' or tolerance_percent=85\n",
        "2. For catching more anomalies: sensitivity_level='high' or tolerance_percent=30\n",
        "3. For balanced detection: sensitivity_level='medium' or tolerance_percent=50\n"
      ],
      "metadata": {
        "id": "4TUS7ypoQSMM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**For String-based tolerance:**"
      ],
      "metadata": {
        "id": "n6caLi5-T3mB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "controller = SimpleAnomalyController()\n",
        "updated_results = controller.apply_sensitivity_control(\n",
        "    lstm_pyod_results=lstm_pyod_results,\n",
        "    sensitivity_level='very_low',  # 'very_high', 'high', 'medium', 'low', 'very_low'\n",
        "    target_date='2023-02-27'\n",
        ")"
      ],
      "metadata": {
        "id": "nkXo2eW9QMke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**For percentage-based tolerance:**"
      ],
      "metadata": {
        "id": "F5qvRVWFTzsX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "controller = PercentageAnomalyController()  # Different controller\n",
        "updated_results = controller.apply_tolerance_percentage(\n",
        "    lstm_pyod_results=lstm_pyod_results,\n",
        "    tolerance_percent=99,  # 0-100%, higher = less sensitive\n",
        "    target_date='2023-02-27'\n",
        ")"
      ],
      "metadata": {
        "id": "TxAXsjjWTTeg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uPCDkoC4T_Yh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}